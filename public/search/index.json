[{"content":"hugo theme stack에서 giscus 댓글창 사용하기 댓글창 활성화하기 댓글창 활성화해야지, 해야지 생각만 하다가 거의 두달이 지났으니 이젠 진짜 해야만 한다\nGiscus 댓글창 추가 블로그 글을 참고하였다.\ngithub repo 생성 및 giscus 설치 theme과 연결 내가 사용하는 hugo stack theme은 giscus comment systems를 지원하고 있었다. 그래서 가이드를 따라서 설정을 진행했다.\nhugo stack theme doc\n설정은 hugo.toml을 수정하면 되는데, 이 때 필요한 repo id나 기타 등등은 https://giscus.app/ko를 통해 알 수 있다.\nlightTheme, darkTheme에 각각 라이트, 다크모드의 giscus theme을 적어주면 된다.\n나는 위에 언급한 페이지에서 테마를 몇개 구경하고, light_high_contrast와 dark_high_contrast로 정해서 세팅파일에 적어주었다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [params.comments] enabled = true provider = \u0026#34;giscus\u0026#34; [params.comments.giscus] reactionsEnabled = 1 emitMetadata = 0 repo = \u0026#34;srlee056/giscus\u0026#34; repoID = \u0026#34;R_kgDOK7YF9g\u0026#34; category = \u0026#34;Blog\u0026#34; categoryID = \u0026#34;DIC_kwDOK7YF9s4Cb2te\u0026#34; mapping = \u0026#34;pathname\u0026#34; lang = \u0026#34;ko\u0026#34; lightTheme = \u0026#34;light_high_contrast\u0026#34; darkTheme = \u0026#34;dark_high_contrast\u0026#34; 결과 화면 [ 다크모드 ON ]\n[ 다크모드 OFF ]\n","date":"2023-12-19T15:22:00+09:00","permalink":"https://srlee056.github.io/Blog/blog-3/","title":"Blog 제작기 #3"},{"content":" 📋 공부 내용 hangman web 실습 flask web page 실행해보기 play-with-docker 사이트를 활용해서 테스트\ngit clone으로 fork 해둔 repo를 받아오고, 실행하기\n1 2 3 4 git clone https://github.com/srlee056/hangman_web.git cd hangman_web/ pip install -r requirements.txt python3 -m flask run --host 0.0.0.0 --port=4000 docker 이미지 빌드 실습 Dockerfile 작성 1 2 3 4 5 6 7 8 9 FROM python:3.8-slim-buster WORKDIR /app COPY app.py ./ COPY requirements.txt ./ RUN pip3 install -r requirements.txt EXPOSE 4000 CMD python3 -m flask run --host 0.0.0.0 --port=4000 # 리스트 형태로 적어도 동작은 같음 CMD [\u0026#34;python3\u0026#34;, \u0026#34;-m\u0026#34;, \u0026#34;flask\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;--host\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, \u0026#34;--port=4000\u0026#34;] docker build \u0026amp; test build 1 docker build -t hangman-web . run -p 옵션을 사용해서 포트 포워딩 진행 외부 포트 : 내부 포트 순서로 작성한다 1 docker run -p 4000:4000 hangman-web push image to docker Hub 1 2 3 docker tag hangman-web seorim/hangman-web docker login --username=seorim docker push seorim/hangman-web test in another host 1 2 docker pull seorim/hangman-web docker run -p 4000:4000 seorim/hangman-web docker run detach 옵션 백그라운드에서 실행하게 해주는 옵션 1 docker run -p 4000:4000 -d seorim/hangman-test CI/CD Continuous Integration One of Software Engineering Practice\n기본 원칙\n코드 Repository는 하나만 유지 (Main) 코드 변경을 자주 반영 테스트를 최대한 추가 (Test Coverage) 빌드의 자동화 (Commit Build vs. Nightly Build) 성공한 빌드를 프로덕션으로 릴리스 자동화: CD CI/CD 자동화 과정에 도커를 활용 GitHub Actions GitHub의 CI/CD service\nworkflow Push, PR 등 트리거 이벤트가 발생하면 시작되는 일련의 동작을 지칭\n{workflow_name}.yaml(or .yml) Job으로 나누어지며, 각 Job은 일련의 Step을 수행함 GitHub Actions 사용 실습 공통적인 부분 workflow 파일의 구조는 보통 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 name: app-name on: # trigger events push: branches: [\u0026#34;main\u0026#34;] # name of branches pull_request: branches: [\u0026#34;main\u0026#34;] permissions: contents: read jobs: build: runs-on: ubuntu-latest steps: ... 테스트 자동화 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 steps: - uses: actions/checkout@v3 - name: Set up Python 3.10 uses: actions/setup-python@v3 with: python-version: \u0026#34;3.10\u0026#34; - name: Install dependencies run: | python -m pip install --upgrade pip pip install flake8 if [ -f requirements.txt ]; then pip install -r requirements.txt; fi - name: Lint with flake8 run: | # stop the build if there are Python syntax errors or undefined names flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics - name: Test with unittest run: | python3 -m unittest discover -p \u0026#39;test*.py\u0026#39; # python3 test.py Docker Build \u0026amp; Push 자동화 repository settings -\u0026gt; secrets \u0026amp; variables -\u0026gt; Actions 에서 로그인 정보 (ID/PW) 저장하고 가져와서 사용할 수 있다. ${{secrets.DOCKER_USER}} 형식으로 불러올 수 있으며, 파일에서 사용할 땐 env에서 지정하거나, 바로 사용할 수도 있다. 1 2 3 4 5 6 7 8 9 - name: Login to the Docker Hub env: DOCKER_USER: ${{secrets.DOCKER_USER}} DOCKER_PASSWORD: ${{secrets.DOCKER_PASSWORD}} run: docker login -u $DOCKER_USER -p $DOCKER_PASSWORD - name: Build the Docker image run: docker build --tag ${{secrets.DOCKER_USER}}/hangman-web:latest . - name : Push the Docker image to the Docker Hub run: docker push ${{secrets.DOCKER_USER}}/hangman-web:latest 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 오늘은 dockerfile을 직접 작성해보고, GitHub Actions를 사용해보았다. Dockerfile은 직접 작성해서 문제없이 빌드 됐다는 것에 의의를 뒀고, GitHub Actions는 이미 사용해 본 적이 몇번 있어서 쉽게 이해하고 넘어갈 수 있었다.\n강의 듣고 정리하는게 일찍 끝나서 블로그에 댓글기능을 추가했다. 다음엔 viewer 기능을 추가할 까 고민중.\n","date":"2023-12-19T12:54:14+09:00","permalink":"https://srlee056.github.io/p/day-47/","title":"Day 47 Docker(2)"},{"content":"GitHub Link\n문제 설명 이 문제는 아주 평범한 배낭에 관한 문제이다.\n한 달 후면 국가의 부름을 받게 되는 준서는 여행을 가려고 한다. 세상과의 단절을 슬퍼하며 최대한 즐기기 위한 여행이기 때문에, 가지고 다닐 배낭 또한 최대한 가치 있게 싸려고 한다.\n준서가 여행에 필요하다고 생각하는 N개의 물건이 있다. 각 물건은 무게 W와 가치 V를 가지는데, 해당 물건을 배낭에 넣어서 가면 준서가 V만큼 즐길 수 있다. 아직 행군을 해본 적이 없는 준서는 최대 K만큼의 무게만을 넣을 수 있는 배낭만 들고 다닐 수 있다. 준서가 최대한 즐거운 여행을 하기 위해 배낭에 넣을 수 있는 물건들의 가치의 최댓값을 알려주자.\n입력 첫 줄에 물품의 수 N(1 ≤ N ≤ 100)과 준서가 버틸 수 있는 무게 K(1 ≤ K ≤ 100,000)가 주어진다. 두 번째 줄부터 N개의 줄에 거쳐 각 물건의 무게 W(1 ≤ W ≤ 100,000)와 해당 물건의 가치 V(0 ≤ V ≤ 1,000)가 주어진다.\n입력으로 주어지는 모든 수는 정수이다.\n출력 한 줄에 배낭에 넣을 수 있는 물건들의 가치합의 최댓값을 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import sys def main(): num, total_weight = map(int, sys.stdin.readline().split()) elements = [] for _ in range(num): weight, value = map(int, sys.stdin.readline().split()) elements.append([weight, value]) # 최대 무게 * 물건의 수 value_by_weights_elements = [ [0 for _ in range(total_weight + 1)] for _ in range(num + 1) ] for i, ele in enumerate(elements): for j in range(total_weight + 1): orig_val = value_by_weights_elements[i][j] if j \u0026gt;= ele[0]: new_val = value_by_weights_elements[i][j - ele[0]] + ele[1] value_by_weights_elements[i + 1][j] = max(orig_val, new_val) else: value_by_weights_elements[i + 1][j] = orig_val print(value_by_weights_elements[-1][-1]) if __name__ == \u0026#34;__main__\u0026#34;: main() CHECK! knapsack dp 구현 방식에 대해 블로그를 참고하였다. 키워드는 time complexity를 줄이기 위해, 무게와 물건 순서를 활용하는 것 다음에 다시 풀어봐야 할 것 같다. ","date":"2023-12-19T11:39:29+09:00","permalink":"https://srlee056.github.io/p/231219-12865/","title":"백준 : [Gold V] 평범한 배낭 - 12865"},{"content":"GitHub Link\n문제 설명 2×n 크기의 직사각형을 1×2, 2×1 타일로 채우는 방법의 수를 구하는 프로그램을 작성하시오.\n아래 그림은 2×5 크기의 직사각형을 채운 한 가지 방법의 예이다.\n입력 첫째 줄에 n이 주어진다. (1 ≤ n ≤ 1,000)\n출력 첫째 줄에 2×n 크기의 직사각형을 채우는 방법의 수를 10,007로 나눈 나머지를 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import sys def main(): n = int(sys.stdin.readline()) counts = {1: 1, 2: 2} for i in range(3, n + 1): counts[i] = (counts[i - 1] + counts[i - 2]) % 10007 print(counts[n]) if __name__ == \u0026#34;__main__\u0026#34;: main() CHECK! 딱히 어려운 점 없었음. 직사각형 하나를 가로로 두개 놓는 경우와, 세로로 하나 놓는 경우, 각각 2x(n-1), 2x(n-2) 크기의 직사각형을 채우는 방법의 수와 같게 됨 이를 dictionary 형태의 변수에 저장하는 형태로 구현함으로써 시간 복잡도를 줄임 ","date":"2023-12-19T11:39:23+09:00","permalink":"https://srlee056.github.io/p/231219-11726/","title":"백준 : [Silver III] 2×n 타일링 - 11726"},{"content":"GitHub Link\n문제 설명 정수 4를 1, 2, 3의 합으로 나타내는 방법은 총 7가지가 있다. 합을 나타낼 때는 수를 1개 이상 사용해야 한다.\n1+1+1+1 1+1+2 1+2+1 2+1+1 2+2 1+3 3+1 정수 n이 주어졌을 때, n을 1, 2, 3의 합으로 나타내는 방법의 수를 구하는 프로그램을 작성하시오.\n입력 첫째 줄에 테스트 케이스의 개수 T가 주어진다. 각 테스트 케이스는 한 줄로 이루어져 있고, 정수 n이 주어진다. n은 양수이며 11보다 작다.\n출력 각 테스트 케이스마다, n을 1, 2, 3의 합으로 나타내는 방법의 수를 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import sys def main(): test_cases = int(sys.stdin.readline()) for _ in range(test_cases): num = int(sys.stdin.readline()) counts = {1: 1, 2: 2, 3: 4} counts = counts_of_sum(counts, num) print(counts[num]) def counts_of_sum(counts, n): for i in range(4, n + 1): if i not in counts: counts[i] = counts[i - 1] + counts[i - 2] + counts[i - 3] return counts if __name__ == \u0026#34;__main__\u0026#34;: main() CHECK! 순서가 다르면 다른 경우로 체크하므로, 이에 대해서 판단할 필요가 없어서 편했음 합으로 나타낼 때 1+(n-1), 2+(n-2), 3+(n-3) 으로 경우를 나눌 수 있으므로, 이 세 경우를 합하면 됨 시간 복잡도를 위해 변수에 저장(dictionary에 저장했는데 이 경우엔 배열에 저장해도 충분할 것 같음)하여 계산을 진행 ","date":"2023-12-19T11:39:17+09:00","permalink":"https://srlee056.github.io/p/231219-9095/","title":"백준 : [Silver III] 1, 2, 3 더하기 - 9095"},{"content":" 📋 공부 내용 실습 로컬에서 이미지 빌드\nDocker Hub에 push\n다른 서버에서 다운로드 하여 실행\ndocker가 설치되어있는 서버를 4시간동안 제공해주는 사이트 https://labs.play-with-docker.com 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nInstall docker desktop on Ubuntu server 서버 사양 Google Cloud Compute Engine 머신 : n1-standard-4 4 vCPUs, 2 cores, 15GB memory 부팅 디스크 Ubuntu 22.04 LTS SSD 64GB 설치 과정 root 유저로 로그인\n1 sudo su install docker engine 링크 참고\nDEB package 다운로드\n1 2 3 curl -O https://desktop.docker.com/linux/main/amd64/docker-desktop-4.26.1-amd64.deb?utm_source=docker\u0026amp;utm_medium=webreferral\u0026amp;utm_campaign=docs-driven-download-linux-amd64 # 파일 이름에 쿼리가 붙어서 이상해진 경우에 이름 변경 필요함 mv docker-desktop-4.26.1-amd64.deb\\?utm_source\\=docker docker-desktop-4.26.1-amd64.deb 패키지 설치 링크 참고\n1 sudo apt-get install ./docker-desktop-4.26.1-amd64.deb 일반 유저로 빠져나와서 도커 권한설정 및 서비스 실행\n1 2 3 exit sudo usermod -aG docker ${USER} systemctl --user start docker-desktop Headless 환경에서 docker desktop을 실행할 수 있도록 설정\nHeadless server : GUI 환경이 존재하지 않는, User Interaction 기기가 없는? 그런 서버 ubuntu desktop을 설치하면 더 편하지만, 그렇게 하지 않고 다른 방법이 있다면 그걸로 진행해보고 싶었음 크롬 원격 데스크탑을 설치하고 설정하여 연결 진행 참고링크 xfce4 설치\n리눅스 및 유닉스 계열 운영 체제를 위한 가벼운 데스크탑 환경 1 sudo apt-get install xfce4 크롬 설치\n1 2 wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb sudo apt install ./google-chrome-stable_current_amd64.deb 크롬 데스크탑 설치 및 설정\n1 2 wget https://dl.google.com/linux/direct/chrome-remote-desktop_current_amd64.deb sudo apt install ./chrome-remote-desktop_current_amd64.deb 설정 1 vi ~/.chrome-remote-desktop-session 파일에 다음 추가 1 exec /usr/bin/xfce4-session 크롬 원격 데스크탑 서비스 실행 1 systemctl restart chrome-remote-desktop@$USER 크롬 원격 데스크탑 호스트 실행 및 연결\n실행 1 DISPLAY= /opt/google/chrome-remote-desktop/start-host --code=\u0026#34;4/0AfJohXmJq9WTMUqer6hYc5SHvw2-HH8XJBktdLdjEwjjqfTzxDb-Hnkh7XsTWVWintaZ7A\u0026#34; --redirect-url=\u0026#34;https://remotedesktop.google.com/_/oauthredirect\u0026#34; --name=$(hostname) 오류 발생\n[1218/052045.042357:ERROR:host_config.cc(83)] Failed to read /home/sarah/.config/chrome-remote-desktop/host#6d661ddc3145c41c372a1cce192c59c2.json\n권한 주고 재실행\n1 2 3 sudo chown -R sarah:sarah /home/sarah/.config/chrome-remote-desktop sudo chmod -R 755 /home/sarah/.config/chrome-remote-desktop systemctl --user restart chrome-remote-desktop VM 머신 위에선 docker desktop은 안되는 것 같음 포기하고 docker-desktop 삭제함 (ㅠ) ubuntu-desktop은 혹시 몰라서 남겨둠 nested vm 설정하면 된다는 말이 있어서 시도해봄 참고 링크 e2머신은 설정이 안돼서 n1, n2 중 비슷한 사양으로 골라서 진행 성공! killall -3 gnome-shell 으로 실행했을 때 activities 활성화 된 상태로 갖혀있게되는 문제 해결 overview 안뜨게 하는 extension 설치 ❗ 느낀 점 도커를 로컬에서 돌리기 어려운 환경이라, 이참에 도커를 설치한 서버를 만들어서 운영하자는 생각을 하고 있었다.\n처음에는 서버에 docker만 설치해서 진행 할 예정이었다. 그런데 Ubuntu 22.04 이상부터 docker desktop을 지원한다는 사실을 알게 되었고, GUI환경을 구성해서 docker desktop 프로그램으로 띄워보고싶은 욕망(ㅋㅋ)이 생겼다.\n코어타임 6시간 중 5시간 이상을 서버 설정하고 설치하는데 소모했는데, 여러 시행착오를 거쳤지만 결국 성공했다는게 너무 뿌듯하고 기분이 좋았다.\nkvm지원여부를 먼저 확인했다면 참 좋았을텐데\u0026hellip; 그랬다면 xfce4를 설치했다 지웠다 난리치고 그럴 일도 없었을텐데\u0026hellip; 참 아쉽지만 도커 데스크탑이 안되던 이유를 알고, nested visualization을 지원하는 머신으로 교체한 후 거짓말처럼 성공했기 때문에 잊으려고 한다.. (ㅠㅠ)\n이 과정 및 airflow 서버 구성 과정도 정리해서 블로그에 글을 올려볼까 한다. 누군가에겐 도움이 되겠지 ^^\n","date":"2023-12-18T12:21:18+09:00","permalink":"https://srlee056.github.io/p/day-46/","title":"Day 46 Docker(1)"},{"content":"GitHub Link\n문제 설명 다음 소스는 N번째 피보나치 수를 구하는 C++ 함수이다.\nint fibonacci(int n) { if (n == 0) { printf(\"0\"); return 0; } else if (n == 1) { printf(\"1\"); return 1; } else { return fibonacci(n‐1) + fibonacci(n‐2); } } fibonacci(3)을 호출하면 다음과 같은 일이 일어난다.\nfibonacci(3)은 fibonacci(2)와 fibonacci(1) (첫 번째 호출)을 호출한다. fibonacci(2)는 fibonacci(1) (두 번째 호출)과 fibonacci(0)을 호출한다. 두 번째 호출한 fibonacci(1)은 1을 출력하고 1을 리턴한다. fibonacci(0)은 0을 출력하고, 0을 리턴한다. fibonacci(2)는 fibonacci(1)과 fibonacci(0)의 결과를 얻고, 1을 리턴한다. 첫 번째 호출한 fibonacci(1)은 1을 출력하고, 1을 리턴한다. fibonacci(3)은 fibonacci(2)와 fibonacci(1)의 결과를 얻고, 2를 리턴한다. 1은 2번 출력되고, 0은 1번 출력된다. N이 주어졌을 때, fibonacci(N)을 호출했을 때, 0과 1이 각각 몇 번 출력되는지 구하는 프로그램을 작성하시오.\n입력 첫째 줄에 테스트 케이스의 개수 T가 주어진다.\n각 테스트 케이스는 한 줄로 이루어져 있고, N이 주어진다. N은 40보다 작거나 같은 자연수 또는 0이다.\n출력 각 테스트 케이스마다 0이 출력되는 횟수와 1이 출력되는 횟수를 공백으로 구분해서 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import sys # fib_print_zero = 1, 0, 1, 1, 2, .. # fib_print_one = 0, 1, 1, 2, 3, .. def fib_print(n): for i in range(2, n + 1): if i not in fib_prints: fib_prints[i] = [fib_prints[i - 1][1], sum(fib_prints[i - 1])] test_cases = int(sys.stdin.readline()) fib_prints = {0: [1, 0], 1: [0, 1]} for _ in range(test_cases): n = int(sys.stdin.readline()) fib_print(n) print(\u0026#34; \u0026#34;.join(map(str, fib_prints[n]))) CHECK! 시간 초과를 막기 위해 recursive하게 구현하지 않고, 값을 배열에 저장하는 형태로 구현 ","date":"2023-12-18T12:06:01+09:00","permalink":"https://srlee056.github.io/p/221218-1003/","title":"백준 : [Silver III] 피보나치 함수 - 1003"},{"content":"GitHub Link\n문제 설명 차세대 영농인 한나는 강원도 고랭지에서 유기농 배추를 재배하기로 하였다. 농약을 쓰지 않고 배추를 재배하려면 배추를 해충으로부터 보호하는 것이 중요하기 때문에, 한나는 해충 방지에 효과적인 배추흰지렁이를 구입하기로 결심한다. 이 지렁이는 배추근처에 서식하며 해충을 잡아 먹음으로써 배추를 보호한다. 특히, 어떤 배추에 배추흰지렁이가 한 마리라도 살고 있으면 이 지렁이는 인접한 다른 배추로 이동할 수 있어, 그 배추들 역시 해충으로부터 보호받을 수 있다. 한 배추의 상하좌우 네 방향에 다른 배추가 위치한 경우에 서로 인접해있는 것이다.\n한나가 배추를 재배하는 땅은 고르지 못해서 배추를 군데군데 심어 놓았다. 배추들이 모여있는 곳에는 배추흰지렁이가 한 마리만 있으면 되므로 서로 인접해있는 배추들이 몇 군데에 퍼져있는지 조사하면 총 몇 마리의 지렁이가 필요한지 알 수 있다. 예를 들어 배추밭이 아래와 같이 구성되어 있으면 최소 5마리의 배추흰지렁이가 필요하다. 0은 배추가 심어져 있지 않은 땅이고, 1은 배추가 심어져 있는 땅을 나타낸다.\n1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 입력 입력의 첫 줄에는 테스트 케이스의 개수 T가 주어진다. 그 다음 줄부터 각각의 테스트 케이스에 대해 첫째 줄에는 배추를 심은 배추밭의 가로길이 M(1 ≤ M ≤ 50)과 세로길이 N(1 ≤ N ≤ 50), 그리고 배추가 심어져 있는 위치의 개수 K(1 ≤ K ≤ 2500)이 주어진다. 그 다음 K줄에는 배추의 위치 X(0 ≤ X ≤ M-1), Y(0 ≤ Y ≤ N-1)가 주어진다. 두 배추의 위치가 같은 경우는 없다.\n출력 각 테스트 케이스에 대해 필요한 최소의 배추흰지렁이 마리 수를 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import sys test_cases = int(sys.stdin.readline()) d_x = [0, 0, 1, -1] d_y = [1, -1, 0, 0] for _ in range(test_cases): m, n, k = map(int, sys.stdin.readline().split()) points = [] for _ in range(k): point = list(map(int, sys.stdin.readline().split())) points.append(point) count = 0 orgin_points = points[:] while points: p = points.pop() neighbors = [p] count += 1 while neighbors: nb = neighbors.pop() if nb not in points and nb != p: continue # not crops elif nb in points: points.remove(nb) p_x, p_y = nb for i in range(4): if (p_x + d_x[i] \u0026gt;= 0 and p_x + d_x[i] \u0026lt; m) and ( p_y + d_y[i] \u0026gt;= 0 and p_y + d_y[i] \u0026lt; n ): neighbors.append([p_x + d_x[i], p_y + d_y[i]]) print(count) CHECK! 작물이 있는 좌표 중 하나를 골라 상하좌우 좌표를 리스트에 추가하고, 이 좌표에 작물이 있다면 전체 좌표 목록에서 빼는 방식으로 진행 .pop()으로 좌표를 하나 고르고 count += 1, 이 좌표와 인접한 그룹이 전체 목록에서 모두 제거되도록 코드 구현 이 때 인접 좌표 리스트(neighbors)에서 고른 좌표가 전체 좌표 목록에서 없거나 처음에 고른 작물의 좌표가 아니라면, 상하좌우 좌표를 추가하지 않고 그냥 continue로 pass함 ","date":"2023-12-18T12:05:48+09:00","permalink":"https://srlee056.github.io/p/221218-1012/","title":"백준 : [Silver II] 유기농 배추 - 1012"},{"content":"GitHub Link\n문제 설명 정수 X에 사용할 수 있는 연산은 다음과 같이 세 가지 이다.\nX가 3으로 나누어 떨어지면, 3으로 나눈다. X가 2로 나누어 떨어지면, 2로 나눈다. 1을 뺀다. 정수 N이 주어졌을 때, 위와 같은 연산 세 개를 적절히 사용해서 1을 만들려고 한다. 연산을 사용하는 횟수의 최솟값을 출력하시오.\n입력 첫째 줄에 1보다 크거나 같고, 106보다 작거나 같은 정수 N이 주어진다.\n출력 첫째 줄에 연산을 하는 횟수의 최솟값을 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import sys def update_counts(v, value_with_counts, count): old_count = value_with_counts.get(v, count) value_with_counts[v] = min(old_count, count) n = int(sys.stdin.readline()) value_with_counts = {n: 0} while value_with_counts: v = max(value_with_counts) c = value_with_counts.pop(v) if v \u0026lt;= 1: print(c) break if v % 3 == 0: update_counts(v // 3, value_with_counts, c + 1) elif v % 3 == 1: update_counts((v - 1) // 3, value_with_counts, c + 2) else: update_counts((v - 2) // 3, value_with_counts, c + 3) if v % 2 == 0: update_counts(v // 2, value_with_counts, c + 1) else: update_counts((v - 1) // 2, value_with_counts, c + 2) CHECK! 시간초과를 막기 위해, 3과 2로 나누어지지 않을 때는 나머지만큼 뺀 후 나누는 방식으로 진행 매번 1을 뺀 값을 리스트에 더하는 것 보다 경우의 수가 줄게 됨 중복된 코드 제거를 위해 update_counts 함수를 만듬 ","date":"2023-12-18T12:05:39+09:00","permalink":"https://srlee056.github.io/p/221218-1463/","title":"백준 : [Silver III] 1로 만들기 - 1463"},{"content":" 📋 공부 내용 OLTP 테이블 복사하기 Production MySQL Tables (OLTP) -\u0026gt; AWS Redshift (OLAP) MySQL Tables(Source) -\u0026gt; Airflow Server COPY Command : -\u0026gt; S3(Cloud Storage) -\u0026gt; Data Warehouse INSERT Command : -\u0026gt; Data Warehouse 실습 관련 설정 권한 설정 버킷과 DB 서버를 가진 계정에서 설정\n1. Airflow DAG에서 S3 접근 (Write 권한)\nIAM User를 생성 User에게 S3버킷에 대한 Read/Write 권한을 설정 User의 access key, secret key 사용 Custom Policy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::grepp-data-engineering\u0026#34;, \u0026#34;arn:aws:s3:::grepp-data-engineering/*\u0026#34; ] } ] } 2. Redshift에서 S3 접근 (Read 권한)\nRedshift에서 S3 접근할 수 있는 Role 생성 후 Redshift에 지정 Airflow Connection 설정 S3 : AWS type 선택 후 access key id, secret access key 입력 (Extra에 지역 입력)\nMySQL : 호스트, schema, id/pw, port 입력\nDB Tables MySQL(OLTP) Table 1 2 3 4 5 CREATE TABLE prod.nps ( id INT NOT NULL AUTO_INCREMENT primary key, created_at timestamp, score smallint ); Redshift(OLAP) Table DAG 실행 이전에 해당 테이블을 미리 생성해야 함 1 2 3 4 5 CREATE TABLE {schema}.nps ( id INT NOT NULL primary key, created_at timestamp, score smallint ); Full Refresh tasks in DAG 이미 작성되어있는 operator의 파라미터값만 작성하여 task를 생성\nIncremental Update도 같은 방식 사용\n1 2 from airflow.providers.amazon.aws.transfers.sql_to_s3 import SqlToS3Operator from airflow.providers.amazon.aws.transfers.s3_to_redshift import S3ToRedshiftOperator SqlToS3Operator\nMySQL SQL 결과 -\u0026gt; S3\n저장 위치 : s3://s3_bucket/s3_key (s3://grepp-data-engineering/{user_id}-nps)\nTask code\n1 2 3 4 5 6 7 8 9 10 11 12 mysql_to_s3_nps = SqlToS3Operator( task_id = \u0026#39;mysql_to_s3_nps\u0026#39;, query = \u0026#34;SELECT * FROM prod.nps\u0026#34;, s3_bucket = s3_bucket, s3_key = s3_key, #{schema} - {table} sql_conn_id = \u0026#34;mysql_conn_id\u0026#34;, aws_conn_id = \u0026#34;aws_conn_id\u0026#34;, verify = False, replace = True, #파일이 이미 존재하면 덮어씀 pd_kwargs={\u0026#34;index\u0026#34;: False, \u0026#34;header\u0026#34;: False}, #index, header를 제외하고 copy dag = dag ) S3ToRedshiftOperator\nS3 -\u0026gt; Redshift 테이블 ( Redshift : {schema}.nps )\nCOPY command is used\nTask code\n1 2 3 4 5 6 7 8 9 10 11 12 s3_to_redshift_nps = S3ToRedshiftOperator( task_id = \u0026#39;s3_to_redshift_nps\u0026#39;, s3_bucket = s3_bucket, s3_key = s3_key, schema = schema, table = table, copy_options=[\u0026#39;csv\u0026#39;], # file type : csv method = \u0026#39;REPLACE\u0026#39;, # REPLACE : 테이블이 이미 존재하면 덮어씀 (full refresh) redshift_conn_id = \u0026#34;redshift_dev_db\u0026#34;, aws_conn_id = \u0026#34;aws_conn_id\u0026#34;, dag = dag ) Incremental Update MySQL/PostgreSQL Table 조건 created(timestamp) : Optional modified(timestamp) deleted(boolean) : 레코드를 삭제하지 않고 deleted = True 구현 방식 1. ROW_NUMBER로 직접 구현\nRedshift의 A 테이블을 temp_A 테이블로 복사 MySQL의 A 테이블 레코드 중 modified == execution_date(지난 일)인 모든 레코드를 temp_A로 복사 MySQL에 다음 쿼리를 보내고 결과를 파일로 저장. S3로 업로드하고 COPY 수행 1 2 3 SELECT * FROM A WHERE DATE(modified) = DATE(execution_date) temp_A의 레코드들을 primary key를 기준으로 파티션한 다음, modified 값을 기준으로 DESC 정렬 일련번호가 1인 것들만 다시 A로 복사 2. UPSERT 사용 (실습에서 사용)\nS3ToRedshiftOperator로 구현\nquery 파라미터 1 2 3 SELECT * FROM A WHERE DATE(modified) = DATE(execution_date) method 파라미터 : “UPSERT” upsert_keys 파라미터 : Primary key nps 테이블이라면 “id” 필드를 사용 tasks in DAG SqlToS3Operator\n'{{ execution_date }}' 를 쿼리 sql에 넣음으로서 airflow가 넘겨주는 execution date 값을 활용할 수 있음 여기에서 modified가 아니라 created_at인 이유는 애초에 테이블에 modified컬럼이 존재하지 않기 때문 1 2 3 4 5 6 7 8 9 10 11 12 mysql_to_s3_nps = SqlToS3Operator( task_id = \u0026#39;mysql_to_s3_nps\u0026#39;, query = \u0026#34;SELECT * FROM prod.nps WHERE DATE(created_at) = DATE(\u0026#39;{{ execution_date }}\u0026#39;)\u0026#34;, # query 파라미터에 새로 생성된 데이터만 가져오도록 sql을 입력 s3_bucket = s3_bucket, s3_key = s3_key, sql_conn_id = \u0026#34;mysql_conn_id\u0026#34;, aws_conn_id = \u0026#34;aws_conn_id\u0026#34;, verify = False, replace = True, pd_kwargs={\u0026#34;index\u0026#34;: False, \u0026#34;header\u0026#34;: False}, dag = dag ) S3ToRedshiftOperator\n1 2 3 4 5 6 7 8 9 10 11 12 13 s3_to_redshift_nps = S3ToRedshiftOperator( task_id = \u0026#39;s3_to_redshift_nps\u0026#39;, s3_bucket = s3_bucket, s3_key = s3_key, schema = schema, table = table, copy_options=[\u0026#39;csv\u0026#39;], redshift_conn_id = \u0026#34;redshift_dev_db\u0026#34;, aws_conn_id = \u0026#34;aws_conn_id\u0026#34;, method = \u0026#34;UPSERT\u0026#34;, # UPSERT 방식으로 테이블을 수정 upsert_keys = [\u0026#34;id\u0026#34;], # 이 테이블의 primary key를 기준으로 upsert를 진행 dag = dag ) 실습 진행 Full Refresh 테스트해보기\n1 airflow dags test MySQL_to_Redshift 실행되는 sql query 1 2 3 4 5 COPY imsolem1226.nps FROM \u0026#39;s3://grepp-data-engineering/imsolem1226-nps\u0026#39; credentials \u0026#39;aws_access_key_id=xxx;aws_secret_access_key=xxx\u0026#39; csv; 실행 성공 후 Redshift에 저장된 데이터 확인 Incremental Update (Upsert) 테스트해보기\n1 airflow dags test MySQL_to_Redshift_v2 실행되는 sql query 1 2 3 4 5 6 7 8 COPY # FROM \u0026#39;s3://grepp-data-engineering/imsolem1226-nps\u0026#39; credentials \u0026#39;aws_access_key_id=xxx;aws_secret_access_key=xxx\u0026#39; csv; -- 임시 테이블과 id가 같은 데이터들(중복된 데이터들)을 모두 지우고, 임시 테이블의 데이터만 다시 추가한다 DELETE FROM imsolem1226.nps USING #nps WHERE nps.id = #nps.id; INSERT INTO imsolem1226.nps SELECT * FROM #nps; Backfill 실행 데이터를 여러번 다시 읽어와야 하는 경우 한번에 하나씩 vs. 한번에 여러개씩 동시에 여러 요청이 들어가게 되면 데이터 소스 쪽에 문제가 발생 데이터 읽기를 전담으로 하는 worker를 만들어 두는 방식으로 분산하여 해결 데이터 쓰기는 main(master?)에서 진행 여러 날짜의 데이터를 읽어오는 프로세스가 동시에 실행되는 경우, 데이터 덮어쓰기 등 문제 발생 하나씩 실행하는것이 안전 : max_active_runs(DAG parameter)를 1로 세팅(?) Command Line 1 airflow dags backfill dag_id -s 2018-07-01 -e 2018-08-01 catchUp : True로 execution_date을 사용해서 Incremental update가 구현되어 있음 start_date부터 시작하지만 end_date은 포함하지 않음 실행순서는 랜덤 (날짜, 시간 순 X) 날짜순으로 하고 싶다면 DAG default_args의 depends_on_past를 True로 설정 1 2 3 default_args = { \u0026#39;depends_on_past\u0026#39;: True, ... How to Make Your DAG Backfill ready 모든 DAG가 backfill을 필요로 하지는 않음\nFull Refresh를 한다면 backfill은 의미가 없음 Incremental Update를 해도, 마지막 업데이트 시간 기준 backfill을 하는 경우에는 execution_date을 이용한 backfill은 필요하지 않음 (Data Warehouse 테이블에 기록된 시간 기준) backfill 구현 상황 및 요건\n데이터가 굉장히 커지면 backfill 기능 구현은 필수 airflow를 활용하는것이 많이 도움됨 데이터 소스가 backfill 방식을 지원하는것이 제일 중요 backfill을 어떻게 구현할 것인가?\nexecution_date을 사용해서 업데이트할 데이터 결정 catchup 필드를 True로 설정 start_date/end_date을 backfill하려는 날짜로 설정 DAG를 구현할 때 execution_date을 고려해야 하며, idempotent 해야함 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-12-15T12:53:19+09:00","permalink":"https://srlee056.github.io/p/day-45/","title":"Day 45 Airflow(4)"},{"content":"GitHub Link\n문제 설명 선영이는 주말에 할 일이 없어서 새로운 언어 AC를 만들었다. AC는 정수 배열에 연산을 하기 위해 만든 언어이다. 이 언어에는 두 가지 함수 R(뒤집기)과 D(버리기)가 있다.\n함수 R은 배열에 있는 수의 순서를 뒤집는 함수이고, D는 첫 번째 수를 버리는 함수이다. 배열이 비어있는데 D를 사용한 경우에는 에러가 발생한다.\n함수는 조합해서 한 번에 사용할 수 있다. 예를 들어, \"AB\"는 A를 수행한 다음에 바로 이어서 B를 수행하는 함수이다. 예를 들어, \"RDD\"는 배열을 뒤집은 다음 처음 두 수를 버리는 함수이다.\n배열의 초기값과 수행할 함수가 주어졌을 때, 최종 결과를 구하는 프로그램을 작성하시오.\n입력 첫째 줄에 테스트 케이스의 개수 T가 주어진다. T는 최대 100이다.\n각 테스트 케이스의 첫째 줄에는 수행할 함수 p가 주어진다. p의 길이는 1보다 크거나 같고, 100,000보다 작거나 같다.\n다음 줄에는 배열에 들어있는 수의 개수 n이 주어진다. (0 ≤ n ≤ 100,000)\n다음 줄에는 [x1,...,xn]과 같은 형태로 배열에 들어있는 정수가 주어진다. (1 ≤ xi ≤ 100)\n전체 테스트 케이스에 주어지는 p의 길이의 합과 n의 합은 70만을 넘지 않는다.\n출력 각 테스트 케이스에 대해서, 입력으로 주어진 정수 배열에 함수를 수행한 결과를 출력한다. 만약, 에러가 발생한 경우에는 error를 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def process_elements(funcs, elements, is_reversed): left, right = 0, len(elements) - 1 for func in funcs: if func == \u0026#34;R\u0026#34;: is_reversed = not is_reversed elif func == \u0026#34;D\u0026#34;: if is_reversed: right -= 1 else: left += 1 if left \u0026gt; right + 1: return \u0026#34;error\u0026#34; else: result = elements[left : right + 1] if is_reversed: result.reverse() return \u0026#34;[\u0026#34; + \u0026#34;,\u0026#34;.join(map(str, result)) + \u0026#34;]\u0026#34; def main(): num_of_tests = int(input()) for i in range(num_of_tests): funcs = input() num_of_elements = int(input()) elements = map(int, input()[1:-1].split(\u0026#34;,\u0026#34;)) if num_of_elements != 0: elements = list(elements) else: elements = [] print(process_elements(funcs, elements, False)) if __name__ == \u0026#34;__main__\u0026#34;: main() CHECK! 함수로 나누는 과정에서 변수의 초기값 선언을 대신해줌으로써 코드가 간결해지고 보기 편해짐\ndeque를 사용했는데, 사용하지 않아도 시간 안에 잘 돌아감 결국 코드를 어떻게 구현하냐의 문제인 것 같음\n순서를 매번 뒤집지 않고, R, D 명령에 따라 뒤집혔는지 여부와 각 경우에 따라 어느쪽에서 배열의 요소를 삭제하는지 등을 변수에 저장 한 후, 마지막에 배열을 뒤집거나 slicing하는 작업을 한번만 진행한다. 이러면 time complexity가 적어지는것을 볼 수 있음\ntime complexity : test case - t, funcs 길이 p, elements 갯수 n 이라고 한다면\nO(t * (p+n)) 정도 일 것 같다.\n전체 테스트 케이스에 주어지는 p, n의 합은 70만을 넘지 않는다고 했으므로, 결국 t*(p+n) \u0026lt;= 70만\n결국 O(1)으로 수렴하게 될 것 같다. 70만을 O(1)이라고 해도 되는지는 잘 모르겠지만\u0026hellip;\n","date":"2023-12-15T11:26:18+09:00","permalink":"https://srlee056.github.io/p/221215-5430/","title":"백준 : [Gold V] AC - 5430"},{"content":"GitHub Link\n문제 설명 한 개의 회의실이 있는데 이를 사용하고자 하는 N개의 회의에 대하여 회의실 사용표를 만들려고 한다. 각 회의 I에 대해 시작시간과 끝나는 시간이 주어져 있고, 각 회의가 겹치지 않게 하면서 회의실을 사용할 수 있는 회의의 최대 개수를 찾아보자. 단, 회의는 한번 시작하면 중간에 중단될 수 없으며 한 회의가 끝나는 것과 동시에 다음 회의가 시작될 수 있다. 회의의 시작시간과 끝나는 시간이 같을 수도 있다. 이 경우에는 시작하자마자 끝나는 것으로 생각하면 된다.\n입력 첫째 줄에 회의의 수 N(1 ≤ N ≤ 100,000)이 주어진다. 둘째 줄부터 N+1 줄까지 각 회의의 정보가 주어지는데 이것은 공백을 사이에 두고 회의의 시작시간과 끝나는 시간이 주어진다. 시작 시간과 끝나는 시간은 231-1보다 작거나 같은 자연수 또는 0이다.\n출력 첫째 줄에 최대 사용할 수 있는 회의의 최대 개수를 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from collections import deque def main(): num_of_meetings = int(input()) meetings = [] for i in range(num_of_meetings): meeting = map(int, input().split()) meetings.append(list(meeting)) meetings = deque(sorted(meetings, key=lambda x: (x[1], x[0]))) prev_meeting = meetings.popleft() count = 1 while meetings: meeting = meetings.popleft() if meeting[0] \u0026gt;= prev_meeting[1]: prev_meeting = meeting count += 1 print(count) if __name__ == \u0026#34;__main__\u0026#34;: main() CHECK! 큰 데이터에 대해 속도를 빠르게 하기 위해 deque를 사용했다. greedy 알고리즘으로, 끝나는 시간이 빠른 순서 -\u0026gt; 시작하는 시간이 빠른 순서로 정렬하여 가장 위에부터 가능한 미팅을 선택하는 방식을 적용했다. ","date":"2023-12-14T18:07:11+09:00","permalink":"https://srlee056.github.io/p/221214-1931/","title":"백준 : [Silver I] 회의실 배정 - 1931"},{"content":" 📋 공부 내용 Airflow 실습 : DAG 구현하기 Primary Key Uniqueness 보장하기 퀴즈 1 2 3 4 5 6 7 8 # Weather_to_Redshift_v2.py INSERT INTO {schema}.{table} SELECT date, temp, min_temp, max_temp FROM ( SELECT *, ROW_NUMBER() OVER (PARTITION BY date ORDER BY created_date DESC) seq FROM t ) WHERE seq = 1; 여기서 transaction으로 처리되어야 하는 최소 범위의 SQL들은?\nUpsert Insert \u0026amp; Update\nprimary key를 기준으로 존재하는 레코드라면, 새 정보로 수정 존재하지 않는 레코드라면 새 레코드 적재 DW마다 UPSERT를 효율적으로 실행해주는 문법을 지원해줌 Backfill 데이터를 읽어오는 데 실패하거나, 읽어온 데이터의 문제 때문에 데이터 파이프라인을 재실행하여 다시 읽어와야 하는 과정\nIncremental Update 실패 하루에 한 번 동작하는 incremental update 중간에 며칠동안 이 과정이 실패한 경우, 그 이후의 실행에도 영향을 주게 되어있음 실패한 부분을 재실행 -\u0026gt; 얼마나 중요한가? Backfill의 용이성 실패한 데이터 파이프라인의 재실행이 얼마나 용이한 구조인가?\nfull refresh\n문제가 생기면 다시 실행하면 됨 backfill 불필요 Incremental Update\n데이터를 다시 읽어와야 하면 처음부터 모두 다 재실행해야 함 ( 효율성은 더 좋을 수 있지만, 운영\u0026amp;유지보수가 어려워짐) backfill 필요 Airflow : backfill을 쉽게 할 수 있도록 디자인됨\nBackfill of Daily DAG Daily DAG 지금 시간을 기준으로 어제 날짜를 계산, 어제 데이터를 읽어옴\n매일 문제 없이 동작하면 OK, BUT 데이터 읽어오기에 실패하는 경우 ? -\u0026gt; 특정 날짜의 데이터가 빠져있음 -\u0026gt; 실패한 날 기준으로 전날의 데이터를 업데이트 하는 코드를 새로 작성해야 함 (원하는 날짜를 하드코딩하는 방식)\n1 2 3 4 from datetime import datetime, timedelta # y = datetime.now() - timedelta(1) # yesterday = datetime.strftime(y, \u0026#39;%Y-%m-%d\u0026#39;) yesterday = \u0026#39;2023-01-01\u0026#39; 실수하기 쉽고 수정하는 데 시간이 많이 걸림\nDAG를 생성할 때 부터 backfill을 쉽게 만들어야 함\nBackfill을 용이하게 하는 구조 날짜별로 backfill 결과를 기록 날짜는 시스템에서 ETL 인자로 제공 날짜를 따로 계산하지 않고, 시스템이 정해준 날짜를 사용 Airflow의 구조 ETL별로 실행날짜, 결과를 메타데이터 DB에 기록 모든 DAG 실행에 execution_date 지정 execution_date를 바탕으로 데이터를 갱신하도록 코드 작성 DAG Parameter date 관련 parameter 정리\nAirflow 스케쥴링 schedule_interval이 지난 이후에, execution_date 기준으로 실행이 된다.\nstart_date : 2023-12-01 00:00:00\nInterval execution_date 실행 날짜 1 day 2023-12-01 2023-12-02 2023-12-02 2023-12-03 1 hour 2023-12-01 01:00:00 2023-12-01 02:00:00 10 minutes 2023-12-01 00:20:00 2023-12-01 00:30:00 참고 : https://it-sunny-333.tistory.com/157\nstart_date 처음 읽어와야 하는 데이터의 날짜\n2020-11-07의 데이터를 읽어옴\n2020-11-08 부터 ETL 동작\n-\u0026gt; start_date : 2020-11-07\nexecution_date 읽어와야 하는 데이터의 날짜\n2020-11-08 ETL 동작\n-\u0026gt; execution_date : 2020-11-07\n2023-12-14 ETL 동작 -\u0026gt; execution_date : 2023-12-13 (start_date : 2020-11-07)\ncatchup DAG 활성화 시점 \u0026gt; start_date\n그 사이 기간동안 실행되지 않은 job을 어떻게 할 지 정하는 파라미터\nTrue: 디폴트값, 실행되지 않은 job을 모두 실행하여 따라잡으려고 함 False: 실행되지 않은 job을 무시함 잘 모르면 항상 False로 세팅! 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nopenweathermap api https://openweathermap.org/api/one-call-3 구독한 이후에 바로 허가가 안되는 문제가 있음.. 기존 코드를 2.5 -\u0026gt; 3.0 으로 바꿔야 함 퀴즈 DAG 작성 과제 Code : GitHub Link\nUpdateSymbol_v2의 Incremental Update 방식 수정해보기\n앞서 배운 ROW_NUMBER 방식을 사용해서 Primary key가 동일한 레코드들을 처리하기\n1 2 3 4 5 6 7 alter_sql = f\u0026#34;\u0026#34;\u0026#34;DELETE FROM {schema}.{table}; INSERT INTO {schema}.{table} SELECT date, \u0026#34;open\u0026#34;, high, low, close, volume FROM ( SELECT *, ROW_NUMBER() OVER (PARTITION BY date ORDER BY created_date DESC) seq FROM t ) WHERE seq = 1;\u0026#34;\u0026#34;\u0026#34; Incremental Update가 진행됐는지 확인하기 위해, 어제 데이터를 저장한 stock_info_v2의 레코드를 복사해왔고, created_date를 어제로 지정했다.\nUpdate 이전\nUpdate 이후\n새로 레코드가 하나 추가됐으며, created_date가 DAG 실행 시간으로 변경된것을 볼 수 있다.\ngcp sdk 활용해서 서버\u0026lt;-\u0026gt;로컬 파일 통신 1 gcloud compute scp {option} {from_path} {to_path} 다운로드 (서버 -\u0026gt; 로컬) 서버쪽 폴더 안의 모든 파일을 전부 다운로드 1 gcloud compute scp --recurse \u0026#34;airflow-test\u0026#34;:/var/lib/airflow/dags ~/github-repo/dags 업로드 (로컬 -\u0026gt; 서버) 권한이 있어야 업로드 가능 -\u0026gt; root@ 로컬 특정 파일을 서버쪽 폴더 안으로 업로드 1 gcloud compute scp ~/github-repo/dags/{filename} root@\u0026#34;airflow-test\u0026#34;:/var/lib/airflow/dags airflow 유저에 업로드한 파일에 대한 권한이 없어서, chmor 664 {filename} 으로 수정 권한 부여함 vscode remote ssh 관련 문제 GCP Vm instance의 RAM은 2GB인데, 이 중 airflow 프로세스가 1.3GB정도를 차지함 vscode를 위한 ssh server도 1GB정도 필요함 그래서 vscode remote ssh로 연결하고 있으면 자꾸 멈추고 airflow 웹 서버가 잘 안돌아가는 등 문제가 있었던 것 RAM 증설하기로 결정 (어차피 오래 사용할 것 아니고 무료 크레딧이라 괜찮) ❗ 느낀 점 알고리즘 문제 풀 때 함수별로 나누는 습관, 주석 적는 습관 만들어보기 다음 질문에 대해 생각/찾아보기 DAG에서 같은 함수, task를 여러번 호출 할 수 있는가 @task 외에 다른 decorator 있는지 찾아보기 과제에서 기존 created_date를 가져오지 않고 새로 레코드를 만들 때 생성하는 이유는 뭘까? ","date":"2023-12-14T12:07:41+09:00","permalink":"https://srlee056.github.io/p/day-44/","title":"Day 44 Airflow(3)"},{"content":"GitHub Link\n문제 설명 오민식 선생님은 올해 형택초등학교 6학년 1반 담임을 맡게 되었다. 오민식 선생님은 우선 임시로 반장을 정하고 학생들이 서로 친숙해진 후에 정식으로 선거를 통해 반장을 선출하려고 한다. 그는 자기반 학생 중에서 1학년부터 5학년까지 지내오면서 한번이라도 같은 반이었던 사람이 가장 많은 학생을 임시 반장으로 정하려 한다.\n그래서 오민식 선생님은 각 학생들이 1학년부터 5학년까지 몇 반에 속했었는지를 나타내는 표를 만들었다. 예를 들어 학생 수가 5명일 때의 표를 살펴보자.\n1학년 2학년 3학년 4학년 5학년 1번 학생 2 3 1 7 3 2번 학생 4 1 9 6 8 3번 학생 5 5 2 4 4 4번 학생 6 5 2 6 7 5번 학생 8 4 2 2 2 위 경우에 4번 학생을 보면 3번 학생과 2학년 때 같은 반이었고, 3번 학생 및 5번 학생과 3학년 때 같은 반이었으며, 2번 학생과는 4학년 때 같은 반이었음을 알 수 있다. 그러므로 이 학급에서 4번 학생과 한번이라도 같은 반이었던 사람은 2번 학생, 3번 학생과 5번 학생으로 모두 3명이다. 이 예에서 4번 학생이 전체 학생 중에서 같은 반이었던 학생 수가 제일 많으므로 임시 반장이 된다.\n각 학생들이 1학년부터 5학년까지 속했던 반이 주어질 때, 임시 반장을 정하는 프로그램을 작성하시오.\n입력 첫째 줄에는 반의 학생 수를 나타내는 정수가 주어진다. 학생 수는 3 이상 1000 이하이다. 둘째 줄부터는 1번 학생부터 차례대로 각 줄마다 1학년부터 5학년까지 몇 반에 속했었는지를 나타내는 5개의 정수가 빈칸 하나를 사이에 두고 주어진다. 주어지는 정수는 모두 1 이상 9 이하의 정수이다.\n출력 첫 줄에 임시 반장으로 정해진 학생의 번호를 출력한다. 단, 임시 반장이 될 수 있는 학생이 여러 명인 경우에는 그 중 가장 작은 번호만 출력한다.\n풀이 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def main(): num_of_students = int(input()) groups = [] for i in range(num_of_students): group = map(int, input().split()) groups.append(list(group)) common_groups = {} for year_idx in range(5): temp_group_dict = {} for student_idx in range(num_of_students): group_num = groups[student_idx][year_idx] temp_group_dict[group_num] = temp_group_dict.get(group_num, []) temp_group_dict[group_num].append(student_idx) for group_num, students in temp_group_dict.items(): for student in students: common_groups[student] = common_groups.get(student, set()) common_groups[student].update(students) max_len = max(len(v) for v in common_groups.values()) max_len_students = [k for k, v in common_groups.items() if len(v) == max_len] max_len_students.sort() print(max_len_students[0] + 1) if __name__ == \u0026#34;__main__\u0026#34;: main() CHECK! 같은 반이 된 횟수가 많은 사람이 아니라, 같은 반이 된 친구가 많은 사람이 임시 반장이 되는 것이 포인트.\n예를 들어, 1번 학생이 2번 학생과 5년 내내 같은 반을 했고, (5회, 1명) 3번 학생이 1, 2번 학생과 각각 1년씩 같은 반을 했을 때(2회, 2명) 임시 반장은 3번 학생이다.\n그 외에도 모두가 같은 반을 해본 적 없거나, 학생 수가 1명일 때 등 여러 경우에 대한 예외처리를 잘 해야 한다.\n","date":"2023-12-14T11:33:02+09:00","permalink":"https://srlee056.github.io/p/221214-1268/","title":"백준 : [Bronze I] 임시 반장 정하기 - 1268"},{"content":"📋 공부 내용 Airflow 실습 context \u0026amp; xcom_pull Connections \u0026amp; Variables @task decorator DAG schedule Airflow 과제 과제 github\nairflow 실행 및 성공한 결과 화면 (코드 테스트 하느라 많이도 실패함)\nData warehouse에 연결하여 생성된 table 내용을 불러온 결과\n👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nSSH 연결 in vscode remote ssh 설치 f1 \u0026gt; connect to host 1 ssh -i {path_to_ssh_secret_key}/{key_name} user@ip /Users/{user_name}/.ssh/config root 유저로 접속하는 경우 config 파일 내용은 다음과 같다. 1 2 3 4 Host {ip} HostName {ip} IdentityFile {path_to_ssh_secret_key}/{key_name} User root ssh key 생성법 root user로 생성한 키 1 ssh-keygen -t rsa -f {key_name} -C root -b 2048 root user 로그인 방법 (feat. Google Cloud platform) 참고 링크 내용 그대로 따라하기 접속 시에는 기존 gcloud 커맨드에 root@ 붙여주면 됨 1 gcloud compute ssh --project root@your-project-id --zone your-zone your-instance-name SQL single quote in string insert into table_name values (\u0026lsquo;Seorim\u0026rsquo;s name\u0026rsquo;) -\u0026gt; 에러 발생\nreplace \u0026rsquo; to '\u0026rsquo;\n1 2 3 text = \u0026#34;Seorim\u0026#39;s name\u0026#34; text = text.replace(\u0026#34;\u0026#39;\u0026#34;, \u0026#34;\u0026#39;\u0026#39;\u0026#34;) # Seorim\u0026#39;s -\u0026gt; Seorim\u0026#39;\u0026#39;s insert into table_name values (\u0026lsquo;Seorim\u0026rsquo;\u0026rsquo;s name\u0026rsquo;) -\u0026gt; 잘 실행되는걸 볼 수 있음 :\u0026gt;\n❗ 느낀 점 ","date":"2023-12-13T17:15:12+09:00","permalink":"https://srlee056.github.io/p/day-43/","title":"Day 43 Airflow(2)"},{"content":"📋 공부 내용 Airflow 실습 Google Compute Engine - VM instance 만들어서 사용 연결을 위한 google cloud sdk 설치 https://cloud.google.com/sdk/docs/downloads-interactive?hl=ko 1 2 3 4 5 6 7 8 9 # Google Cloud SDK 설치 curl https://sdk.cloud.google.com | bash exec -l $SHELL gcloud init # 구글 로그인 자동 진행됨 (구글 클라우드 계정으로 로그인 하면 됨) # VM 인스턴스에 SSH로 연결 gcloud compute ssh --project your-project-id --zone your-zone your-instance-name 우분투 vm instance 접속에 성공한 화면\nairflow 2.5.1 설치 https://github.com/keeyong/airflow-setup/blob/main/docs/Airflow%202%20Installation.md\n웹 브라우저에서 접속 확인\nvm instance -\u0026gt; 방화벽 -\u0026gt; http 접근 허용\nvpc - 방화벽 규칙 생성 -\u0026gt; 8080포트 접근 허용\n👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-12-12T12:47:43+09:00","permalink":"https://srlee056.github.io/p/day-42/","title":"Day 42 Airflow(1)"},{"content":" 📋 공부 내용 데이터 파이프라인 Data를 소스로부터 목적지로 복사하는 작업\n(Write code using)Python, Scalar SQL Query(DW or DL -\u0026gt; DW) 목적지 : (대부분)DATA WAREHOUSE 데이터 웨어하우스 구성 1 데이터 소스 --(다수의 ETL)--\u0026gt; 데이터 웨어하우스 --\u0026gt; 대시보드 다수의 ETL들 간의 순서를 정하고 주기적으로 실행해주는 프레임워크(=Airflow)가 필요해짐\nETL Extract, Transform and Load\nDate Pipeline, ETL, Data Workflow, DAG(in Airflow) ETL vs. ELT 용어 설명 및 데이터 흐름 ETL 데이터소스 -\u0026gt; 데이터 웨어하우스 데이터 엔지니어 ELT 데이터 웨어하우스(or 데이터 레이크) 내부, 새로운 데이터 생성 데이터 분석가 ELT 프로세스 SQL CTAS dbt : Data Build Tool (Done by Analytics Engineering) Data Lake vs. Data Warehouse 데이터 레이크 (Data Lake) 데이터 웨어하우스보다 몇배 더 큰 크기의 저장소 구조화 데이터 + 비구조화 데이터 보존 기한이 없는, 데이터를 원본으로 저장하는 저장소 데이터 웨어하우스 (Data Warehouse) 보존 기한이 있는, 구조화된 데이터를 저장하고 처리하는 저장소 시각화를 진행하는 BI툴의 백엔드로 연결 Data Lake \u0026amp; ELT Data Sources -\u0026gt; Data Lake(S3, GCS,..) -\u0026gt; Data Transforms(Spark, Athena,..) -\u0026gt; Data Warehouse(==Data Mart) Data Lake의 원본 데이터를 처리하여 Data Warehouse에 적재하는 과정도 ELT 데이터 파이프라인의 종류 Raw Data ETL Jobs (ETL) By Data Engineer 외부와 내부 데이터 소스를 읽어 데이터 포맷 변환 후 (데이터가 커지면 Spark 등 활용) 데이터 웨어하우스에 로드 Summary / Report Jobs (ELT) By Data Analyst\nAnalytics Engineer (DBT Tool)\nDW or DL에서 데이터를 읽고 다시 DW에 쓰는 과정\nRaw Data를 읽고 일종의 리포트나 써머리 형태의 정제된 테이블을 다시 만드는 용도\n특수한 형태 : AB 테스트 결과를 분석하는 데이터 파이프라인\nProduction Data Jobs DW에서 데이터를 읽어 다른 Storage에 쓰는 과정 (데이터 목적지가 외부 Storage)\n일반적인 타겟 스토리지\nCassandra/HBase/DynamoDB 등과 같은 NoSQL (ML과정에서 필요한 특정 피쳐를 미리 계산) MySQL과 같은 관계형 데이터베이스(OLTP, Production DB) Redis, Memcache와 같은 캐시 ElasticSearch와 같은 검색엔진 데이터 파이프라인을 만들 때 고려할 점 운영 중 발생하는 여러 문제들 데이터 파이프라인의 실패 버그 :\u0026lt; 데이터 소스의 문제 ex: 데이터 포맷 변환이 불가능하다면? 데이터 파이프라인들 간 의존도에 대한 이해 부족 특정 테이블의 이름을 바꾸거나, 컬럼을 드랍 하는 등 변경이 생기면 여기에 의존하는 다른 파이프라인에 문제가 생김 데이터 파이프라인 증가 -\u0026gt; 유지보수 비용 기하급수적으로 증가 데이터 소스 사이에 의존도가 생기면서 더욱 복잡해짐 ex: 마케팅 채널 정보가 업데이트 되지 않으면 이 관련 다른 모든 정보가 갱신되지 않음 더 많은 테이블을 관리해야함 Best Practices Full Refresh 가능하다면, 매번 통째로 전부 복사해서 테이블을 만들기 Incremental Update만 가능하다면? Incremental Update : 새로 생성되거나, 업데이트 된 레코드들만 읽어오는 방식 full refresh 할 만큼 충분한 시간이 있는가? 특정 시간을 기준으로 새로 생성되거나 업데이트 된 레코드만 지정해서 읽어올 수 있어야 함 멱등성(Idempotency) 보장 동일한 데이터 소스에 대해 파이프라인을 여러번 실행해도 최종 테이블 결과가 달라지지 않아야 함 ex: 중복 데이터 X 멱등성이 깨질 경우 데이터 품질에 문제가 발생 실패를 하더라도 멱등성이 깨지지 않도록 깔끔하게 실패해야 함 중요 포인트 : critical point들이 하나의 atomic action으로 실행이 되어야 함 (다같이 성공, 다같이 실패) SQL transaction Backfill 실패한 데이터 파이프라인을 다시 실행하는 과정이 쉬워야 함 full refresh : backfill이 쉬움 Airflow: backfill 데이터 파이프라인 입력, 출력을 명확하게 문서화하기 비즈니스 오너, 테크니컬 오너 명시하여 기록으로 남기기 비즈니스 오너 : 데이터를 요청한 사람 데이터 카탈로그 데이터 디스커버리 데이터 의존성때문에 발생하는 문제(데이터 리니지)를 해결할 때 필요 사용되지 않는 데이터를 주기적으로 삭제 테이블의 사용 여부를 주기적으로 확인 사용하지 않는 테이블을 찾고, 이 테이블을 생성하는 데이터 파이프라인을 삭제 사고 리포트(post-mortem report) 작성하기 동일한, 비슷한 사고가 재발하는 것을 방지 사고 원인을 이해하고, 방지하기 위한 액션 아이템이 중요 기술 부채 정도를 이야기하는 바로미터 중요 데이터 파이프라인의 입력과 출력을 체크 입력 레코드 수, 출력 레코드 수를 체크 써머리 테이블 작성, primary key uniqueness 보장 여부 체크 중복 레코드 체크 \u0026hellip; ETL 작성 실습 #TODO Airflow 소개 가장 많이 사용되는 데이터 파이프라인 프레임워크\n구성 설명 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-12-11T11:49:09+09:00","permalink":"https://srlee056.github.io/p/day-41/","title":"Day 41 Data pipeline"},{"content":"📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nSnowflake 오류 해결기 JOIN ON A like B + \u0026lsquo;%\u0026rsquo;\nA, B 칼럼 모두 문자열을 가지는 컬럼 + operator은 numeric value에 적용되기 때문에 이 과정에서 숫자로 변환하는 과정을 거치게 됨 -\u0026gt; 오류 발생 -\u0026gt; JOIN ON CONTAINS(A, B) 로 해결 ❗ 느낀 점 (한 일 정리) 저는 오늘 배송기간, 배송거리 두가지 키워드로 데이터를 분석하고 차트를 만들어봤습니다.\n평균 배송 기간은 수도권과 제주도 높게 나왔고, 배송 거리와 뚜렷한 상관관계는 없었습니다. 그래서 긴 배송기간을 갖는 루트의 특징에 생각해 봤고, 배송 물량이 많은 곳(수도권), 산간지역(제주도 등), 같은 지역으로의 배송 등 이라는 걸 파악할 수 있었습니다. 카테고리별로 나누어 bubble chart로 표시해봤습니다.\n배송기간별 배송건수 분포를 보면, 배송기간 1일이 제일 많은 다른 지역들과 다르게 제주도는 배송기간 2일에 제일 많은 배송이 이루어지는 것을 볼 수 있습니다.\n내일 구 단위까지 분석해보고, 기존과 같은 분석 외에도\n택배를 받기까지 가장 오래 걸리는 지역구 택배가 가장 많이 오가는 지역구 등을 분석해서 차트로 만들어 볼 생각입니다. ","date":"2023-12-07T11:39:01+09:00","permalink":"https://srlee056.github.io/p/day-39/","title":"Day 39"},{"content":"📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-12-06T17:35:40+09:00","permalink":"https://srlee056.github.io/p/day-38/","title":"Day 38"},{"content":"📋 공부 내용 GCS 데이터 추가 Load 각 팀원분들에게 메일으로 권한 부여 각각 데이터 파일을 GCS에 로드 Snowflake SQL TEST SQL 연습 및 테이블을 만들어보는 테스트를 진행하였다.\n필요한 추가 데이터 지역별, 연령별, 성별 별로 인구 수 데이터 지역별 행정동 코드 및 위도/경도 좌표 하나의 테이블로 합치거나, 다른 시트의 데이터를 불러올 수 있는 방법을 찾기 위도/경도 사이의 거리를 계산하는 함수를 작성하고 새롭게 파일을 만들기 지역별 시도 superset code 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-12-05T17:16:08+09:00","permalink":"https://srlee056.github.io/p/day-37/","title":"Day 37 프로젝트 2일차"},{"content":"📋 공부 내용 GCS (Google Cloud Storage) 버킷 생성 Scraping using requests 1년간의 데이터를 받아오는 함수 코드 Setting Session\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import requests s = requests.Session() headers = { ... \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\u0026#34;, \u0026#34;X-Requested-With\u0026#34;: \u0026#34;XMLHttpRequest\u0026#34;, ... } payload = { \u0026#34;account\u0026#34;: {myaccount}, \u0026#34;password\u0026#34;: {mypassword}, } Login with Session\n1 2 # session에 post로 login res = s.post(\u0026#34;https://kdx.kr/auth/autoLogin\u0026#34;, headers=headers, data=payload) Download file with login authentication\n1 2 # session에 get으로 파일 url 포함해서 request 보내고 데이터 받아옴 response = s.get(file_url, stream=True) Set download path to GCS bucket# Directly Download file to GCS\n1 2 3 4 5 6 7 8 9 10 # import google cloud library from google.cloud import storage # setting with bucket name storage_client = storage.Client() bucket_name = {mybucket} # 여기에 실제 버킷 이름을 입력하세요 bucket = storage_client.bucket(bucket_name) blob = bucket.blob(f\u0026#34;{filename}.csv\u0026#34;) blob.upload_from_string(response.content) Google Cloud 인증 정보 IAM 및 관리자 \u0026gt; 서비스 계정 \u0026gt; 서비스 계정 만들기\n액세스 권한 설정 (GCS에 객체를 생성할 수 있는 권한으로 설정) 키 생성 및 로컬에 저장\n~/.zshrc\n1 export GOOGLE_APPLICATION_CREDENTIALS=\u0026#34;/path/to/your/service-account-file.json\u0026#34; Snowflake Connect with GCS write SQL Code\nGCS Integration\nsnowflake\u0026rsquo;s GCS account object 생성됨 Make custom IAM Role\ncan read bucket, and CRUD objects in the bucket connect snowflake\u0026rsquo;s account with this custom Role Bulk Update with COPY Command 파일을 전부 테이블로 복사하는 방식 파일의 일부 컬럼만 골라서 복사하는 방식을 사용할 수 있다. 남아있는 무료 요금 확인하는 법 Superset ( preset.io ) Connect with Snowflake Security \u0026gt; Network policy\n👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-12-04T18:20:22+09:00","permalink":"https://srlee056.github.io/p/day-36/","title":"Day 36"},{"content":"📋 공부 내용 시각화 툴 KPI, 지표, 중요한 데이터 포인트들을 데이터 기반으로 계산/분석 표시해주는 툴\nDashboard or BI(Business Intelligence) Tool\n결정권자 : 데이터 기반 의사결정을 할 수 있음\n현업 종사자 : 데이터 분석을 쉽게 할 수 있음\nKPI : Key Performance Indicator\n데이터 기반 의사결정의 종류\n데이터 기반 결정 (Data-Driven Decision) 데이터 참고 결정 (Data-Informed Decision) Citizen Data Analyst / Scientist\nEDA : Exploratory Data Analysis\n데이터 특성 분석 어떤 시각화 툴이 있을까? 기업 Tools 특징 Excel\nGoogle Spreadsheet 가장 많이 쓰이는 시각화 툴 Python EDA에 더 적합 Google Looker Salesforce Tableau MS Power BI Apache Superset\nReDash 오픈소스 Mode Analytics Google Studio\nAWS Quicksight 자사 클라우드 기반의 Dashboard 기능이 비교적 떨어짐 Excel, Python 등은 코딩이 가능해야 활용 가능 -\u0026gt; 기능상의 제약 존재 Looker 2019.06 구글에 인수됨 특징 LookML이 자체 언어로 데이터 모델을 만들어줌 내부고객 뿐 아니라 외부 고객을 위한 대시보드 작성 가능 다른 사람이 작성한 Dashboard를 참고하여 내가 활용할 수 있음(Template 처럼) setup은 힘든 편, backend에 부하가 좀 있는 편 Tableau 2019.06 Salesforce에 인수됨 특징 다양한 제품군, 일부는 무료로 사용 가능 배우기 어렵지만 강력한 대시보드 -\u0026gt; 일부 전문가만 대시보드 작성 가능 Looker 뜨기 전까지 오랫동안 마켓 리더로 군림해옴 ReDash 2020 Databricks에 인수됨\n특징\n오픈소스로 시작, Superset과 흡사 SQL 에디터 존재 -\u0026gt; Dashboad와 연결된 곳에 Query를 보낼 수 있음 Superset이 Redash와 다른 점\nrole 기반 사용자 역할, 권한 지정 가능 dashboard에 역할 지정 가능 Mode Anlytics 특징 조금 더 기술적인 인력을 대상으로 하는 대시보드 SQL, R, Python 등으로 분석 가능 KPI 대시보드 보다는 EDA 툴에 더 가까움 시각화 툴 선택? Looker vs. Tableau\n둘 다 초반 learning curve 존재 Tableau: 가격적인 부분에 이점 Self Service Dashboard의 중요성\n매번 사람의 노동을 필요로 하지 않음 사용하기 쉬워야 더 많은 인력들이 직접 대시보드를 만들 수 있음 Data Democratization, Data Decentralization 데이터 품질의 중요성, 데이터 거버넌스가 필요한 이유 Supserset Airbnb에서 시작된 오픈소스, Maxim(Airflow 개발자)과 같이 시작 특징 다양한 형태의 시각화 쉬운 인터페이스 대시보드 공유 지원 엔더프라이즈 수준의 보안, 권한 제어 기능 제공 SQLALchemy 연동 -\u0026gt; 다양한 db(SQLAlchemy와 연동되는) 지원 Druid.io(streaming db)와 연동한 실시간 데이터의 시각화 가능 API, 플러그인 아키텍쳐 제공 -\u0026gt; 기능 확장이 쉬움 구조 Python으로 제작됨 Web Interface -\u0026gt; Flask \u0026amp; React JS metadata db : sqlite 병렬성이 떨어지는 단점 -\u0026gt; postgresql or mysql 사용 Redis를 caching layer로 사용하여 성능 최적화 용어 Database : backend db (Redshift, Druid, \u0026hellip;) Dataset : table Dashboard - Chart : Dashboard는 하나 이상의 chart로 구성됨 실습 Dashboard 구성 DB : Redshift 2 charts in 1 Dashboard 채널별 MAU(Monthly Active User) chart Dataset : analytics.user_session_summary Monthly Cohort chart Dataset : analytics.cohort_summary MAU chart session단으로 완전한 정보를 갖게 만든 테이블 1 2 3 4 CREATE TABLE analytics.user_session_summary AS SELECT usc.*, t.ts FROM raw_data.user_session_channel usc LEFT JOIN raw_data.session_timestamp t ON t.sessionid = usc.sessionid Monthly Cohort chart Cohort?\n특정 속성(보통은 사용자의 서비스 등록월)을 바탕으로 나뉜 사용자 그룹 Cohort 분석?\nCohort 기반으로 사용자의 이탈률, 잔존률, 총 소비금액 등을 계산 사용자 잔존률(Retention) : 보통 월 기반으로 시각화해서 봄 analytics.cohort_summary\n1 2 3 4 5 6 7 8 CREATE TABLE analytics.cohort_summary as SELECT cohort_month, visited_month, cohort.userid FROM ( SELECT userid, date_trunc(\u0026#39;month\u0026#39;, MIN(ts)) cohort_month FROM raw_data.user_session_channel usc JOIN raw_data.session_timestamp t ON t.sessionid = usc.sessionid GROUP BY 1 ) cohort JOIN ( SELECT DISTINCT userid, date_trunc(\u0026#39;month\u0026#39;, ts) visited_month FROM raw_data.user_session_channel usc JOIN raw_data.session_timestamp t ON t.sessionid = usc.sessionid ) visit ON cohort.cohort_month \u0026lt;= visit.visited_month and cohort.userid = visit.userid; Google Spreadsheet를 활용한 시각화 실습 +) Python gspread module을 활용하면 Python으로 스프레드시트 조작 가능\nMAU chart\nMonthly Cohort chart\nSuperset 사용 방법 preset.io 회원가입 workspace 생성 database 연결 docker docker 설치 및 활용 ram 크기 설정 (mac: 6GB 이상)\nSuperset Github repo를 클론\n1 git clone https://github.com/apache/superset.git superset 폴더로 들어가서 다음 두 command 실행\n1 2 3 4 5 cd superset # 특정 버전을 다운로드 하려면 아래 command 실행 # git checkout 1.4.0 docker-compose -f docker-compose-non-dev.yml pull docker-compose -f docker-compose-non-dev.yml up http://localhost:8088으로 웹 UI 로그인 (id : admin, pw : admin)\nRedshift db 연결 SQLAlchemy URI 를 통해 연결 가능\n1 postgresql://admin:xxxx@default-workgroup.705556746971.ap-northeast-2.redshift-serverless.amazonaws.com:5439/dev 연결된 db 정보 SQL Lab Redshift로 SQL 쿼리 보낼 수 있음\nMAU, Monthly Cohort chart를 위한 table을 생성\n설정\n사용하는 database에 DML 권한을 부여해야 함 MAU dataset \u0026amp; chart Cohort dataset \u0026amp; chart (추가) snowflake db 연결 입력 정보 ACCOUNT 확인 방법 (in Snowflake) HW - nps chart dataset\n이전 단계에서 연결시킨 snowflake db를 사용\nchart\nEdit dataset \u0026gt; Metrics \u0026gt; overal_nps item 추가\nchart 설정 및 결과 화면\nresult dashboard 👀 CHECK 용어 데이터 거버넌스 https://cloud.google.com/learn/what-is-data-governance?hl=ko (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들) 기타 preset.io 가입 google account로 가입 시 14일동안 Professional plan 무료 체험 가능 14일 이후에는 starter plan(free)로 변경되는 듯 함 ❗ 느낀 점 superset 대시보드를 써 보게 됐다. 내가 걱정? 우려했던 것 보다는 쉬웠다. snowflake도 그렇고 redshift도 그렇고 다들 UI가 편하고 깔끔해서 좋았다. docker를 쓰고 싶었는데 맥북 램이 8gb.. 다른 프로그램을 다 끄고 도커만 사용한다면 가능할 수도 있는데 그건 아니라 결국 preset.io 사이트에서 하게 됐다. preset.io 사이트는 어차피 superset 기반으로 한 사이트고 docker를 통해 구동하는것과 UI가 같아서 문제는 없을 것 같다.\n모각콩 참가자분들하고 한시간정도 대화하는 시간을 가졌는데 각자 갖고 있는 정보를 공유할 수 있어서 좋았다. 다들 어디서 그렇게 정보를 많이 얻는지 신기하다는 생각도 했다. ㅋㅋㅋ\n주말에는 주중에 배운것들 복습 할 겸 미리 세팅을 하려고 한다. 같은 팀 분들하고 상의를 해 봐야 하겠지만, superset-snowflake-s3(or google cloud) 를 활용하는 게 AWS의 요상한 청구 시스템 때문에 발생하는 부차적인 과금없이 무료 플랜으로만 진행할 수 있어 보인다. 그런데 snowflake credit 초과하면 결국은 과금을 해야겠지..?\n","date":"2023-12-01T11:54:04+09:00","permalink":"https://srlee056.github.io/p/day-35/","title":"Day 35 Superset Dashboard"},{"content":"📋 공부 내용 Snowflake 소개 클라우드 기반 데이터웨어하우스 \u0026ldquo;데이터 클라우드\u0026rdquo; 특징 가변비용 모델\nstorage, computing infra 별도 설정 가능 노드 수 조정, distkey(데이터 skew 문제) 등 조절 불필요 데이터 처리\nSQL 기반 빅데이터 처리 가능 비구조화 데이터 처리, ML 기능 제공 멀티클라우드\nAWS, GCP, Azure 과 같은 글로벌 클라우드 위에서 모두 동작(멀티클라우드) 다양한 포맷, 다양한 플랫폼의 클라우드 스토리지(S3, GC Cloud Storage 등) 지원 다른 지역 데이터 공유 (Cross-Region Replication) 기능 지원\nTime travel\n정의된 기간 내의 모든 시점에서 과거 데이터에 액세스할 수 있는 기능 오브젝트 복원, 과거 시점 데이터 복제 혹은 백업, 지정된 기간 동안 데이터 사용/조작 분석 등으로 활용 가능 Python API 제공\nSnowflake 계정 구성\nOrganizations 하나 혹은 그 이상의 Account로 구성됨 Accounts 하나 혹은 그 이상의 DB로 구성됨 Databases Account에 소속된 데이터를 다루는 컨테이너 Warehouse(컴퓨팅리소스)와 일대일 관계가 아님 (1 Warehouse - 4 Databases) Data Marketplace\nData Sharing\n\u0026ldquo;Share, Don\u0026rsquo;t Move\u0026rdquo;\nDataset을 Storage level에서 공유하는 방식\nActivity\nQuery/Copy/Task History 비용 컴퓨팅 비용 : Credit Credit : 쿼리 실행, 데이터 로드 등 작업 수행에 소비되는 리소스 단위 1 Credit = $2~$4 Snowflake Warehouse : 사용시간 당 크레딧 청구 스토리지 비용 TB 당 비용 청구 네트워크 비용 지역간, 또는 (다른)클라우드간 데이터 전송 시 TB 당 비용 청구 Data Governance 필요한 데이터가 적재적소에 올바르게 사용됨을 보장하기 위한 데이터 관리 프로세스\nObject Tagging Snowflake object에 태그를 지정할 수 있는 기능\nObject : Organization, Account, Schema, View, \u0026hellip;\n생성 : CREATE TAG Snowflake에서 기본적으로 제공하는 시스템 태그 존재 지정된 tag는 구조를 따라 계승됨 Data Classification Snowflake가 데이터를 자동으로 분류하여 태그를 지정해주는 기능\n\u0026lsquo;매뉴얼하게 관리하기가 어려운\u0026rsquo; Object Tagging의 단점을 보완해주기 위해 등장\nAnalyze : 테이블에서 개인정보나 민감정보가 있는 컬럼들을 분류 Review : 분류한 결과를 사람(데이터 엔지니어등)이 수정 등 리뷰 Apply : 최종 결과를 System Tag로 적용 SNOWFLAKE.CORE.PRIVACY_CATEGORY (상위레벨) IDENTIFIER, QUASI_IDENTIFIER, SENSITIVE SNOWFLAKE.CORE.SEMANTIC_CATEGORY (하위레벨 - 더 세부정보) 식별자와 준식별자 식별자(Identifier) : 개인을 바로 지칭할 수 있는 정보 준식별자(Quasi Identifier) : 조합을 통해 개인을 지칭할 수 있는 정보 PRIVACY_CATEGORY SEMANTIC_CATEGORY IDENTIFIER EMAIL, NAME, PHONE_NUMBER, \u0026hellip; QUASI_IDENTIFIER AGE, GENDER, \u0026hellip; Tag based Masking Policies 태그를 기반으로 유저와 그 권한을 지정하는 기능\nTag에 액세스 권한을 지정 Tag가 지정된 Snowflake Object의 액세스 권한을 그에 맞춰 제한하는 방식 개인정보와 같은 Tag에 액세스 권한을 부여하는 방식으로 많이 사용됨 Access History 데이터 액세스에 대한 기록을 제공하여 감사 추적을 가능하게 함으로써 보안과 규정 준수\n모든 클라우드 데이터 웨어하우스에서 제공되고 있는 기능\n'Access History' 데이터베이스 로그인, 실행된 쿼리, 테이블 및 뷰 액세스, 데이터 조작 작업 잠재적인 보안 위반이나 무단 액세스 시도의 조사를 가능하게 해줌 캡처된 정보 : 사용자 신원, IP 주소, 타임스탬프 및 기타 관련 세부 정보 포함 Object Dependencies 테이블이나 뷰 등 Object를 수정할 때 이로 인한 영향을 자동으로 식별하는 기능\n데이터 거버넌스와 시스템 무결성 유지를 목적으로 함\nex: 테이블 이름이나 컬럼 이름을 변경하거나 삭제하는 경우 계승 관계 분석을 통한 더 세밀한 보안 및 액세스 제어 어떤 테이블의 개인정보 컬럼이 새로운 테이블을 만들때 사용된다면? 원본 테이블에서의 권한 설정이 그대로 전파됨 (Tag 포함) Snowflake 활용 실습 계정 생성 무료 시험판 계정 생성\n무료계정은 별도의 로그인 링크를 통해 접속해야 함\n실습 코드 Schema 1 2 3 4 5 SNOWFLAKE DB \u0026amp; Schema dev ├─ raw_data ├─ analytics └─ adhoc db \u0026amp; schema 생성 1 2 3 4 5 6 -- create db and schema CREATE DATABASE dev; CREATE SCHEMA dev.raw_data; CREATE SCHEMA dev.analytics; CREATE SCHEMA dev.adhoc; table 생성 session_transaction, user_session_channel, session_timestamp 세 개의 테이블 생성 1 2 3 4 5 6 -- create tables CREATE OR REPLACE TABLE dev.raw_data.session_transaction ( sessionid varchar(32) primary key, refunded boolean, amount int ); s3 data 연결 S3 read 권한을 가진 IAM User 생성 \u0026amp; ACCESS KEY를 발급 COPY command로 데이터 파일에서 추출하여 저장 1 2 3 4 COPY INTO dev.raw_data.session_transaction FROM \u0026#39;s3://{s3-bucket-path}/session_transaction.csv\u0026#39; credentials=(AWS_KEY_ID=\u0026#39;\u0026#39; AWS_SECRET_KEY=\u0026#39;\u0026#39;) FILE_FORMAT = (type=\u0026#39;CSV\u0026#39; skip_header=1 FIELD_OPTIONALLY_ENCLOSED_BY=\u0026#39;\u0026#34;\u0026#39;); analytics schema에 테이블을 생성하고 데이터가 잘 불러와졌는지 확인 1 2 3 4 5 6 7 8 9 10 11 -- create a table using CTAS CREATE TABLE dev.analytics.mau_summary AS SELECT TO_CHAR(A.ts, \u0026#39;YYYY-MM\u0026#39;) AS month, COUNT(DISTINCT B.userid) AS mau FROM raw_data.session_timestamp A JOIN raw_data.user_session_channel B ON A.sessionid = B.sessionid GROUP BY 1 ORDER BY 1 DESC; SELECT * FROM dev.analytics.mau_summary LIMIT 10; Role \u0026amp; User 생성 1 2 3 4 5 6 7 8 9 10 -- create 3 roles CREATE ROLE analytics_users; CREATE ROLE analytics_authors; CREATE ROLE pii_users; -- create a user CREATE USER seorim PASSWORD=\u0026#39;xx\u0026#39;; -- grant role to user GRANT ROLE analytics_users to USER seorim; 각 ROLE의 권한 설정 1 2 3 4 5 6 7 8 9 10 11 12 13 -- set up analytics_users GRANT USAGE on schema dev.raw_data to ROLE analytics_users; GRANT SELECT on all tables in schema dev.raw_data to ROLE analytics_users; GRANT USAGE on schema dev.analytics to ROLE analytics_users; GRANT SELECT on all tables in schema dev.analytics to ROLE analytics_users; GRANT ALL on schema dev.adhoc to ROLE analytics_users; GRANT ALL on all tables in schema dev.adhoc to ROLE analytics_users; -- set up analytics_authors -- authors role이 users role의 권한 설정도 상속받게 됨 GRANT ROLE analytics_users TO ROLE analytics_authors; GRANT ALL on schema dev.analytics to ROLE analytics_authors; GRANT ALL on all tables in schema dev.analytics to ROLE analytics_authors; 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nSnowflake SQL https://docs.snowflake.com/en/guides-overview-queries \u0026ldquo;Snowflake supports standard SQL\u0026rdquo;, including a subset of ANSI SQL:1999 and the SQL:2003 analytic extensions. Snowflake also supports common variations for a number of commands where those variations do not conflict with each other.\nSnowflake Object Hierachy https://docs.snowflake.com/en/user-guide/security-access-control-overview ❗ 느낀 점 강의는 Snowflake에 대해 배우고, 간단하게 활용해보는 내용이었다. 전반적으로 어려운 건 없었다. notebook을 따로 써야하는(Colab or Jupyter) Redshift와는 다르게, 자체적으로 notebook 역할을 하는 worksheet를 제공한다. worksheet를 포함한 UI가 redshift를 사용할 때와 비교하면 더 편하고 깔끔해서 좋았다.\n오늘은 게더에서 모각코(모각공)을 해봤다. 화면 공유를 하면서 강의를 들으니까 원래보다 집중은 잘 됐는데, 아쉬운점은 같이 공부하는 느낌이 잘 안들더라. 어떻게 진행해야할지 고민이 좀 된다. 시간을 정해서 말을 걸거나 잘 안되는 걸 물어보면 어떨까? 모각코 참여하시는 분들하고 친해지고 싶은데 말 걸기가 쉽지 않아서 어떤 주제로 어떻게 얘기하면 좋을지 고민을 좀 해봐야겠다\u0026hellip;. ㅠㅜ\n","date":"2023-11-30T12:06:30+09:00","permalink":"https://srlee056.github.io/p/day-34/","title":"Day 34 Snowflake"},{"content":"📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-29T00:00:00Z","permalink":"https://srlee056.github.io/p/day-33/","title":"Day 33"},{"content":"TIL - 📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-22T15:32:21+09:00","permalink":"https://srlee056.github.io/p/day-28/","title":"Day 28"},{"content":" 블로그\nGitHub repo\nGitHub Pages GitHub Pages 공식 페이지\n“GitHub Pages is a static site hosting service that takes HTML, CSS, and JavaScript files straight from a repository on GitHub.”\n사용 이유 편리한 사이트 제작 및 관리\n도메인 및 호스팅 서비스를 직접 관리할 필요 없음 버전 관리 이점\n변경 이력을 기록할 수 있고 삭제 및 변경이 자유로움 다양한 예쁜 테마와 커스터마이징\nhttps://themes.gohugo.io/ 자유로운 Markdown 표현\nTistory, Velog 등 플랫폼에서 Markdown 문법이 원하는 형태로 표현되지 않아 생기는 불편함 극복\nhtml 문법 사용 가능\n정적 사이트 생성기 지킬과 휴고는 둘 다 정적 사이트 생성기지만, 다른 언어로 개발되었고 각자의 특징을 가지고 있습니다.\n지킬 (Jekyll) 장점 GitHub에서 기본적으로 지원되는 정적 사이트 생성기로, Ruby로 개발됐습니다. GitHub Pages에 호스팅할 때 추가적인 설정 없이 지킬을 사용할 수 있습니다. 플러그인이 다양하게 제공되어 확장성이 높습니다. 단점 Ruby 기반이기 때문에, Ruby 개발 환경이 필요하고 초기 설정이 복잡할 수 있습니다. 빌드 시간이 상대적으로 더 오래 걸릴 수 있습니다. 휴고 (Hugo) 장점 Go 언어로 개발되어 빠른 빌드 속도를 자랑합니다. 단순하고 직관적인 구조로 빠르게 사이트를 생성할 수 있습니다. 다양한 테마와 플러그인을 제공하며, 커스터마이징이 자유롭습니다. 단점 Go 언어로 개발되어 있어 Go 환경이 필요하며, Ruby나 다른 언어에 비해 커스터마이징이 조금 더 쉽지 않을 수 있습니다. 블로그 제작기 Hugo 셋업 Hugo Guidline - Quick start\n선행 패키지 및 언어 설치\n각자의 OS에 맞게 설치 : https://gohugo.io/installation/ Go Hugo 사이트 생성\nHugo 명령어를 사용하여 새로운 사이트를 생성합니다. hugo new site \u0026lt;사이트 이름\u0026gt; 1 hugo new site testsite 테마 연결\n선택한 테마를 다운로드하거나 Git submodule로 연결하여 사이트에 적용합니다. 1 2 3 cd testsite git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack config.toml 파일에 테마 설정을 추가합니다. 1 theme = \u0026#34;hugo-theme-stack\u0026#34; config\nconfig.toml 파일에서 설정을 변경할 수 있습니다. base URL 설정 : https://\u0026lt;username\u0026gt;.github.io or custom domain 1 baseURL = \u0026#34;https://srlee056.github.io\u0026#34; 한국어 설정 1 2 3 4 5 6 7 8 9 languageCode = \u0026#34;ko-KR\u0026#34; DefaultContentLanguage = \u0026#34;ko\u0026#34; ... [languages.ko] languageName = \u0026#34;Korean\u0026#34; title = \u0026#34;서림록\u0026#34; weight = 1 [languages.ko.params] description = \u0026#34;\u0026#34; 기타 설정 math : 수학 수식 표시 여부 toc : 목차 readingTime : 해당 글의 글자수를 기준으로 읽는 데 몇 분 정도 걸리는지 표시함 1 2 3 4 [params.article] math = false toc = true readingTime = false 서버 구동\nhugo server http://localhost:1313/ 글 템플릿 설정 archetypes 폴더 내에 .md 템플릿을 추가하여, 새 글을 발행할 때 템플릿으로 활용할 수 있습니다.\n‘til’ 템플릿과 그 내용\n새 글 발행 : --kind 커맨드로 template 적용\n1 hugo new content content/post/newpost.md --kind til 아바타, 파비콘 등 resource 위치 Avatar : assets/img/avatar.png\nhogo.toml Favicon: static/img/favicon.ico\nhugo.toml 글 속성 및 구조 url\n별도로 설정하지 않으면 title = url 1 2 title = \u0026#39;Blog 제작기 #2\u0026#39; url = \u0026#39;/Blog/blog-2\u0026#39; draft\n빌드 포함 여부 (true : 미포함) default.md(기본 template) 1 2 3 4 author = \u0026#34;Seorim\u0026#34; title = \u0026#39;{{ replace .File.ContentBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#39; date = {{ .Date }} draft = false structure\npost/\u0026lt;title\u0026gt;.md or post/\u0026lt;folder-name\u0026gt;/\u0026lt;title\u0026gt;.md or post/\u0026lt;title\u0026gt;/index.md 1 2 3 4 5 6 7 8 9 content ├─ post │ ├─ Blog │ │ └─ blog-2.md │ ├─ day-10 │ │ ├─ image.png │ │ └─ index.md │ └─ DevCourse └─ \\_index.md 이미지를 포함하는 글 구조\n글 본문에 이미지 삽입\nHosting Hugo Guidline - Host on GitHub Pages\nrepo 생성 및 연결 GitHub에서 .github.io 이름으로 새로운 레포지토리 생성 local Hugo site repository를 연결 command 1 git remote add origin \u0026lt;원격 저장소 URL\u0026gt; GitHub Actions 세팅 Settings \u0026gt; Pages\nBuild and Deployment 소스를 branch → GitHub Actions 변경 GitHub Actions - workflow 파일 생성\n.github/workflows/hugo.yaml\nActions \u0026gt; New workflow \u0026gt; hugo 검색 설정한대로 build\u0026amp;deploy 자동 실행\n느낀점 및 회고 블로그 제작 걱정한 것 보다 쉬웠고(3일 정도 소요) 블로그의 기능에 만족하며, 세부적으로 꾸미는 과정에 재미를 느끼고 있습니다. 2-버전 관리와 고민과 Markdown 표현에 대한 고민을 한번에 해결하게 되어 후련함을 느꼈습니다. 자동 배포 이해: GitHub Actions를 활용한 자동 배포를 경험하며 이해할 수 있었고, 프로젝트에 활용하게 되는 계기가 되었습니다. Hugo 설정 과정의 고난과 성취 Hugo의 config 설정 관련 변경사항이 많았고, 한국어로 된 자료도 많이 부족합니다. 블로그 제작 기간 중 대부분의 시간을 config 파일 관련된 부분을 찾고 이해하는데 소요했습니다. 그만큼 원하는 결과를 얻게 되어 만족스럽습니다. Git Submodule : Git Submodule 개념을 처음 접하고 활용하면서, 이에 대한 필요성과 활용 가능성을 체감하게 되었습니다. ","date":"2023-11-22T00:00:00Z","permalink":"https://srlee056.github.io/Blog/blog/","title":"Blog 제작기 발표"},{"content":"TIL - AWS Services - DB \u0026amp; Network 📋 공부 내용 DB SQL vs NoSQL SQL NoSQL 특징 구조화 된 데이터 비정형 데이터 db MySql 등 Mongodb 등 OLAP Cube Key-Value, Graph, Document, Column store AWS Service RDS, \u0026hellip; DocumentDB, Dynamo DB Network Route53 Amazon Route 53 : DNS 관리 서비스. 도메인 등록, DNS 라우팅, 상태 확인 가능\nACM AWS Certificate Manager\n사용할 SSL/TLS 인증서를 발급받거나, 등록할 수 있다. DNS 또는 email 검승으로 해당 인증서의 도메인 소유권을 검증한다. 등록된 인증서는 AWS 서비스, 리소스등에 사용할 수 있다. CloudFront AWS CDN(콘텐츠 전송 네트워크) Service\n데이터 사용량이 많은 application의 웹 페이지 로딩 속도를 빠르게 하는 서비스 (영상, 사진 등 콘텐츠를 빠르게 로딩, 캐싱 등 기술 활용)\n특징\n대기 시간 감소 보안 향상 비용 절감 ELB Elastic Load Balancing\n리소스 전체에 네트워크 트래픽을 균등하게 배포\nLoad Balancer\n서버에 가해지는 로드를 분산시키는 장치 또는 기술을 통칭 계층에 따라 L4 LB(Transport layer), L7 LB(Application layer)가 존재한다. VPC Amazon Virtual Private Cloud\n사용자가 정의하는 가상네트워크\n특성\nSubnet IP 주소 지정 Routing Tables Gateway \u0026amp; Endpoint peering 연결 CIDR\n👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n참고 사이트들 IP, 그리고 VPC와 서브넷에 대해 알아보자 AWS-Region, AZ, VPC, Subnet 편 ❗ 느낀 점 궁금한 건 있는데 표현이 잘 안되니까 너무 답답하다. 한마디로 뭘 모르는지 모르는상태.. 내가 궁금한건 웬만하면 어디에 적어두기만 하고 \u0026lsquo;그렇구나\u0026rsquo; 하고 넘어가야 속이 편할 것 같다. 왜냐면 나도 뭘 모르는지 모르니까 질문을 할 수 없기 때문\nVPC의 각 subnet은 하나의 AZ안에 존재한다. 근데 subnet은 왜 여러 AZ를 걸쳐서 존재할 수 없지? 리소스를 분배하기 어려운가? 기능적으로 불가능한게 아니라 여러 AZ에 걸쳐서 존재할경우 한 AZ에 문제가 생기면 영향을 주는 서브넷의 수가 많아지기 때문인가? 같은 AZ안에 있어야 속도 등 효율도 더 좋고? 그럼 한 subnet이 하나의 서비스(instance)를 담당하는건 맞나? 그럼 보통 한 application에 VPC는 몇개까지 할당될 수 있지? 한 VPC내에 4~5개의 public subnet과 여러 private subnet이 존재하는 거 같은데 필요한 서비스 개수를 만족할만큼 subnet을 가질 수 있나?\n어제만 해도 이런식으로 꼬리에 꼬리를 물고 궁금한게 떠올랐고\u0026hellip; 정리하기도 힘들고 결과적으로 뭘 질문하고 찾아봐야하는지도 모르겠어서 포기했다. 적어두고 나중에 내가 더 지식이 생기면 이 질문들을 어떻게 물어봐야 할지도 알게 되겠지\u0026hellip;. ㅠㅠ\n","date":"2023-11-21T14:53:46+09:00","permalink":"https://srlee056.github.io/p/day-27/","title":"Day 27"},{"content":"TIL - AWS EC2 📋 공부 내용 클라우드 컴퓨팅 클라우드 컴퓨팅의 이점 민첩성 : 빠르게 배포 및 운영이 가능하다. 탄력성 : CPU 등 리소스의 추가 및 제거가 쉽다. 비용절감 : 잉여리소스에 대한 비용이 감소한다. On demand : 리소스가 필요할 경우 바로 구매하여 사용할 수 있다. 관리 용이성 : 서버실 등 일일이 관리할 필요가 없으며, 서비스 업체를 통해 GUI등으로 쉽게 관리할 수 있다. 클라우드 유형 (리소스 관점에서 분류)\nOn Premises : 직접 서버를 구성하고 관리 IAAS : 하드웨어 부분까지 클라우드 서비스 업체가 관리해주며, 그 외에는 직접 관리 PAAS : 하드웨어 + OS, 미들웨어 부분까지 클라우드 서비스가 관리 SAAS : 모든 리소스를 클라우드 서비스에서 관리 AWS Amazon에서 제공하는 클라우드 서비스\nAWS 기본 용어 가상화 : 물리적 컴퓨터 하드웨어를 효율적으로 활용하게 해주는 프로세스 가상머신(Virtual Machine) : 물리적 컴퓨팅을 소프트웨어 형태로 시뮬레이션 할 수 있는 가상 환경 스냅샷 : 특정 시점에 스토리지의 파일 시스템을 포착해 보관하는 기술 데이터 센터 : 여러 서버들이 한데 모여 네트워크로 연결된 시설 Region : Data Center 위치, 국가마다 자원 사용 비용이 다름 AZ(Availability Zone): 가용 영역, 하나의 Region은 둘 이상의 AZ로 구성됨 EC2 EC2 특성 및 정보 인스턴스 : 가상 컴퓨팅 환경 AMI(Amazon Machine Image) : 서버에 필요한 OS, Software 등이 구성되어있는 템플릿 Key pair : 인스턴스 로그인 정보를 보호하기 위해 제공 ~/.ssh 폴더에 발급받은 키 이동 키의 권한 변경 커맨드 입력을 통해 EC2 서버에 연결 Amazon EBS(Elastic Block Store) Security Group : 인스턴스에 연결할 수 있는 protocol, port, IP 등을 지정 EIP (Elastic IP) : 실행될 때 마다 동적으로 변경되는 IP 대신 사용하기 위해 발급받는 고정 IPv4 주소 Tag : EC2 리소스 등에 할당하는 메타데이터, 검색가능 VPC(Virtual Private Cloud) : 가상 네트워크 Elastic Beanstalk 애플리케이션을 신속하게 배포하고 관리해주는 서비스\n특징\n용량 provisioning, load balancing 등을 자동으로 처리해줌 Go, Java, .NET, Node.js, PHP, Python, Ruby 언어 지원 EC2 등 AWS 리소스를 provisioning 하여 애플리케이션을 실행 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nelsticbeanstalk 오류 관련 해결법\nstackoverflow 링크\nenvirionment 생성 시 오류 발생 IAM Role 생성해서 오류 해결 environment 생성 성공 ❗ 느낀 점 개념 및 설정 위주라 크게 어렵거나 이해가 안되는 부분은 없었다. 다만 이전 강의를 다 완료하지 못하고 시작해서 혹시 aws 쪽 설정에 충돌이 생길까봐 걱정이 됐다.\n그 외에는 오늘 강의 외에 해야 할 다른 일들이 많아서 정신이 없다 보니까 TIL도 기본적인 내용만 적게 됐다. 많이 아쉽다 ㅠㅠ\n이전에 적지 못했던 TIL들을 천천히 적고 있는데 아무래도 글쓰기를 잘 못하다보니 오랜 시간이 걸린다. 그렇지만 글은 쓰면서 늘 테니까\u0026hellip;! 힘들어도 많이 써보고 나중에 다시 보면서 고쳐봐야겠다. 😊 👍\n","date":"2023-11-20T10:50:47+09:00","permalink":"https://srlee056.github.io/p/day-26/","title":"Day 26"},{"content":"TIL - 📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-17T15:26:49+09:00","permalink":"https://srlee056.github.io/p/day-25/","title":"Day 25"},{"content":"TIL - 📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-16T16:23:59+09:00","permalink":"https://srlee056.github.io/p/day-24/","title":"Day 24"},{"content":"TIL - 📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-15T16:26:00+09:00","permalink":"https://srlee056.github.io/p/day-23/","title":"Day 23"},{"content":"TIL - 📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-14T18:00:57+09:00","permalink":"https://srlee056.github.io/p/day-22/","title":"Day 22"},{"content":"TIL - SQL and RDB 📋 공부 내용 SQL SQL : Structured Query Language\nDDL(Data Definition Language) : 테이블 schema 정의 DML(Data Manipulation Language) : 테이블 데이터(레코드) 조작과 질의 1. SQL 특징\n구조화된 데이터를 분석하는 쉽고 검증된 언어 빅 데이터 등장 -\u0026gt; SQL 하락? -\u0026gt; 빅 데이터 또한 구조화 된 부분이 있기 때문에 SQL이 필요 -\u0026gt; SQL 재기 모든 데이터 웨어하우스 (Redshift, Snowflake, BigQuery 등) SQL 기반 데이터 직군 : 데이터 엔지니어, 데이터 분석가, 데이터 과학자 모두 SQL이 중요 2. 단점\n비구조화된 데이터를 다루는 데 제한적 정규표현식을 통해 어느정도만 가능 Spark, Hadoop 같은 분산 컴퓨팅 환경 필요 많은 RDB는 플랫한 구조만 지원(JSON처럼 nested 구조 X) RDB Relational Database\n구조화된 데이터를 저장하고 질의하는 데 사용되는 저장 장치\n1. Table Schema?\ntable format 테이블을 구성하는 컬럼의 이름과 타입 2. RDB 특징\n구조화된 데이터 : RDB에 저장하기 편함 But, 구조화되지 않은 형태의 데이터도 많음 (text, image, video, streaming, \u0026hellip;) 3. data modeling\nRDB에서 데이터를 어떻게 표현할것인가? 에 대한 고민 프로덕션 데이터베이스 Production Database OLTP (Online Transaction Processing)\n빠른 응답 속도, 서비스에 필요한 데이터 저장\n웹, 앱 서비스 등에 사용되며 FE, BE 개발자들이 주로 사용\nStar schema\n데이터를 논리적 단위로 나누어 저장하며, 필요할 경우 JOIN 스토리지의 낭비가 덜하며, 계산 속도가 상대적으로 느리지만 데이터 업데이트가 편함 데이터 웨어하우스 Data Warehouse OLAP (Online Analytical Processing)\n큰 데이터 처리, 데이터 분석 또는 모델 빌딩을 위한 데이터 저장\n데이터 직군 및 데이터팀이 주로 사용\nDenomalized schema\n단위 테이블로 나누어 저장하지 않으며, 별도의 JOIN이 필요하지 않음 스토리지를 더 사용하지만, 빠른 계산이 가능 RDB 2단계 구조 db folder(schema) tables 1 2 3 4 5 6 7 8 9 raw_data(DB) |-patient(table) |-patientData |-patientProfile | analytics(DB) |-patientSummary(table) |-vitalSummary |-alertSummary table 구조 records(row) 하나 이상의 field(column)으로 구성 field는 name, type, primary key 여부로 구성됨 column name type pk? userId int sessionId varchar(32) Yes channel varchar(32) Data Warehouse 데이터 분석 등 큰 데이터의 처리를 위해 별도로 존재하는 DB\n프로덕션 DB의 속도 저하를 막고 서비스에 영향을 주지 않기 위해 구성\n고객이 아닌 내부 직원을 위한 데이터베이스 프로덕션 DB를 주기적으로 복사하여 데이터 웨어하우스에 저장 프로덕션 DB와 다르게 primary key uniqueness를 보장하지 않음 1. 서비스 별 비용 옵션 비교\n회사 Data Warehouse 비용 청구 옵션 AWS Redshift 고정비용 GoogleCloud Big Query 가변비용 Snowflake 실제 사용시 가변비용의 웨어하우스 사용 추천 2. ETL(데이터 파이프라인)\n외부 데이터를 가져와 Data Warehouse로 저장하는 코드 데이터 인프라 데이터 엔지니어가 관리 ETL, Data Warehouse (비 구조적 데이터가 추가될 경우 )Spark 등 대용량 분산처리 시스템 Cloud \u0026amp; AWS Cloud 컴퓨팅 자원을 네트워크를 통해 서비스 형태로 사용하는 것\n1. 컴퓨팅 자원\n초기에는 서버 등 하드웨어에 국한되어 서비스됨 최근에는 mysql 등 소프트웨어 또한 서비스되고 있음 2. 탄력적 자원\n\u0026ldquo;No Provisioning\u0026rdquo;, \u0026ldquo;Pay As You Go\u0026rdquo;\n자원을 필요한만큼 실시간으로 할당하여 사용한만큼 지불 필요한만큼의 자원을 유지하는것이 중요 3. 클라우드 컴퓨팅이 없다면?\n서버,네트워크, 저장소 등 구매와 설정 ㅅ직접 수행 확장이 필요하면 공간부터 확보해야함 서버 구매 및 설치에 2~3달 소모 Peak time 기준으로 Capacity planning -\u0026gt; 자원이 놀게 되는 현상 발생 직접 운영 비용과 클라우드 컴퓨팅 비용 -\u0026gt; 기회비용 (직접 설치에 소요되는 시간을 비용으로 환산한다면?) 4. 클라우드 컴퓨팅 장점\n초기 투자 비용이 크게 줄어듬 -\u0026gt; 운영 비용이 증가 자원 준비 및 설정을 위한 대기시간 대폭 감소 노는 리소스 제거로 비용 감소 AWS 가장 큰 클라우드 컴퓨팅 서비스 업체 현재 Amazon에서 제일 큰 이익을 내고 있음 Netflix, Zynga 등 상장 업체들도 사용중\nAWS 서비스\nEC2: 서버 호스팅 서비스 S3: 대용량 클라우스 스토리지 서비스 Redshift : Data Warehouse 서비스 기타 DB 서비스, AI\u0026amp;ML 서비스 등 Redshift Scalable SQL 엔진\nOLAP Columnar storage : 컬럼별 압축 가능, 컬럼 추가 및 삭제가 빠름 (레코드 기준 X) 벌크 업데이트 지원: insert 커맨드로는 추가하기 어려운 많은 records를 갖고 있는 경우에 copy 커맨드를 통해 쉽고 빠르게 일괄 복사 가능 Postgresql 8.x와 SQL (대부분)호환됨 Redshift Schema 1 2 3 4 5 DEV | ----------------------- | | | \u0026lt;raw_data\u0026gt; \u0026lt;analytics\u0026gt; \u0026lt;adhoc\u0026gt; SQL command\n1 2 3 CREATE SCHEMA raw_data CREATE SCHEMA analytics CREATE SCHEMA adhoc 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-13T14:03:32+09:00","permalink":"https://srlee056.github.io/p/day-21/","title":"Day 21"},{"content":"TIL - Github 협업과 프로젝트 세팅 📋 공부 내용 Github 협업 Organization issue, pr, branch convention project, wiki package version management View django MTV의 View\u0026hellip; 모델과 template가 없으면 쉽사리 작성하기가 어렵다는걸 깨달았다.\n👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-06T17:18:28+09:00","permalink":"https://srlee056.github.io/p/day-16-20-project-1/","title":"Day 16-20 Project 1"},{"content":"TIL - 📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-03T16:16:11+09:00","permalink":"https://srlee056.github.io/p/day-15/","title":"Day 15"},{"content":"TIL - 📋 공부 내용 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\n❗ 느낀 점 ","date":"2023-11-02T15:29:23+09:00","permalink":"https://srlee056.github.io/p/day-14/","title":"Day 14"},{"content":"TIL - Django REST framework 📋 공부 내용 Django REST framework install settings.py 1 2 3 4 5 ... INSTALLED_APPS = [ ... \u0026#34;rest_framework\u0026#34;, ] Serializer Serializer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from rest_framework import serializers from polls.models import Question class QuestionSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) question_text = serializers.CharField(max_length=200) pub_date = serializers.DateTimeField(read_only=True) def create(self, validated_data): return Question.objects.create(**validated_data) def update(self, instance, validated_data): instance.question_text = ( validated_data.get(\u0026#34;question_text\u0026#34;, instance.question_text) + \u0026#34;[시리얼라이저에서 업데이트]\u0026#34; ) # id, pub_date는 Readonly라 업데이트 하지 않음 instance.save() return instance ModelSerializer 1 2 3 4 5 6 from rest_framework import serializers from polls.models import Question class QuestionSerializer(serializers.ModelSerializer): class Meta: model = Question fields = [\u0026#34;id\u0026#34;, \u0026#34;question_text\u0026#34;, \u0026#34;pub_date\u0026#34;] Views CRUD in HTTPS\nMethod 기반 URL Conf\nmysite/ursl.py 1 2 3 4 5 6 7 8 from django.contrib import admin from django.urls import path, include urlpatterns = [ path(\u0026#34;admin/\u0026#34;, admin.site.urls), path(\u0026#34;polls/\u0026#34;, include(\u0026#34;polls.urls\u0026#34;)), path(\u0026#34;rest/\u0026#34;, include(\u0026#34;polls_api.urls\u0026#34;)), ] polls_api/urls.py 1 2 3 4 5 6 7 from django.urls import path from .views import * urlpatterns = [ path(\u0026#34;question/\u0026#34;, question_list, name=\u0026#34;question-list\u0026#34;), path(\u0026#34;question/\u0026lt;int:id\u0026gt;/\u0026#34;, question_detail, name=\u0026#34;question-detail\u0026#34;), ] GET\n1 2 3 4 5 6 7 8 9 10 11 from polls.models import Question from polls_api.serializers import QuestionSerializer from rest_framework.response import Response from rest_framework.decorators import api_view # 데코레이터 아무것도 넣지 않으면 \u0026#39;GET\u0026#39; @api_view() def question_list(request): questions = Question.objects.all() # 여러개의 인스턴스를 줄 때 Many 옵션 serializer = QuestionSerializer(questions, many=True) return Response(serializer.data) POST 1 2 3 4 5 6 7 8 9 10 11 12 ... from rest_framework import status @api_view([\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;]) def question_list(request): ... if request.method == \u0026#34;POST\u0026#34;: serializer = QuestionSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) else: return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) PUT \u0026amp; DELETE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ... from django.shortcuts import get_object_or_404 @api_view([\u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;]) def question_detail(request, id): question = get_object_or_404(Question, pk=id) if request.method == \u0026#34;GET\u0026#34;: serializer = QuestionSerializer(question) return Response(serializer.data) if request.method == \u0026#34;PUT\u0026#34;: serializer = QuestionSerializer(question, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_200_OK) else: return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) if request.method == \u0026#34;DELETE\u0026#34;: question.delete() return Response(status=status.HTTP_204_NO_CONTENT) Class 기반 APIView 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 ... from rest_framework.views import APIView class QuestionList(APIView): def get(self, request): questions = Question.objects.all() serializer = QuestionSerializer(questions, many=True) return Response(serializer.data) def post(self, request): serializer = QuestionSerializer(data=request.data) print(type(request.data)) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) else: return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) class QuestionDetail(APIView): def get(self, request, id): question = get_object_or_404(Question, pk=id) serializer = QuestionSerializer(question) return Response(serializer.data) def put(self, request, id): question = get_object_or_404(Question, pk=id) serializer = QuestionSerializer(question, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_200_OK) else: return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) def delete(self, request, id): question = get_object_or_404(Question, pk=id) question.delete() return Response(status=status.HTTP_204_NO_CONTENT) URL Conf : polls_api/urls.py 1 2 3 4 5 ... urlpatterns = [ path(\u0026#34;question/\u0026#34;, QuestionList.as_view(), name=\u0026#34;question-list\u0026#34;), path(\u0026#34;question/\u0026lt;int:id\u0026gt;/\u0026#34;, QuestionDetail.as_view(), name=\u0026#34;question-detail\u0026#34;), ] Mixin 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class QuestionList( mixins.ListModelMixin, mixins.CreateModelMixin, generics.GenericAPIView ): queryset = Question.objects.all() serializer_class = QuestionSerializer def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) class QuestionDetail( mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, generics.GenericAPIView, ): queryset = Question.objects.all() serializer_class = QuestionSerializer def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) def put(self, request, *args, **kwargs): return self.update(request, *args, **kwargs) def delete(self, request, *args, **kwargs): return self.destroy(request, *args, **kwargs) URL Conf : polls_api/urls.py 1 2 3 4 5 ... urlpatterns = [ path(\u0026#34;question/\u0026#34;, QuestionList.as_view(), name=\u0026#34;question-list\u0026#34;), path(\u0026#34;question/\u0026lt;int:pk\u0026gt;/\u0026#34;, QuestionDetail.as_view(), name=\u0026#34;question-detail\u0026#34;), ] Generic API View 1 2 3 4 5 6 7 class QuestionList(generics.ListCreateAPIView): queryset = Question.objects.all() serializer_class = QuestionSerializer class QuestionDetail(generics.RetrieveUpdateDestroyAPIView): queryset = Question.objects.all() serializer_class = QuestionSerializer URL Conf : polls_api/urls.py 1 2 3 4 5 ... urlpatterns = [ path(\u0026#34;question/\u0026#34;, QuestionList.as_view(), name=\u0026#34;question-list\u0026#34;), path(\u0026#34;question/\u0026lt;int:pk\u0026gt;/\u0026#34;, QuestionDetail.as_view(), name=\u0026#34;question-detail\u0026#34;), ] 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\ndjango rest framework\n강의에는 따로 나오지 않는데, 설치 진행하고 https://www.django-rest-framework.org/ mysite/settings.py -\u0026gt; INSTALLED_APPS에 \u0026ldquo;rest_framework\u0026rdquo;, 추가해줘야 함 스택오버플로우 DRF ReturnDict, OrderedDict\npython venv 설정 공유 (협업)\n참고 글 참고 글2 ❗ 느낀 점 ","date":"2023-11-01T12:58:26+09:00","permalink":"https://srlee056.github.io/p/day-13/","title":"Day 13"},{"content":" TIL - Django 📋 공부 내용 Django의 디자인 패턴 MVC 구성 요소를 Model-View-Controller로 구분하는 디자인 패턴\n각 구성 요소가 다른 요소에게 영향을 미치지 않아야 함\nModel\n데이터를 갖고, 처리하는 로직을 가짐 View\n요청에 대한 결과를 화면에 보여주는 역할. 유저와의 인터페이스 Controller\nModel과 View를 이어주는 역할 MTV Model-Template-View MVC 패턴에 대응되는 Django의 디자인 패턴\nModel\nDB에 저장되는 데이터를 의미하며, 클래스 하나가 table 하나에 대응됨 Template\nMVC 패턴의 View 역할으로, 유저에게 보여지는 화면을 의미 View\nMVC 패턴의 Controller 역할으로, 요청에 따른 로직을 수행하며 결과를 Template으로 렌더링하며 응답하거나 데이터를 주고받음 +URLConf\nURL pattern을 정의하고 URL과 View를 매핑함 View polls/views.py\nimport\n1 2 3 4 5 from .models import * from django.http import HttpResponse, HttpResponseRedirect #, Http404 from django.shortcuts import render, get_object_or_404 from django.urls import reverse from django.db.models import F index page 1 2 3 4 5 6 7 8 9 # 웹 서버는 요청에 응답하는 역할이기 때문에, 요청을 받고 응답을 반환하는 기능이 필요 def index(request): # \u0026#39;-pub_date\u0026#39; : pub_date 기준 \u0026#34;역순\u0026#34;으로 latest_question_list = Question.objects.order_by(\u0026#34;-pub_date\u0026#34;)[:5] # context = {\u0026#34;{Template 변수(?) 이름}\u0026#34;: 값} context = {\u0026#34;questions\u0026#34;: latest_question_list} # request에 대해 context를 넘겨 \u0026#39;polls/index.html\u0026#39; template를 렌더링한다. return render(request, \u0026#34;polls/index.html\u0026#34;, context) detail page 1 2 3 4 5 6 7 8 9 10 def detail(request, question_id): \u0026#34;\u0026#34;\u0026#34; Http404를 활용하는 방법 try: question = Question.objects.get(pk=question_id) except Question.DoesNotExist: raise Http404(\u0026#34;Question does not exist\u0026#34;) \u0026#34;\u0026#34;\u0026#34; # Django에서 제공하는 404 Shortcut question = get_object_or_404(Question, pk=question_id) return render(request, \u0026#34;polls/detail.html\u0026#34;, {\u0026#34;question\u0026#34;: question}) vote page 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def vote(request, question_id): question = get_object_or_404(Question, pk=question_id) try: selected_choice = question.choice_set.get(pk=request.POST[\u0026#34;choice\u0026#34;]) except (KeyError, Choice.DoesNotExist): return render( request, \u0026#34;polls/detail.html\u0026#34;, { \u0026#34;question\u0026#34;: question, \u0026#34;error_message\u0026#34;: f\u0026#34;선택이 없습니다. id={request.POST[\u0026#39;choice\u0026#39;]}\u0026#34;, }, ) else: # 동시에 두 서버에서 같은 선택을 한 경우, 값을 제대로 변경하기 위해 # db에서 값을 읽어 계산 진행 selected_choice.votes = F(\u0026#34;votes\u0026#34;) + 1 # F : django db selected_choice.save() # vote template를 render하지 않고, result page로 redirect return HttpResponseRedirect(reverse(\u0026#34;polls:result\u0026#34;, args=(question_id,))) result page 1 2 3 def result(request, question_id): question = get_object_or_404(Question, pk=question_id) return render(request, \u0026#34;polls/result.html\u0026#34;, {\u0026#34;question\u0026#34;: question}) Template polls/templates/polls/ 폴더 내에 .html 파일으로 작성\nindex.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {% if questions %} \u0026lt;ul\u0026gt; {% for question in questions %} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;{% url \u0026#39;polls:detail\u0026#39; question.id %}\u0026#34;\u0026gt; {{question.question_text}} \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; {% else %} \u0026lt;p\u0026gt;no questions\u0026lt;/p\u0026gt; {% endif %} {% comment %} template에서는 인덱싱에 . 사용 questions[0] : X questions.0 : O appname 설정하지 않은 경우 : url \u0026#39;detail\u0026#39; appname 설정한 경우 : url \u0026#39;polls:detail\u0026#39; \u0026#39;{app_name : name}\u0026#39; in urls.py {% endcomment %} detail.html : Using form to get input from User 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;form action={% url \u0026#39;polls:vote\u0026#39; question.id %} method=\u0026#39;post\u0026#39;\u0026gt; {# django에서 자동으로 토큰 생성 #} {% csrf_token %} \u0026lt;h1\u0026gt;{{ question.question_text }}\u0026lt;/h1\u0026gt; {% if error_message %} \u0026lt;p\u0026gt; \u0026lt;strong\u0026gt;{{ error_message }}\u0026lt;/strong\u0026gt; \u0026lt;/p\u0026gt; {% endif %} {% for choice in question.choice_set.all %} \u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;choice\u0026#34; id=\u0026#34;choice{{ forloop.counter }}\u0026#34; value=\u0026#34;{{choice.id}}\u0026#34;\u0026gt; \u0026lt;lable for=\u0026#34;choice{{ forloop.counter }}\u0026#34;\u0026gt; {{ choice.choice_text }} \u0026lt;/lable\u0026gt; \u0026lt;br\u0026gt; {% endfor %} \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Vote\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; result.html 1 2 3 4 5 6 \u0026lt;h1\u0026gt;{{ question.question_text }}\u0026lt;/h1\u0026gt; \u0026lt;br /\u0026gt; {% for choice in question.choice_set.all %} \u0026lt;lable\u0026gt; {{ choice.choice_text }} -- {{ choice.votes }} \u0026lt;/lable\u0026gt; \u0026lt;br /\u0026gt; {% endfor %} URL Config polls/urls.py 1 2 3 4 5 6 7 8 9 10 11 12 from django.urls import path from . import views app_name = \u0026#34;polls\u0026#34; # app_name이 설정된 경우, polls:detail, polls:vote 등 app_name을 필수적으로 포함하여 호출해야 함 urlpatterns = [ path(\u0026#34;\u0026#34;, views.index, name=\u0026#34;index\u0026#34;), # \u0026lt;int:question_id\u0026gt;/ : 사용자가 입력하는 주소를 통해 question_id가 전달됨 path(\u0026#34;\u0026lt;int:question_id\u0026gt;/\u0026#34;, views.detail, name=\u0026#34;detail\u0026#34;), path(\u0026#34;\u0026lt;int:question_id\u0026gt;/vote/\u0026#34;, views.vote, name=\u0026#34;vote\u0026#34;), path(\u0026#34;\u0026lt;int:question_id\u0026gt;/result/\u0026#34;, views.result, name=\u0026#34;result\u0026#34;), ] Customizing Admin page 같이 개발하는 또는 데이터를 활용하는 내부 User를 위해 Admin Page를 적절하게 조작하는 방법에 대해 배운다.\npolls/models.py\n1 2 3 4 5 6 7 8 9 10 class Question(models.Model): # verbose_name 으로 넘겨준 문자열이 admin page에서 제목으로 표시된다. question_text = models.CharField(max_length=200, verbose_name=\u0026#34;질문\u0026#34;) pub_date = models.DateTimeField(auto_now_add=True, verbose_name=\u0026#34;생성일\u0026#34;) # admin page display를 표시하는 방식을 변경한다. @admin.display(boolean=True, description=\u0026#34;최근생성(하루기준)\u0026#34;) def was_published_recently(self): return self.pub_date \u0026gt;= timezone.now() - datetime.timedelta(days=1) ... polls/admin.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from django.contrib import admin from .models import * # StackedInline, TabularInline # Question admin page에서 연결된 Choice를 Inline 형태로 출력하기 위한 class class ChoiceInline(admin.TabularInline): model = Choice extra = 2 # 추가 등록 칸 # Question admin page customizing class QuestionAdmin(admin.ModelAdmin): fieldsets = [ (\u0026#34;생성일\u0026#34;, {\u0026#34;fields\u0026#34;: [\u0026#34;pub_date\u0026#34;], \u0026#34;classes\u0026#34;: [\u0026#34;collapse\u0026#34;]}), # collapse : 숨김처리 (\u0026#34;질문 섹션\u0026#34;, {\u0026#34;fields\u0026#34;: [\u0026#34;question_text\u0026#34;]}), ] list_display = [\u0026#34;question_text\u0026#34;, \u0026#34;pub_date\u0026#34;, \u0026#34;was_published_recently\u0026#34;] readonly_fields = [\u0026#34;pub_date\u0026#34;] # cannot modify. inlines = [ChoiceInline] list_filter = [\u0026#34;pub_date\u0026#34;] # filter records by pub_date search_fields = [\u0026#34;question_text\u0026#34;, \u0026#34;choice__choice_text\u0026#34;] # register Question to admin site with customized page \u0026#34;QuestionAdmin\u0026#34; admin.site.register(Question, QuestionAdmin) 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nvscode django template 포매팅\n참고글 django template 주석 처리\n1 2 3 4 {% comment %} 주석 내용 {% endcomment %} {# 한 줄 주석 #} ❗ 느낀 점 오늘은 제일 맘에 들지 않는 TIL 인 것 같다. 일단 정리도 제대로 안됐고, 용어도 제대로 기억을 못했다. 강의를 다시 보면서 강사님이 사용하는 용어등을 체크하고 작성했으면 좋았겠지만 시간이 빠듯하기도 하고 집중도 잘 안돼서 제대로 못 적었다. 내일 중에 시간이 나면 오늘 강의를 다시 들으면서 수정을 좀 하고싶다. 내일 못하더라도 주말에는 꼭 할 생각이다.\n어제 오늘 배운 내용들은 아무래도 프로젝트를 하면서 직접 더 찾아보고 사용해봐야 제대로 이해할 것 같다. View와 Template, URL Config가 하는 역할은 이해도 가고 활용해서 다른 페이지를 만들어보는것도 할 수 있다. 그런데 각각의 필드나 활용 가능한 메소드 등 깊게 들어가기 시작하면 말이나 글로 풀어서 설명하는게 너무 어렵다. 그리고 학교를 다니면서 영어로 된 term을 더 자주 접해서 그런가.. TIL을 적을 때에도 한국어로 설명하기 애매하고 어려운 용어들은 무조건 영어로 적는 습관이 있다.\n요즘 강의들은 실습 위주라 그런지 TIL을 코드와 주석 위주로만 적는 경향이 있는데, 다른 방식으로 적어보고 싶다. 예전에 찾아둔 TIL 참고 링크와, 부트캠프를 참가자들 블로그를 보면서 잘 쓴 TIL들을 참고해봐야겠다.\n","date":"2023-10-31T14:18:08+09:00","permalink":"https://srlee056.github.io/p/day-12/","title":"Day 12"},{"content":" TIL - Django 📋 공부 내용 Django 설치 및 개발환경 설정 Python virtual environment (venv) 서로 다른 환경에서 개발되는 여러 프로젝트를 진행할 때, 환경을 체크하고 변경하는 번거로움 및 프로젝트간의 충돌이 발생한다.\n이와 같은 문제점을 방지하고 프로젝트들을 각 목적에 맞게 효율적으로 관리하기 위해, 프로젝트마다 가상환경을 만들어 사용하는것을 권장한다.\n가상환경 프로젝트 생성 1 $ python -m venv {project-name} 활성화 1 $ source project-name/bin/activate 비활성화 1 $ deactivate Django 가상환경이 활성화 된 상태에서 설치\n1 $ pip install django Django 활용 Django : 파이썬으로 제작된 웹 프레임워크\n프로젝트 프로젝트 생성 및 서버 실행\n1 2 $ django-admin startproject mysite $ python3 manage.py runserver (python으로 입력하는 경우 실행이 되지 않을 때가 많아 python3 사용)\nApp \u0026amp; Url 새로운 앱 polls와 index, some_url 페이지를 생성하고 url 연결 1 $ python3 manage.py startapp polls polls/views.py 1 2 3 4 5 6 7 from django.http import HttpResponse def index(request): return HttpResponse(\u0026#34;Hello, world.\u0026#34;) def some_url(request): return HttpResponse(\u0026#34;Some ulr을 구현해 봤습니다.\u0026#34;) mysite/urls.py 1 2 3 4 5 6 7 from django.contrib import admin from django.urls import path, include urlpatterns = [ path(\u0026#34;admin/\u0026#34;, admin.site.urls), path(\u0026#34;polls/\u0026#34;, include(\u0026#39;polls.urls\u0026#39;)) ] polls/urls.py 1 2 3 4 5 6 7 from django.urls import path from . import views urlpatterns = [ path(\u0026#39;\u0026#39;,views.index, name=\u0026#39;index\u0026#39;) path(\u0026#39;some_url\u0026#39;,views.some_url) ] RDB Relational Database 관계형 데이터베이스 데이터를 행과 열로 이루어진 테이블의 형태로 구성하고, 테이블 간의 관계를 정의하는 데이터베이스\n테이블 table\n행과 열로 구성되어 있는 데이터의 집합\n열 column\n테이블의 필드(field)\nprimary key 테이블의 각 행(row)을 고유하게 식별할 수 있는 열(column) forien key 다른 테이블의 primary key를 참조하는 열(column)으로, 두 테이블 간의 관계를 설정할 수 있음 행 row\n테이블에 저장된 데이터 레코드(Record)\nModel Django에서 RDB와 연동을 담당하는 클래스로, 각 모델은 데이터베이스의 테이블(Table)에 해당하며 필드(Field)를 가지고 있다.\n모델 필드 (model field) 다양한 타입의 필드와 옵션이 존재한다. 자세한 설명은 아래 링크를 참고. Django Model Fields mysite/settings.py 1 2 3 4 5 6 7 8 9 10 11 12 13 ... # Application definition INSTALLED_APPS = [ \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;polls.apps.PollsConfig\u0026#39;, #새로 생성한 app을 settings.py에 추가 ] ... polls/models.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from django.db import models # polls app에 모델 두 개를 만들고 각각의 field를 설정 # 따로 primary key(=pk)를 설정하지 않을 경우, 모델이 생성될 때 주어지는 id와 같은 값을 갖게 됨 class Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField(\u0026#39;date published\u0026#39;) # foreign key로 Question 모델의 pk를 참조 class Choice(models.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) migration 파일 생성 1 $ python3 manage.py makemigrations polls migration으로 실행될 SQL 문장 살펴보기 1 $ python3 manage.py sqlmigrate polls 0001 migration 실행하기 1 $ python3 manage.py migrate migration 롤백 1 2 #0001 버전으로 롤백 $ python3 manage.py migrate polls 0001 Admin 관리자 계정을 생성하고 웹 브라우저를 통해 사이트에 접속하여\nUser, App 그리고 Model 등을 생성, 수정 및 삭제할 수 있다.\nAdmin 생성 1 $ python manage.py createsuperuser polls/admin.py 1 2 3 4 5 6 from django.contrib import admin from .models import * # polls/models.py 에서 정의한 모델을 가져온다. #admin site에 생성한 모델 등록 admin.site.register(Question) admin.site.register(Choice) polls/models.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from django.db import models class Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField(\u0026#39;date published\u0026#39;) # field 출력을 위한 함수 def __str__(self): return f\u0026#39;제목: {self.question_text}, 날짜: {self.pub_date}\u0026#39; class Choice(models.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) Model Method polls/modes.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.utils import timezone import datetime class Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField(\u0026#39;date published\u0026#39;) def was_published_recently(self): return self.pub_date \u0026gt;= timezone.now() - datetime.timedelta(days=1) def __str__(self): if self.was_published_recently(): new_badge = \u0026#39;NEW!!!\u0026#39; else: new_badge = \u0026#39;\u0026#39; return f\u0026#39;{new_badge} 제목: {self.question_text}, 날짜: {self.pub_date}\u0026#39; QuerySet List of model objects\n데이터베이스로부터 데이터를 읽고, 필터링하거나 정렬할 수 있음\n(Django Shell에서 진행)\nDjango Shell 실행 1 $ python manage.py shell Read model object 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 모델 가져오기 \u0026gt;\u0026gt;\u0026gt; from polls.models import * #모든 Question,Choice 오브젝트 출력 \u0026gt;\u0026gt;\u0026gt; Question.objects.all() \u0026gt;\u0026gt;\u0026gt; Choice.objects.all() #첫번째 Choice 오브젝트를 가져와 필드 출력 \u0026gt;\u0026gt;\u0026gt; choice = Choice.objects.all()[0] \u0026gt;\u0026gt;\u0026gt; choice.id \u0026gt;\u0026gt;\u0026gt; choice.choice_text \u0026gt;\u0026gt;\u0026gt; choice.votes #첫번째 Choice와 연결된 Question을 가져와 필드 출력 \u0026gt;\u0026gt;\u0026gt; q = choice.question \u0026gt;\u0026gt;\u0026gt; choice.question.pub_date \u0026gt;\u0026gt;\u0026gt; choice.question.id #해당 Question과 연결되어 있는 모든 Choice 가져오기 \u0026gt;\u0026gt;\u0026gt; q.choice_set.all() CRUD model objects (Records) (CRUD : Create, Read, Update \u0026amp; Delete)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u0026gt;\u0026gt;\u0026gt; from polls.models import * # 새로운 Question 오브젝트를 내용과 함께 생성하고 \u0026#39;q1\u0026#39;이라는 변수에 저장 \u0026gt;\u0026gt;\u0026gt; q1 = Question(question_text = \u0026#34;커피 vs 녹차\u0026#34;) # \u0026#39;q1\u0026#39; 생성시각을 설정 \u0026gt;\u0026gt;\u0026gt; from django.utils import timezone \u0026gt;\u0026gt;\u0026gt; q1.pub_date = timezone.now() # \u0026#39;q1\u0026#39;을 데이터베이스에 저장하기 \u0026gt;\u0026gt;\u0026gt; q1.save() # 같은 과정을 통해 q2를 생성하고 데이터베이스에 저장 \u0026gt;\u0026gt;\u0026gt; q2 = Question(question_text = \u0026#34;abc\u0026#34;) \u0026gt;\u0026gt;\u0026gt; q2.pub_date = timezone.now() \u0026gt;\u0026gt;\u0026gt; q2.save() # .create method로 Choice object를 생성하여 q2와 연결 \u0026gt;\u0026gt;\u0026gt; q2.choice_set.create(choice_text = \u0026#34;b\u0026#34;) # Choice object를 생성할 때 question field에 q2값을 넣어 연결 \u0026gt;\u0026gt;\u0026gt; choice_c = Choice(choice_text=\u0026#39;c\u0026#39;, question=q3) #새로운 Choice 오브젝트를 데이터베이스에 저장하기 \u0026gt;\u0026gt;\u0026gt; choice_c.save() # q2와 연결된 Choice 오브젝트들을 확인 \u0026gt;\u0026gt;\u0026gt; q2.choice_set.all() \u0026lt;QuerySet [\u0026lt;Choice: b\u0026gt;, \u0026lt;Choice: c\u0026gt;]\u0026gt; # 가장 마지막으로 생성된 오브젝트 가져와 삭제하기 \u0026gt;\u0026gt;\u0026gt; q = Question.objects.last() \u0026gt;\u0026gt;\u0026gt; q.delete() Filter model objects QuerySet method get() 1 2 3 4 5 6 # 조건에 맞는 오브젝트 필터링 \u0026gt;\u0026gt;\u0026gt; Question.objects.get(id=1) \u0026gt;\u0026gt;\u0026gt; Question.objects.get(question_text__startswith=\u0026#39;휴가를\u0026#39;) # 오브젝트 여러개를 반환하는 필터링을 진행할 경우 에러 발생 \u0026gt;\u0026gt;\u0026gt; Question.objects.get(pub_date__year=2023) # get() returned more than one Question QuerySet method filter() \u0026amp; exclude() 1 2 3 4 5 6 7 8 9 10 # 여러 오브젝트를 반환하는 필터링 가능 \u0026gt;\u0026gt;\u0026gt; Question.objects.filter(pub_date__year=2023) \u0026lt;QuerySet [\u0026lt;Question: 제목: 휴가를 어디서 보내고 싶으세요?, 날짜: 2023-02-05 18:52:59+00:00\u0026gt;, \u0026lt;Question: 제목: 가장 좋아하는 디저트는?, 날짜: 2023-02-05 18:53:27+00:00\u0026gt;, ...]\u0026gt; \u0026gt;\u0026gt;\u0026gt; Question.objects.filter(pub_date__year=2023).count() 2 # 관계기반의 필터링 # foreign key로 지정된 Model의 필드값으로 필터링 가능 \u0026gt;\u0026gt;\u0026gt; Choice.objects.filter(question__question_text__startswith=\u0026#39;휴가\u0026#39;) \u0026gt;\u0026gt;\u0026gt; Choice.objects.exclude(question__question_text__startswith=\u0026#39;휴가\u0026#39;) SQL query 1 2 3 4 5 6 7 8 9 # example 1 \u0026gt;\u0026gt;\u0026gt; print(Question.objects.filter(pub_date__year=2023).query) SELECT \u0026#34;polls_question\u0026#34;.\u0026#34;id\u0026#34;, \u0026#34;polls_question\u0026#34;.\u0026#34;question_text\u0026#34;, \u0026#34;polls_question\u0026#34;.\u0026#34;pub_date\u0026#34; FROM \u0026#34;polls_question\u0026#34; WHERE \u0026#34;polls_question\u0026#34;.\u0026#34;pub_date\u0026#34; BETWEEN 2023-01-01 00:00:00 AND 2023-12-31 23:59:59.999999 # example 2 # pk == primary key = id \u0026gt;\u0026gt;\u0026gt; q = Question.objects.get(pk=1) \u0026gt;\u0026gt;\u0026gt; print(q.choice_set.all().query) SELECT \u0026#34;polls_choice\u0026#34;.\u0026#34;id\u0026#34;, \u0026#34;polls_choice\u0026#34;.\u0026#34;question_id\u0026#34;, \u0026#34;polls_choice\u0026#34;.\u0026#34;choice_text\u0026#34;, \u0026#34;polls_choice\u0026#34;.\u0026#34;votes\u0026#34; FROM \u0026#34;polls_choice\u0026#34; WHERE \u0026#34;polls_choice\u0026#34;.\u0026#34;question_id\u0026#34; = 1 Field lookups QuerySet methods filter(), exclude() \u0026amp; get() 에서 keyword arguments로 지정됨\n1 2 3 4 5 6 7 8 9 10 11 12 # startswith \u0026gt;\u0026gt;\u0026gt; Question.objects.filter(question_text__startswith=\u0026#39;휴가를\u0026#39;) # contains \u0026gt;\u0026gt;\u0026gt; Question.objects.filter(question_text__contains=\u0026#39;휴가\u0026#39;) # gt, gte, lt, lte \u0026gt;\u0026gt;\u0026gt; Choice.objects.filter(votes__gt=0) # 정규표현식 \u0026gt;\u0026gt;\u0026gt; print(Question.objects.filter(question_text__regex=r\u0026#39;^휴가.*어디\u0026#39;).query) SELECT \u0026#34;polls_question\u0026#34;.\u0026#34;id\u0026#34;, \u0026#34;polls_question\u0026#34;.\u0026#34;question_text\u0026#34;, \u0026#34;polls_question\u0026#34;.\u0026#34;pub_date\u0026#34;, \u0026#34;polls_question\u0026#34;.\u0026#34;owner_id\u0026#34; FROM \u0026#34;polls_question\u0026#34; WHERE \u0026#34;polls_question\u0026#34;.\u0026#34;question_text\u0026#34; REGEXP ^휴가.*어디 날짜와 시간 date \u0026amp; time information datetime date : 날짜를 다루기 위한 클래스(Year, Month, Day) time : 시간을 다루기 위한 클래스(Hour, Minute, Second, Microsecond) datetime : 날짜와 시간을 다루기 위한 클래스 (date 클래스와 time 클래스의 속성을 모두 가짐) timedelta : 시간 간격을 다루기 위한 클래스 1 2 3 4 5 6 7 8 9 from datetime import datetime, timedelta now = datetime.now() # one hour / one day / one week / one year later hour_after = now + timedelta(hours=1) day_after = now + timedelta(days=1) week_after = now + timedelta(days=7) # weeks=1 year_after = now + timedelta(days=365) timezone UTC 정보를 포함하며, 기본값은 UTC+0 1 2 3 4 from django.utils import timezone now = timezone.now() # datetime.datetime(2023, 10, 28, 6, 25, 23, tzinfo=datetime.timezone.utc) 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nvscode 세팅\nvscode 파이썬 가상환경 세팅 참고 블로그 vscode setting 에서 가상환경(venv) 루트 지정 가능 f1 -\u0026gt; interpreter -\u0026gt; 가상환경의 interpreter 지정하여 django 개발 환경으로 설정 문자열 보간 String Interpolation\n%, .format, f 1 2 def __str__(self): return f\u0026#34;제목: {self.question_text}, 날짜: {self.pub_date}\u0026#34; 참고 블로그 에러노트\n사용중인 Port 1 Error: That port is already in use. Ctrl + z 로 종료해서 서버가 제대로 종료되지 않아 생기는 에러 (Ctrl + c 로 종료해야 함) 해당 포트에서 돌아가고 있는 서버 확인 1 lsof -i:{port number} 해당 프로세스 kill 1 kill -9 {port number} MVC in Django : MTV\nMVC(Model-View-Controller) : 웹 개발 디자인 패턴 중 하나 MTV(Model-Template-View) : MVC에 대응되는 Django의 디자인 패턴 참고 블로그1 참고 블로그2 ❗ 느낀 점 오늘은 Django 프레임워크의 소개 및 기본 기능과 구조에 대해 배웠다. 간단한 개념 및 소개였기 때문에 어렵다기 보다는 정리하고 기억해야 할 내용이 많아 공부하고 정리하는 데 오랜 시간이 들었다.\n오늘 공부한 기본적인 개념을 잘 정리하고싶어서 강의를 들은 시간만큼 TIL을 적었다. 100% 만족하진 못해도 내가 정리한 내용과 공식 document를 통해 따로 찾아본 내용들을 기반으로 적어서 뿌듯하다. 오늘 정리하는게 정말 힘들었지만 이 경험 덕분에 이후 강의들을 잘 이해할 수 있을거라고 본다.\n모르는 내용을 찾아보고 적용하는덴 자신이 있지만 남들이 이해할 수 있게 정리하는덴 정말 자신이 없다. (말로 설명하는것도 비슷한 편이다.) 그래도 TIL을 적기 전보다는 훨씬 나아졌다는 걸 스스로도 체감중이다. 정리하는데 들인 시간들이 거름이 되어 나중에는 \u0026lsquo;잘 이해되는 글\u0026rsquo;, \u0026lsquo;잘 설명한 글\u0026rsquo; 이라는 좋은 결과를 수확할 수 있기를!!\n","date":"2023-10-30T12:39:04+09:00","permalink":"https://srlee056.github.io/p/day-11/","title":"Day 11"},{"content":"TIL - 스크래핑 데이터의 시각화 📋 공부 내용 Seaborn 데이터의 시각화 Seaborn matplolib 라이브러리를 기반으로 하여, 다양한 고수준(high-level) 그래프를 그릴 수 있는 라이브러리\nmatplolib 파이썬 시각화 라이브러리\nWordCloud 텍스트 클라우드 라이브러리로, 텍스트 구름을 그릴 수 있음\nKoNLPy 한국어 형태로 분석기 라이브러리. 주어진 문장에서 명사를 뽑아낼 수 있음\n설치 및 불러오는 방법 설치 1 2 3 pip install seaborn pip install wordcloud pip install konlpy 불러오기 (import) 1 2 3 4 import seaborn as sns import matplotlib.pyplot as plt from wordcloud import WordCloud from konlpy.tag import Hannanum 데이터 시각화1 - 라이브러리 기본 활용 꺾은선 그래프 lineplot 1 sns.lineplot(x=[1, 3, 2, 4], y=[0.7, 0.2, 0.1, 0.05]) 바 그래프 barplot 1 sns.barplot(x=[\u0026#34;Amy\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Cat\u0026#34;, \u0026#34;Dog\u0026#34;], y=[0.7, 0.2, 0.1, 0.05]) plot 속성\n제목 title 1 2 3 4 5 sns.barplot(x=[\u0026#34;Amy\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Cat\u0026#34;, \u0026#34;Dog\u0026#34;], y=[0.7, 0.2, 0.1, 0.05]) plt.title(\u0026#34;Bar Plot\u0026#34;) # jupyter lab에서 실습할 경우 노트북 환경이라 plt.show()를 쓰지 않아도 보였지만, 실제로는 필수적으로 이 코드를 적어야 볼 수 있음 plt.show() xlabel, ylabel 1 2 3 4 5 6 sns.barplot(x=[\u0026#34;Amy\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Cat\u0026#34;, \u0026#34;Dog\u0026#34;], y=[0.7, 0.2, 0.1, 0.05]) plt.xlabel(\u0026#34;This is x-label\u0026#34;) plt.ylabel(\u0026#34;This is y-label\u0026#34;) plt.show() x limit, y limit 1 2 3 4 5 6 sns.lineplot(x=[1, 3, 2, 4], y=[4, 3, 2, 1]) # plt.xlim() plt.ylim(0, 10) plt.show() size 1 2 3 4 5 # plot으로 그래프 그리기 전에 먼저 figure size를 지정해야 함 plt.figure(figsize=(20, 10)) sns.lineplot(x=[1, 3, 2, 4], y=[4, 3, 2, 1]) plt.show() 데이터 시각화2 - 기상청 날씨 정보 표현하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 라이브러리 불러오기 # 스크래핑을 위한 selenium \u0026amp; webdriver from selenium import webdriver from selenium.webdriver import ActionChains, Keys from selenium.webdriver.chrome.service import Service from selenium.webdriver.common.actions.action_builder import ActionBuilder from selenium.webdriver.common.by import By from webdriver_manager.chrome import ChromeDriverManager # 데이터 시각화를 위한 seaborn import seaborn as sns import matplotlib.pyplot as plt # 기상청 페이지에서 날씨 중 온도 데이터를 가져와서 저장 driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) url = \u0026#34;https://www.weather.go.kr/w/weather/forecast/short-term.do\u0026#34; driver.get(url) driver.implicitly_wait(5) temperatures = driver.find_element(By.ID, \u0026#34;my-tchart\u0026#34;).text temperatures = [int(i) for i in temperatures.replace(\u0026#34;℃\u0026#34;, \u0026#34;\u0026#34;).split(\u0026#34;\\n\u0026#34;)] plt.ylim(min(temperatures)-2, max(temperatures)+2) sns.lineplot( x = [i for i in range(len(temperatures))], y = temperatures ) plt.ylabel(\u0026#34;temperature\u0026#34;) plt.show() 데이터 시각화3 - 제목에 사용되는 단어의 빈도 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import requests from bs4 import BeautifulSoup import time from collections import Counter import matplotlib.pyplot as plt import seaborn as sns url = \u0026#34;https://qna.programmers.co.kr/?page={}\u0026#34; user_agent = { \u0026#34;User-Agent\u0026#34;: {user-agent} } # 사전 형태로 데이터의 빈도를 체크 tagsD = {} for i in range(1, 11): res = requests.get(url.format(i), user_agent) soup = BeautifulSoup(res.text, \u0026#34;html.parser\u0026#34;) tags = soup.find_all(\u0026#34;li\u0026#34;, \u0026#34;label-tag\u0026#34;) for i, t in enumerate(tags): tags[i] = t.text.strip() for t in tags: tagsD[t] = tagsD.get(t, 0) + 1 time.sleep(0.5) # Counter의 .most_common으로 제일 많이 등장하는 10개만 추출 tagsC = Counter(tagsD).most_common(10) # seaborn /plt를 통해 적절하게 시각화 x_elem = [a[0] for a in tagsC] y_elem = [a[1] for a in tagsC] plt.figure(figsize=(20, 10)) sns.barplot(x=x_elem, y=y_elem) plt.xlabel(\u0026#34;Tag\u0026#34;) plt.ylabel(\u0026#34;Frequency\u0026#34;) plt.title(\u0026#34;Frequency of questions in Programmers\u0026#34;) plt.show() 데이터 시각화 4 - 스크래핑한 내용으로 단어구름 만들기 데이터 시각화 3와 같은 조건에서 스크래핑한 내용으로 단어구름을 만든다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # 스크래핑에 사용되는 라이브러리 import requests from bs4 import BeautifulSoup # 시각화에 사용되는 라이브러리 import matplotlib.pyplot as plt from wordcloud import WordCloud import time from collections import Counter from konlpy.tag import Hannanum url = \u0026#34;https://qna.programmers.co.kr/?page={}\u0026#34; questions = [] for i in range(1, 6): res = requests.get(url.format(i), {\u0026#34;User-Agent\u0026#34;:user_agent}) soup = BeautifulSoup(res.text, \u0026#34;html.parser\u0026#34;) parsed_datas = soup.find_all(\u0026#34;li\u0026#34;, \u0026#34;question-list-item\u0026#34;) for data in parsed_datas: questions.append(data.h4.text.strip()) # 제목에서 명사만 추출 hannanum = Hannanum() words = [] for q in questions: nouns = hannanum.nouns(q) words += nouns # 한 글자 단어를 제외하려면 밑의 코드를 작성하면 된다. # words = [w for w in words if len(w) \u0026gt; 1] counter = Counter(words) # 한국어는 기본지원이 되지 않아 font_path로 한국어폰트를 제공해주어야 함 # width, height, background_color로 결과 이미지의 크기와 색을 바꿀 수 있음 wordcloud = WordCloud( font_path=\u0026#34;/Users/sarah/github-repo/dev_project/TAEBAEK-font.ttf\u0026#34;, width = 1000, height = 1000, background_color=\u0026#39;white\u0026#39; ) img = wordcloud.generate_from_frequencies(counter) plt.imshow(img) 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nWordCloud font_path에 온라인 폰트 링크를 넣을 수는 없을까? 단어 구름 모양을 하트, 스페이드 등 네모가 아닌 모양으로 만들 수 있을까? 결과 이미지를 표로 내보내지 않고 이미지만 가져올 수 있을까? ❗ 느낀 점 강의를 통해 시각화를 배우고 실습하면서, 다양하게 활용해보고싶은 욕심이 들었다. CHECK에 적은것처럼 여러가지 활용방식에 대해 궁금증이 떠올랐다. 오늘은 TIL 적는것에 집중이 잘 되지 않고 다른 일에 정신이 팔려서 추가적인 실습을 하지 못했는데, 주말에 전부 진행해보려고 한다.\n오늘은 이번주 마지막 강의였다. 저번주는 주말에 딱히 추가적인 공부를 하지 않았는데, 이번주는 하나라도 하고 글로 정리할 것이다. 분석이나 시각화는 강의자료를 참조하지 않고 외워서 적을 수 있을 정도로 연습을 하려고 한다.\n","date":"2023-10-27T16:54:37+09:00","permalink":"https://srlee056.github.io/p/day-10/","title":"Day 10"},{"content":"TIL - Selenium 📋 공부 내용 Selenium? Selenium 웹 브라우저를 조작할 수 있는 자동화 프레임워크\nWebDriver 웹 브라우저와 연동하고 제어하는 자동화 프레임워크\n설치 방법 1 2 pip3 install selenium pip3 install webdriver-manager Selenium 활용 import Selenium, webdriver 불러오기 1 2 3 4 5 6 7 # web browswer와 직접 연결 from selenium import webdriver # 크롬 객체를 넣을때 인자로 넣어주게 됨 from selenium.webdriver.chrome.service import Service # 사용중인 크롬과 동일한 버전으로 싱크하기 위함 # ex) firefox - firefox driver manager from webdriver_manager.chrome import ChromeDriverManager driver 생성 및 request\u0026amp;response Chrome 객체를 생성하여 크롬창을 실행 1 driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) .get(url) 으로 request 보냄 1 2 3 url = \u0026#34;https://www.example.com\u0026#34; driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) driver.get(url) .page_source로 Response HTML 문서 확인 1 2 3 driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) driver.get(url) print(driver.page_source) with-as 구문으로 driver 자동 종료 작성한 코드를 실행한 후 driver 종료되며 크롬 창도 꺼짐 1 2 3 with webdriver.Chrome(service=Service(ChromeDriverManager().install())) as driver : driver.get(url) print(driver.page_source) HTML 요소 추출 HTML 특정 요소 추출 .find_element(by, target) .find_elements(by, target) by : By.ID, BY.TAG_NAME, BY.CLASS_NAME, BY.XPATH \u0026hellip; 1 from selenium.webdriver.commom.by import By example 1 1 2 3 4 5 6 7 with webdriver.Chrome(service=Service(ChromeDriverManager().install())) as driver : driver.get(url) p1 = driver.find_element(By.TAG_NAME, \u0026#34;p\u0026#34;) p_list = driver.find_elements(By.TAG_NAME, \u0026#34;p\u0026#34;) print(p1.text) for p in p_list: print(p.text) example 2\n찾으려는 요소를 XPath를 통해 찾으려는 경우 1 2 3 path = \u0026#39;//*[@id=\u0026#34;__next\u0026#34;]/div/main/div[2]/div/div[4]/div[1]/div[1]/div/a/div[2]/p[1]\u0026#39; result = driver.find_element(By.XPATH, path) print(result.text) 유사한 XPath를 가진 여러 요소들을 가져오는 경우 1 2 3 4 5 # 반복되는 부분을 제외하고 변하는 부분을 {}로 적은 후 .format() 활용 path = \u0026#39;//*[@id=\u0026#34;__next\u0026#34;]/div/main/div[2]/div/div[4]/div[1]/div[{}]/div/a/div[2]/p[1]\u0026#39; for i in range(1, 11): result = driver.find_element(By.XPATH, path.format(i)) print(result.text) Wait and Call 동적 웹페이지를 스크래핑하기 위해 일정 시간을 기다림(Wait)\nImplicit Wait\n.implicitly_wait({num}) : num초동안 로딩을 기다리는데 그 전에 완전한 응답이 오면 다음으로 진행 1 2 3 4 5 from selenium.webdriver.support.ui import WebDriverWait driver.get(url) driver.implicitly_wait(10) #10초 result = driver.find_element(By.XPATH, path) Explicit Wait\nWebDriverWait() until() : 조건이 만족될 때까지 until_not() : 조건이 만족되지 않을때까지 expected_conditions(EC) : selenium에 정의된 조건들 1 2 3 4 5 6 7 from selenium.webdriver.support import expected_conditions as EC with webdriver.Chrome(service = Service(ChromeDriverManager().install())) as driver: driver.get(url) # XPath 가 path 인 요소가 존재할때까지 최대 10초동안 기다림 element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, path))) print(element.text) Events 마우스 이벤트\n마우스 움직이기, 마우스 누르기, 마우스 떼기 등 여러 이벤트가 일어날 수 있음 특정 버튼을 찾은 후 클릭하는 코드 1 2 3 4 5 6 7 8 9 10 11 # 다른 import 과정은 생략 from selenium.webdriver import ActionChains driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) driver.get(url) driver.implicitly_wait(0.5) # class 두 개 이상인 경우 .으로 연결해 동시에 참조 가능 # class 이름으로 버튼을 찾음 button = driver.find_element(By.CLASS_NAME, \u0026#39;UtilMenustyle__Link-sc-2sjysx-4.ewJwEL\u0026#39;) # 찾은 버튼을 마우스로 `click`하는 이벤트를 실행 ActionChains(driver).click(button).perform() 키보드 이벤트\n키보드 누르기, 키보드 떼기 등 여러 이벤트가 일어날 수 있음\n특정 입력창을 찾은 후 요소에 입력하는 코드\n1 2 3 4 5 6 7 # 다른 import 과정은 생략 from selenium.webdriver import ActionChains, Keys # XPath를 통해 id 입력하는 input 태그를 찾음 id_input = driver.find_element(By.XPATH, id_path) # {your_id}를 input에 입력하는 이벤트를 실행 ActionChains(driver).send_keys_to_element(id_input, {your_id}).perform() 로그인 자동화 예시\n로그인 페이지로 이동 후, 아이디와 비밀번호를 입력하고 로그인버튼을 누르는 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import time # url, id_path, pw_path 등은 사이트마다 달라짐 driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) driver.get(url) time.sleep(1) driver.implicitly_wait(0.5) button = driver.find_element(By.CLASS_NAME, {class_name_1}) ActionChains(driver).click(button).perform() time.sleep(1) id_input = driver.find_element(By.XPATH, id_path) ActionChains(driver).send_keys_to_element(id_input, {your_id}).perform() time.sleep(1) pw_input = driver.find_element(By.XPATH, pw_path) ActionChains(driver).send_keys_to_element(pw_input, {your_password}).perform() time.sleep(1) login_button = driver.find_element(By.CLASS_NAME, {class_name_2}) ActionChains(driver).click(login_button).perform() 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nselenium\nmouse events, keyboard events 찾아보기 EC(expected condition)의 다른 조건에는 어떤게 있는지 찾아 정리해보기 여러 class를 가진 요소 찾기\nclass_name_1.class_name_2처럼 .으로 연결하여 동시에 참조할 수 있음 ❗ 느낀 점 오늘도 2시간 반 정도에 강의와 실습을 모두 끝냈다. 계속 일찍 끝나고 쉬운 내용만 나오니까 너무 겉핥기로만 배우는 것 같고, 혼자서 더 공부해야할까 불안감도 조금 들었다. 그래서 오늘은 TIL을 적은 다음 배운것들을 활용해 KBO사이트에서 스탯을 추출해보려고 한다. 다 진행하고 나서 따로 정리하고 글을 써서 올릴 예정이다.\n그리고 어제 블로그를 세팅한 이후에 기존에 TIL을 올리던 velog를 어떻게 해야할지도 고민하고 있다. 다 지우기도 아깝고 더 안올리자니 멈춰져있는 블로그 같아서.. 백업용으로 주말에 몰아서 일주일치를 올리는 방법도 고민중이다!\n아직 전반적으로 쉬운편이기는 하지만, 점점 더 흥미로워지고 있다. 이후에 배울 내용들과 다음달 초에 하게 될 프로젝트가 기대된다. 🤗\n","date":"2023-10-26T14:37:54+09:00","permalink":"https://srlee056.github.io/p/day-9/","title":"Day 9"},{"content":" TIL - HTML 분석 📋 공부 내용 requests\n라이브러리를 사용해 웹 브라우저와 같이 웹 페이지를 요청하고 응답을 받아옴 응답 받은 문서 -\u0026gt; 분석 필요! BeautifulSoup HTML 코드를 분석 하는 라이브러리 (HTML Parser)\n설치 방법 (mac, python3 기준)\n1 2 3 pip install bs4 or pip3 install bs4 HTML 분석 실습 필요 라이브러리 불러오기\n1 2 import requests from bs4 import BeautifulSoup #import bs library 사이트를 요청하고 응답받기\n1 2 # requests.get으로 사이트 HTML을 받아 와 저장 res = requests.get(\u0026#34;https://www.example.com\u0026#34;) 응답받은 HTML으로 BeautifulSoup 객체를 만들고 내용을 출력해보기\n1 2 3 4 5 6 # bs 객체를 만들고, res.text와 \u0026#34;html.paser\u0026#34;를 인자로 넘겨 # HTML parser 역할을 하게 만듬 soup = BeautifulSoup(res.text, \u0026#34;html.parser\u0026#34;) # HTML의 구조를 잘 보여주도록 들여쓰기하여 출력 print(soup.prettify()) HTML의 특정 요소 찾기\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 해당하는 각 태그의 내용을 보여줌 soup.title soup.head soup.body # h1태그들 중 가장 먼저 나오는것을 찾아 반환 h1 = soup.find(\u0026#34;h1\u0026#34;) # p태그 모두를 찾아 반환 soup.find_all(\u0026#34;p\u0026#34;) # 태그 이름과 (h1) 태그 안의 내용을 가져옴 h1.name h1.text 특정 요소를 찾아 그 안의 원하는 정보만 추려내기\n1 2 3 4 5 6 7 8 9 # 책 리스트를 찾아 그 제목만 추출하는 코드 # 직접 사이트를 확인하고 h3태그에 책 이미지, 저자, 제목 등이 있는것을 확인하여 find_all로 가져옴 h3_results = soup.find_all(\u0026#39;h3\u0026#39;) # 객체로 만들게 되면, 내부 태그를 속성처럼 쓸 수 있음 # h3 \u0026gt; a 태그 내에 title 속성 value를 출력하는 함수 for book in h3_results: print(book.a[\u0026#39;title\u0026#39;]) id를 이용해 요소 가져오기\n1 2 3 # .find(\u0026lt;tag_name\u0026gt;, id = \u0026lt;id_name\u0026gt;) soup.find_all(\u0026#34;div\u0026#34;, id=\u0026#34;bo_list\u0026#34;) soup.find(\u0026#34;div\u0026#34;, id=\u0026#34;bo_cate\u0026#34;) class를 이용해 요소 가져오기\n1 2 3 # .find(\u0026lt;tag_name\u0026gt;, \u0026lt;class_name\u0026gt;) soup.find_all(\u0026#34;li\u0026#34;, \u0026#34;questions\u0026#34;) soup.find(\u0026#34;div\u0026#34;, \u0026#34;question\u0026#34;) user-agent 정보를 넘기면서 요청하기\nuser agent 확인 사이트\n1 2 3 4 5 user_agent = {\u0026#34;User-Agent\u0026#34;: \u0026lt;본인의 user agent 정보\u0026gt;} import requests from bs4 import BeautifulSoup url = \u0026#34;https://qna.programmers.co.kr/\u0026#34; res = requests.get(url, user_agent) 페이지네이션 (Pagination)\n정보를 인덱스로 구분하는 기법\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 해당 사이트는 query string으로 구분 import time import requests from bs4 import BeautifulSoup url = \u0026#34;https://qna.programmers.co.kr/?page={}\u0026#34; for i in range(1, 6): res = requests.get(url.format(i), user_agent) soup = BeautifulSoup(res.text, \u0026#34;html.parser\u0026#34;) questions = soup.find_all(\u0026#34;li\u0026#34;, \u0026#34;question-list-item\u0026#34;) for question in questions: print(question.find(\u0026#34;div\u0026#34;, \u0026#34;question\u0026#34;).find(\u0026#34;div\u0026#34;, \u0026#34;top\u0026#34;).h4.a.text) # 과도한 요청을 방지하기 위해 1초마다 요청 time.sleep(1) 웹 사이트와 스크래핑 정적 or 동적 웹 사이트 웹 사이트는 정적(Static) 웹 사이트 와 동적(Dynamic) 웹 사이트 로 나눌 수 있다. 웹 사이트 Static Dynamic HTML 내용 고정 변경 HTML 데이터 로드 응답 이전에 완료됨 응답 이후에 완료되기도 함 동기 or 비동기 처리 동기 처리 (정적 웹 사이트)\n렌더링이 완료된 이후에 데이터 처리를 진행 요청에 따른 응답을 기다려야 함 비동기 처리 (동적 웹 사이트)\n렌더링과 데이터 처리가 동시에 진행됨 요청에 따른 응답을 기다리지 않음 상황에 따라 응답 시 받은 HTML 문서의 데이터가 완전하지 않은 경우 발생 스크래핑 requests 요청의 문제점\n불완전하고 원하지 않은 내용의 응답을 받게 되어 동적 웹사이트에 적용이 어려움 키보드, 마우스 입력 등 UI와 상호작용 하기 어려움 해결 방법\n데이터 처리 후 응답을 받아오는 방식 적용 UI Action을 프로그래밍 웹 브라우저 역할을 하는 대신 웹 브라우저를 조작 -\u0026gt; Selenium 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nPagination : 정보를 인덱스로 구분하는 기법 Query String .format method 1 \u0026#34;{}\u0026#34;.format(a) -\u0026gt; \u0026#34;a\u0026#34; 동기 처리와 비동기 처리의 개념에 대해 한번 더 복습 bs .find 함수 여러 요소를 찾을 때 or을 적용하여 A or B or C class 모두를 찾을 수 있는지 궁금 class A, B / class A 인 요소 두 개가 있을 때 class B를 가진 요소는 배제하고 찾는 방법도 궁금 정적 웹 사이트에는 requests같은 라이브러리를 쓰고 동적 웹 사이트에는 Selenium을 쓰는지 아니면 일괄적으로 Selenium처럼 웹 사이트를 조작하는 형식의 라이브러리만 쓰는지 궁금하다. 중첩된 div 내에 h4가 있는 경우에 (div\u0026gt;div\u0026gt;h4) 가장 바깥 div 내에 h4가 하나뿐이라면 div_container.find(\u0026quot;div\u0026quot;).h4 로 쓰지 않고 div_container.h4로 작성해도 원하는 기능을 하던데 이유가 궁금하다. ❗ 느낀 점 오늘은 꽤나 만족스러운 하루를 보냈다.\n강의와 실습은 내 기준엔 어렵지 않아 2시간 내로 완료했다. 실습을 하면서 주어진 사이트 외에 다른 사이트도 들어가서 분석하고 배운 함수를 적용해보았다. 실습을 하면서 궁금한 점이 몇개 생겼고 CHECK에도 적어놨는데, TIL을 다 적은 후에 구글링 및 슬랙 채널을 통해서 해결해 볼 생각이다.\n그리고 코어타임 중간에 hugo로 만든 블로그에 글을 올려봤는데 내가 생각했던것 보다 더 쉬워서 안심했다. 블로그와 관련해 다음 세 가지 목표를 세웠다.\ngithub action 수정해서 push 하면 자동으로 빌드, 배포되게 만들기 hugo new post 템플릿 만들기 한국어 설정하기 이렇게 세팅을 완료한 후에, 기존에 작성했던 TIL을 올리고 카테고리 설정까지 하면 완성이다. 나중엔 블로그 메인 페이지 커스텀, 댓글 위젯 설정, SEO 세팅 등을 해보려고 한다.\n","date":"2023-10-25T16:23:38+09:00","permalink":"https://srlee056.github.io/p/day-8/","title":"Day 8"},{"content":"Blog 제작기 #1에서 이어지는 블로그 제작기 입니다. :\u0026gt;\npost template \u0026amp; 속성 설정 template /archetypes 내부에 .md 형식으로 template 생성 /archetypes/default.md : 아무 옵션도 설정하지 않았을 때 기본 생성되는 template /archetypes/til.md : TIL 작성용으로 만든 template 1 2 3 4 5 6 7 8 9 10 author = \u0026#34;Seorim\u0026#34; title = \u0026#34;{{ replace .File.ContentBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date = {{ .Date }} categories = [ \u0026#34;DevCourse\u0026#34;, ] tags = [ \u0026#34;TIL\u0026#34;, ] --kind 커맨드로 template 적용 1 hugo new content content/post/newpost.md --kind til 속성 설정 url\n별도로 설정하지 않으면 title로 url 설정 됨 1 2 title = \u0026#39;Blog 제작기 #2\u0026#39; url = \u0026#39;/Blog/blog-2\u0026#39; draft\n빌드에 포함 시키는 여부. false : 포함 / true : 미포함 기본 template default.md 1 2 3 4 author = \u0026#34;Seorim\u0026#34; title = \u0026#39;{{ replace .File.ContentBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#39; date = {{ .Date }} draft = false structure\npost 폴더 안에 \u0026lt;title\u0026gt;.md 바로 생성 가능 /\u0026lt;title\u0026gt;/index.md 방식으로 따로 분류할수도 있음 이외에 개인적으로 폴더를 나눠 분류할수도 있음 1 2 3 4 5 6 content ├─ post │ ├─ Blog │ │ └─ blog-2.md │ └─ DevCourse └─ _index.md 자동 빌드 /배포 Github Actions /.github/workflows/hugo.yaml git push를 인식하여 자동으로 build/deploy 진행 branch 이름을 main -\u0026gt; master (이전에 만든 repository라서 기본 브랜치 이름이 master였는데, hugo에서 제공하는 기본 코드의 기본 브랜치는 main으로 되어 있었다) 아바타, 파비콘 추가 아바타 /assets/img/avatar.png config file hugo.toml 1 2 3 4 [params.sidebar.avatar] enabled = true local = true src = \u0026#34;img/avatar.png\u0026#34; 파비콘 /static/img/favicon.ico config file hugo.toml 1 2 [params] favicon = \u0026#34;/img/favicon.ico\u0026#34; config 수정 한국어 설정 config file hugo.toml 1 2 3 4 5 6 7 8 9 10 11 languageCode = \u0026#34;ko-KR\u0026#34; DefaultContentLanguage = \u0026#34;ko\u0026#34; ... [languages.ko] languageName = \u0026#34;Korean\u0026#34; title = \u0026#34;서림록\u0026#34; weight = 1 [languages.ko.params] description = \u0026#34;\u0026#34; 기타 설정 math : 수학 수식 표시 여부\ntoc : 목차\nreadingTime : 해당 글의 글자수를 기준으로 읽는 데 몇 분 정도 걸리는지 표시함\n1 2 3 4 [params.article] math = false toc = true readingTime = false ","date":"2023-10-25T00:00:00Z","permalink":"https://srlee056.github.io/Blog/blog-2/","title":"Blog 제작기 #2"},{"content":"TIL - HTTP 📋 공부 내용 웹 웹 페이지와 HTML 웹 페이지\n웹 속의 문서 하나 ex) 네이버 메인 페이지 HTML으로 구성되어있음 웹 사이트\n여러 웹 페이지의 모음 ex) 네이버라는 웹 사이트 웹 브라우저\nHTTP요청을 보낸 후, HTTP응답에 담긴 HTML문서를 사용자가 보기 쉽게 화면으로 그려주는 (렌더링) 역할 HTML(개념 정리 글 링크)\n이전 강의에서 다룬 내용 참고 웹 브라우저마다 지원하는 태그와 속성이 달라짐 웹 스크래핑 / 웹 크롤링 웹 스크래핑\n특정 목적에 따라 웹 페이지에서 원하는 데이터를 \u0026ldquo;추출\u0026rdquo; ex) 날씨 정보 가져오기, 주식 데이터 가져오기, \u0026hellip; 웹 크롤링\n크롤러를 이용해 URL을 타고 이동하며 반복적으로 웹 페이지의 데이터를 가져와 \u0026ldquo;인덱싱\u0026rdquo;(데이터 색인) 구글, 네이버 등 검색 엔진의 웹 크롤러 올바른 HTTP Request 올바른 HTTP Request를 위해선..\n어떤 목적을 달성하려 하는가? 서버에 영향을 미치는가? 로봇 배제 프로토콜(REP)\n웹 크롤링, 스크래핑은 로봇에 의해 실행 가능 사이트의 모든 정보를 취득하는것이 정당한가? 의문에서 시작 robots.txt 각 사이트마다 허용하는 크롤러 정보와 허용범위에 대한 정보를 담고 있음 User-agent, Disallow, Allow HTTP HTTP? HyterText Transfer Protocol\n웹 상에서 정보를 주고받기 위한 약속\nHTTP Request HTTP Response 방향 Client -\u0026gt; Server Client \u0026lt;- Server 역할 정보 요청 요청에 대한 내용을 담은 응답 HEAD method, path, \u0026hellip; content-type, date, \u0026hellip; BODY document 통신하기 requests\nPython으로 HTTP 통신을 진행할 수 있게 해주는 라이브러리 GET\nnaver 메인 페이지를 요청하는 코드 1 2 3 4 import requests res = requests.get(\u0026#34;https://www.naver.com\u0026#34;) # HTTP Response res.headers # Header 확인 res.text # Body(document) text 형태로 확인 POST\nhttps://webhook.site 를 통해 POST 통신을 진행할 수 있음 1 2 3 4 payload = {\u0026#34;name\u0026#34;: \u0026#34;Hello\u0026#34;, \u0026#34;age\u0026#34;: 13} url = \u0026#34;https://webhook.site/\u0026lt;개인 주소\u0026gt;\u0026#34; res = requests.post(url, payload) res.status_code # 상태 코드 확인 DOM DOM? Document Object Model\nHTML을 파싱하여, 브라우저가 이해하도록 만든 Tree형태의 자료구조\nDOM의 각 노드를 객체로 생각하여, 문서를 편리하게 관리할 수 있음\n원하는 요소를 동적으로 변경할 수 있음\n원하는 요소를 쉽게 찾을 수 있음\npython으로 HTML을 직접 분석하려면 DOM을 생성해주는 브라우저를 거치지 않기 때문에, 직접 HTML을 분석하는 HTML Parser가 필요\n👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들)\nJupyter lab\nJupyter notebook이나 Colab은 써 봤는데 Jupyter lab은 처음 접해봄 Jupyter notebook과 비슷하지만 더 개선된 버전(?) DOM에 대한 설명 및 활용 : 복습 후 다른 예시들을 더 찾아볼 것\n❗ 느낀 점 HTML 스크래핑을 해본적이 있어서 이론이나 실습 모두 빠르게 진행했다. 5시간 분량의 강의인데 3시간 내로 끝난 것 같다. TIL을 잘 적고 싶어서 고민을 좀 했고 그 외의 시간은 평소보다는 널널하게 흘려보냈다.\nTIL을 적을 때 기존에는 강의 받아쓰기처럼 적는 경향이 있었는데, 나중에 다시 읽어보니 이해하고 쓴 것 같은 느낌이 전혀 들지 않았다. 어제 HTML이론에 대한 TIL은 실습 부분 외에도 직접 사용해보고 하면서 적은거라, \u0026lsquo;내가 직접 써보고 이해한 내용\u0026rsquo;임을 알 수 있었다. 그런데 초반에 적은 TIL을 다시 보니까 그냥 받아적은게 티가 나기도 하고 잘 기억이 나지 않았다.\n오늘은 강의를 처음부터 끝까지 들은 후 키워드만 체크해 필기한 다음, TIL을 적으면서 중간중간 다시 듣는 방식을 사용했다. 이 방식으로 더 잘 읽히고 짜임새 있는 구성의 글을 쓰게 되어서 만족스러웠다. TIL 쓰는 시간은 오래 걸리지만 익숙해지면 줄어들 것 같아서 걱정은 되지 않는다.\n커리큘럼을 보니 내일부터는 BeautifulSoup를 사용해 스크래핑을 시작하는데, 모르는 부분이 많을 것 같아 벌써부터 기대가 된다. :\u0026gt;\n","date":"2023-10-24T00:00:00Z","permalink":"https://srlee056.github.io/p/day-7/","title":"Day 7"},{"content":" TIL - HTML 📋 공부 내용 HTML\nHypertext Markup Language\n웹 브라우저가 이해할 수 있는 \u0026ldquo;언어\u0026rdquo;\nCSS\nCascading Style Sheets\n문서를 예쁘게 \u0026ldquo;꾸미는\u0026rdquo; 언어\nJavaScript\nJS = JavaScript\n문서에 \u0026ldquo;기능\u0026quot;을 만들어주는 언어\nHTML - 기본 문법 태그 컨텐츠를 갖는 태그 / 가지지 않는 태그 열리는 태그 \u0026amp; 닫히는 태그 / 단일 태그 (셀프 클로징) \u0026lt;div\u0026gt; contents \u0026lt;/div\u0026gt; / \u0026lt;br /\u0026gt; 속성과 값 \u0026lt;div attributes = value\u0026gt;content\u0026lt;/div\u0026gt; \u0026lt;div title = \u0026quot;제목\u0026quot;\u0026gt; ... title : 전역 속성이라 모든 태그에서 사용 가능 속성(Attributes)의 종류는 아주 많고 다양함 부모요소 \u0026amp; 자식요소 1 2 3 4 html ├─ head │ └─ title └─ body html (부모) - head, body (자식)\n부모/자식 구조를 파악하기 좋게, 들여쓰기/내어쓰기 깊이(depth)를 잘 지켜서 작성해야 함\n탭 잘 쓰라는얘기\nHTML 주석 1 \u0026lt;!-- 주석 내용 --\u0026gt; 1 2 3 \u0026lt;!-- 줄바꿈 가능 --\u0026gt; 1 2 3 4 \u0026lt;!-- \u0026lt;!-- --\u0026gt; --\u0026gt; 이처럼 주석 안에 주석을 넣으면 바깥의 여는 태그가 안쪽 닫는 태그를 인식해 주석이 풀리게 된다. 고로 주석 안에 주석은 X 웹 브라우저의 소스보기 등에서 확인 가능하므로 보안이 필요한 정보는 적지 않아야 한다.\nHEAD 사용자에게는 보이지 않지만, 문서의 정보가 담기는 영역\n타이틀 웹 브라우저 탭이나 창에서 표시되는 문서의 제목 메타 데이터 인코딩 정보 charset(character set) : 문서에서 허용하는 문자의 집합 영어만 허용하는 규칙(ISO-8859-1)을 사용할 경우, 한글은 제대로 출력이 되지 않음 \u0026lt;meta charset = \u0026quot;ISO-8859-1\u0026quot;\u0026gt; utf-8(전 세계 언어 지원) 을 기본으로 사용 문서 설명 \u0026lt;meta name = \u0026quot;description\u0026quot; content = \u0026quot;이 문서는 실습 문서입니다.\u0026quot;\u0026gt; 문서 작성자 \u0026lt;meta name = \u0026quot;author content = \u0026quot;srlee\u0026quot; CSS, Javascript 문서 외형에 영향을 주는 태그들로 구성\nstyle\n1 2 3 4 5 6 \u0026lt;!-- 문서 글자색을 blue로 만드는 코드 --\u0026gt; \u0026lt;style\u0026gt; body { color: blue; } \u0026lt;/style\u0026gt; 길이가 너무 길어지면 작성 및 수정이 불편 -\u0026gt; \u0026lt;link\u0026gt;\nlink\n1 2 3 4 \u0026lt;!--단일 속성 rel: 링크된 파일의 속성 href: 파일 경로 --\u0026gt; \u0026lt;link rel = \u0026#34;stylesheet\u0026#34; href=\u0026#34;style.css\u0026#34; /\u0026gt; 별도로 분리된 CSS파일을 링크\nscript\n콘텐츠 방식\n1 2 3 4 \u0026lt;script\u0026gt; const hello = \u0026#39;world\u0026#39;; console.log(hello) \u0026lt;/script\u0026gt; 링크 방식\n1 2 \u0026lt;!-- 콘텐츠를 가지지 않지만 단일태그는 아니기 때문에 셀프 클로징 X --\u0026gt; \u0026lt;script src = \u0026#34;script.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; BODY 사람 눈에 보이는 콘텐츠의 영역\nblock - 블록 레벨 요소 블록처럼 차곡차곡 쌓이며 화면 너비가 꽉 참\n블록의 크기와 내/외부에 여백 지정 가능\n페이지의 구조적 요소\n인라인 요소 포함 가능 / 포함 될 수는 없음\n\u0026lt;div\u0026gt;, \u0026lt;article\u0026gt;, \u0026lt;section\u0026gt;, ...\ninline - 인라인 레벨 요소 블록 요소 내에 포함되는 요소 (블록 요소를 포함할 수 없음!)\n문장, 단어같은 작은 부분에 사용되며, 한 줄에 나열됨\n좌우 여백만 허용\n\u0026lt;span\u0026gt;, \u0026lt;a\u0026gt;, \u0026lt;strong\u0026gt;, ... inline-block 인라인 요소의 불편함을 해결하기 위한 요소 글자처럼 취급되지만 block태그의 성질을 가짐 크기와 내/외부 여백 지정 가능 CSS로 성질을 바꾼 것이기 때문에 의미상 인라인 레벨 요소 활용 예시\n1 2 3 4 \u0026lt;body\u0026gt; \u0026lt;span\u0026gt;인라인\u0026lt;/span\u0026gt; 옆에 글자 \u0026lt;div\u0026gt;블록\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; 1 2 3 4 5 6 7 8 9 span{ padding-left: 100px; padding-top: 100px; /* 적용 X */ } div{ padding-top: 50px; padding-bottom: 30px; padding-left: 100px; } Layout Layout Tag? html5부터 태그를 의미있게 사용하기 위해 Semantic태그를 사용하기 시작 div만 사용하지 않고 적절한 태그를 사용해 웹 문서가 담은 정보와 구조를 의미 있게 전달 semantic한 markup -\u0026gt; 검색 엔진의 순위에 가산점, 로딩속도 빨라짐 등 Tags div 가장 흔하게 사용 구역을 나누기 위한 태그 header 제목, 작성일 등 주요 정보를 담는 태그 footer 페이지 바닥줄에 사용, 저작권 정보, 연락처 등 부차적 정보를 담는 태그 main 페이지의 가장 큰 부분으로 내용, 즉 주요 콘텐츠를 담는 태그 한 페이지에 한번만 등장해야 함 (header, footer는 여러번 등장 가능) -section 콘텐츠의 구역을 나누는 태그 article 구역 안에서 작성된 정보를 전달하는 독립적인 문서의 역할을 하는 태그 aside 문서 내용에 부가적인 갖접정보를 전달하는 태그 예) 쇼핑몰의 \u0026lsquo;오늘 본 상품\u0026rsquo;, 블로그의 \u0026lsquo;위젯\u0026rsquo; 등 레이아웃 분석 (배운 내용을 토대로 해본거라 정확하지 않을 수 있습니다) Contents 제목 태그 h1 ~ h6 문서 구획 제목을 나타내는 태그 h1 태그는 페이지 내에 한번만 사용 구획 순서(h1 ~ h6)는 지켜져야 함 문단 태그 p 문단을 담당하는 태그 제목태그와 함께 사용되기도 하고 단독으로도 사용 레이아웃태그처럼 사용 X 서식 태그 b/strong, i/em, u, s/del b/strong : 굵은 글씨로 변경. strong - 강조 의미 부여 i/em : 기울기 조절, em - 기울임과 내용에 강조 의미 부여 u : 밑줄을 넣고 주석을 가짐. 단순히 밑줄만 긋는 용도로는 사용 X s/del : 취소선, del - 문서에서 제거된 텍스트를 나타냄 1 2 3 4 \u0026lt;p\u0026gt; 안녕하세요.\u0026lt;br\u0026gt; \u0026lt;del\u0026gt;섦\u0026lt;/del\u0026gt; \u0026lt;ins\u0026gt;서림\u0026lt;/ins\u0026gt;입니다. \u0026lt;/p\u0026gt; 안녕하세요.\n섦 서림입니다. 링크 이동 a 클릭하면 페이지를 이동할 수 있는 링크 요소\nhref 속성으로 이동하려는 파일 / URL 작성\ntarget 속성으로 새 창(_blank), 현재창(_self)등 타겟 지정 가능\n1 \u0026lt;a href = \u0026#34;https://velog.io/@srlee056\u0026#34; target = \u0026#34;_blank\u0026#34;\u0026gt; 새 창에서 블로그 열기\u0026lt;/a\u0026gt; 새 창에서 블로그 열기\n멀티미디어 img 이미지를 추가하는 태그 src : 이미지의 경로 alt : 로딩에 문제가 발생했을 때 대체 텍스트 alt 태그에 적힌 메세지가 검색엔진에 키워드로 들어감 1 2 \u0026lt;img src = \u0026#34;\u0026#34; alt = \u0026#34;잘못된 로고\u0026#34;\u0026gt; \u0026lt;img src = \u0026#34;https://cdn.icon-icons.com/icons2/2699/PNG/512/python_logo_icon_168886.png\u0026#34; alt = \u0026#34;파이썬 로고\u0026#34;\u0026gt; figure, figcaption 태그 안의 내용을 하나의 독립적인 콘텐츠로 분리하고 설명을 넣을 수 있는 태그\n보통 이미지를 넣으며 인용문, 비디오/오디오 등 문서 흐름에 참조는 되지만 독립적으로 분리되어도 되는 내용을 담는다.\n이미지 - 인라인 레벨 요소 / 피규어 - 블록 레벨 요소\n1 2 3 4 \u0026lt;figure\u0026gt; \u0026lt;img src = \u0026#34;https://www.lgtwins.com/images/emblem/01.emblem.jpg\u0026#34; alt = \u0026#34;엘지 트윈스 로고\u0026#34;\u0026gt; \u0026lt;figcaption\u0026gt; 엘지 트윈스 우승하자! \u0026lt;/figcaption\u0026gt; \u0026lt;/figure\u0026gt; 엘지 트윈스 우승하자! video 문서 내에 영상을 첨부할 수 있는 태그 src : 비디오 파일이나 온라인 링크 연결 poster : 비디오 로드되기 전 포스터를 보여줄 수 있음 \u0026lt;source\u0026gt; 태그로 여러 타입의 비디오 제공 1 2 3 4 5 6 \u0026lt;video src = \u0026#34;/video.mp4\u0026#34;\u0026gt;\u0026lt;/video\u0026gt; \u0026lt;video poster = \u0026#34;/poster.png\u0026#34;\u0026gt; \u0026lt;source src = \u0026#34;/video.mp4\u0026#34; type = \u0026#34;video/mp4\u0026#34;\u0026gt; \u0026lt;source src = \u0026#34;/video.webm\u0026#34; type = \u0026#34;video/webm\u0026#34;\u0026gt; 비디오 태그가 실행되지 않을 때 보이는 글자 \u0026lt;/video\u0026gt; audio 문서 내에 소리를 첨부할 수 있는 태그\nsrc : 음성 파일이나 온라인 링크 연결\n\u0026lt;source\u0026gt; 태그로 여러 타입의 오디오 제공\ncontrols : 재생/정지 버튼 등이 있는 컨트롤러\n1 2 3 4 5 6 \u0026lt;audio src = \u0026#34;/audio.mp3\u0026#34; controls\u0026gt;\u0026lt;/audio\u0026gt; \u0026lt;audio controls\u0026gt; \u0026lt;source src = \u0026#34;/audio.mp3\u0026#34; type = \u0026#34;audio/mp3\u0026#34;\u0026gt; \u0026lt;source src = \u0026#34;/audio.ogg\u0026#34; type = \u0026#34;audio/ogg\u0026#34;\u0026gt; 오디오 태그가 실행되지 않을 때 보이는 글자 \u0026lt;/audio\u0026gt; svg Scalable Vector Graphics\n그래픽으로 만들어진 이미지\n해상도의 영향을 받지 않아 확대/축소 자유로움\n크기를 자주 바꾸어야 하는 작은 아이콘 등에 많이 사용\n최근 기기들은 해상도가 다양하게 변화하고 있어, 아이콘 외에 로고 등 주요 이미지에도 사용\n\u0026lt;img\u0026gt;태그처럼 svg 파일을 불러올수도 있고, 태그를 그대로 사용할수도 있음\n코드로 이루어져 있어서 스타일을 변경하거나, JS를 사용해 기능 추가도 가능\n1 2 3 4 5 6 \u0026lt;img src=\u0026#34;baseball.svg\u0026#34; alt=\u0026#34;야구공 아이콘\u0026#34; /\u0026gt; \u0026lt;!--또는 .svg 파일의 내용을 가져다가 쓸 수 있음--\u0026gt; \u0026lt;svg\u0026gt; 파일 내용 \u0026lt;/svg\u0026gt; svg 파일 출력 결과\n리스트 \u0026lt;ul\u0026gt;, \u0026lt;li\u0026gt;\n순서가 없고 정렬되지 않은 목록\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;list 1\u0026lt;/li\u0026gt; \u0026lt;!--자식 요소로 li만 와야 함--\u0026gt; \u0026lt;li\u0026gt;list 2 \u0026lt;ul\u0026gt; \u0026lt;!-- ul or ol tag--\u0026gt; \u0026lt;li\u0026gt;sub list 1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;sub list 2\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;sub list 3\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; HTML 출력 결과\nlist 1 list 2 sub list 1 sub list 2 sub list 3 \u0026lt;ol\u0026gt;\n순서가 존재하며 정렬된 목록\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;list 1\u0026lt;/li\u0026gt; \u0026lt;!--자식 요소로 li만 와야 함--\u0026gt; \u0026lt;li\u0026gt;list 2 \u0026lt;ol\u0026gt; \u0026lt;!-- ul or ol tag--\u0026gt; \u0026lt;li\u0026gt;sub list 1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;sub list 2\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;sub list 3\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; HTML 출력 결과\nlist 1 list 2 sub list 1 sub list 2 sub list 3 \u0026lt;dl\u0026gt;, \u0026lt;dt\u0026gt;, \u0026lt;dd\u0026gt;\n설명 목록 태그 \u0026lt;dt\u0026gt;에 작성된 단어 혹은 내용의 설명을 \u0026lt;dd\u0026gt;에 작성 용어사전이나 key-value쌍의 목록을 나타낼 때 사용 \u0026lt;dt\u0026gt; 여러개에 하나의 \u0026lt;dd\u0026gt; 가능 / \u0026lt;dt\u0026gt; 하나에 여러개 \u0026lt;dd\u0026gt; 가능 1 2 3 4 5 6 7 8 9 \u0026lt;dl\u0026gt; \u0026lt;dt\u0026gt;Chrome\u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt;웹 브라우저\u0026lt;dd\u0026gt; \u0026lt;dd\u0026gt;구글에서 제작\u0026lt;/dd\u0026gt; \u0026lt;br\u0026gt; \u0026lt;dt\u0026gt;Whale\u0026lt;/dt\u0026gt; \u0026lt;dt\u0026gt;Microsoft Edge\u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt;Web Browser\u0026lt;/dd\u0026gt; \u0026lt;/dl\u0026gt; 표 \u0026lt;table\u0026gt; : 표를 만드는 태그 \u0026lt;tr\u0026gt; 로 행을, \u0026lt;td\u0026gt;로 열을 나타냄 \u0026lt;th\u0026gt; : 열 제목 \u0026lt;thead\u0026gt; : 제목 그룹 태그, 한번만 사용 \u0026lt;tbody\u0026gt; : 표의 본문 요소 그룹 태그, 역시 한번만 사용 \u0026lt;tfoot\u0026gt; : 표 바닥글 요소 태그 \u0026lt;caption\u0026gt; : 표 설명 태그 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;table\u0026gt; \u0026lt;caption\u0026gt;sample table\u0026lt;/caption\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;col 1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;col 2\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tfoot\u0026gt; \u0026lt;!-- HTML4 에선 tbody 앞--\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;footer\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;footer\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tfoot\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; row1 col1 \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; row1 col2 \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; row2 col1 \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; row2 col2 \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; sample table col 1 col 2 footer footer row1 col1 row1 col2 row2 col1 row2 col2 iframe 현재 문서 안에 다른 HTML 페이지를 삽입하는 역할\nsrc 속성에 원하는 HTML 문서나 URL 전달 name 속성을 지정해 \u0026lt;a\u0026gt; target 속성을 사용해 iframe에서 문서나 URL 열리게 가능 불러온 외부 페이지의 영향을 받을 수 있다. 1 2 3 4 5 \u0026lt;iframe src = \u0026#34;/sample.html\u0026#34; frameborder = \u0026#34;0\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;iframe name=\u0026#34;sample\u0026#34; frameborder=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;a href=\u0026#34;https://example.com/\u0026#34; target=\u0026#34;sample\u0026#34;\u0026gt;example.com\u0026lt;/a\u0026gt; \u0026lt;!--target으로 설정된 iframe에서 외부 페이지가 열림--\u0026gt; 양식 태그 form 정보를 제출하기 위한 태그\n정보 입력을 위한 \u0026lt;input\u0026gt;, \u0026lt;selectbox\u0026gt;, \u0026lt;textarea\u0026gt;\n정보 제출을 위한 \u0026lt;button\u0026gt;\naction 속성 : 정보 제출 시 페이지 이동\nmethod 속성 : 정보 제출 시 처리 방식 결정\nget : 검색 엔진 등에 사용 post : 로그인 등 보안이 중요한 방식에 사용 1 2 3 4 5 6 7 8 9 10 \u0026lt;form action=\u0026#34;form-result.html\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input name=\u0026#34;id\u0026#34; type=\u0026#34;text\u0026#34;\u0026gt; \u0026lt;input name=\u0026#34;password\u0026#34; type=\u0026#34;password\u0026#34;\u0026gt; \u0026lt;select name=\u0026#34;opt\u0026#34;\u0026gt; \u0026lt;option\u0026gt;옵션1\u0026lt;/option\u0026gt; \u0026lt;option\u0026gt;옵션2\u0026lt;/option\u0026gt; \u0026lt;option\u0026gt;옵션3\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;전송\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; label \u0026lt;input\u0026gt;, \u0026lt;selectbox\u0026gt;, \u0026lt;textarea\u0026gt; 의 설명을 작성하는 태그 for 속성 : 연결하려는 태그의 id속성으로 지정하면 label클릭 시 연결된 태그가 선택됨 label 태그 내부에 input 태그를 넣으면, for-\u0026gt;id 연결을 직접 작성하지 않아도 같은 처리를 해 준다. id 속성값은 절대 중복되면 안됨 1 2 3 4 5 6 7 \u0026lt;label for =\u0026#34;userid\u0026#34;\u0026gt;아이디\u0026lt;/label\u0026gt; \u0026lt;input id = \u0026#34;userid\u0026#34; type = \u0026#34;text\u0026#34; name = \u0026#34;userid\u0026#34;\u0026gt; \u0026lt;label\u0026gt; 비밀번호 \u0026lt;input name = \u0026#34;password\u0026#34; type = \u0026#34;password\u0026#34;\u0026gt; \u0026lt;/label\u0026gt; input 사용자에게 데이터를 입력 받을 수 있는 대화형 태그\ntype 속성 : 받을 수 있는 input 유형을 정함 (기본:text)\nvalue 속성 : 기본 내용을 입력해둘 수 있음\nname : input 이름 지정\n자주 사용되는 input type\ncheckbox radio file button : input 태그를 버튼역할로 사용해야할 때 활용 hidden : 시각적으로 숨겨지지만 정보 제출 시 value속성에 입력된 값은 전송됨 1 2 3 \u0026lt;input type=\u0026#34;text\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;input-name\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;입력 내용\u0026#34;\u0026gt; select select, selectbox 옵션 메뉴를 제공하는 태그 option 태그 : 선택할 옵션들을 정의 value 속성 : 제출 시 선택한 옵션의 value값이 전송됨 value 속성을 선언하지 않은 경우엔 option 태그 콘텐츠가 기본값 placehoder 속성 사용 불가 1 2 3 4 5 6 \u0026lt;select name = \u0026#34;selectbox\u0026#34;\u0026gt; \u0026lt;option value=\u0026#34;\u0026#34;\u0026gt;choose\u0026lt;/option\u0026gt; \u0026lt;option value = \u0026#34;opt1\u0026#34;\u0026gt;opt1\u0026lt;/option\u0026gt; \u0026lt;option value = \u0026#34;opt2\u0026#34;\u0026gt;opt2\u0026lt;/option\u0026gt; \u0026lt;option\u0026gt;opt3\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; textarea 여러 줄을 입력할 수 있는 대화형 태그 콘텐츠에 내용을 입력할 경우 그 내용이 기본적으로 표시됨 cols/rows 속성 : 기본 너비와 높이를 지정할 수 있으며, 이는 글자 크기 기준으로 정의됨 알아두면 좋은 속성 readonly : 수정 불가능한 읽기 전용 required : form 제출 시 \u0026ldquo;필수 입력 사항\u0026quot;으로 설정 (안내 문구나 행동 등은 브라우저가 자동으로 처리함) placeholder : input, textarea에 부가설명을 입력해둘 수 있으며, select 에는 사용 불가 disabled : 비활성화되어 제출 시 값이 전송되지 않음 button 클릭가능한 버튼 form tag 내 어디서든 사용 가능 type 속성 submit(기본): 양식 제출 reset: 입력 양식 모두 초기화 콘텐츠에 블록레벨을 제외한 태그 입력 가능 disabled 속성 가능 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들) vscode -\u0026gt; cmd + , -\u0026gt; folder 검색 -\u0026gt; 계층 구조 관련 옵션 바꿀 수 있음 markup : 설명 블로그 맥에서 크롬 개발자 도구 한번에 키는 단축키 : cmd + shift + c ❗ 느낀 점 HTML문법이나 태그 등에 대한건 이미 알고 있었지만 이론적으로 정리해본 적은 없었기에 이번 강의를 듣고 정리할 수 있어서 좋았다. 특히 contents 태그와 단일 태그의 존재는 알았지만 그 명칭은 몰랐기 때문에 머리속에서 모호하게 정의된 개념들이 이름을 가지고 명확해져서 좋았다.\n강의 내용을 정리하고 직접 실행해보고 궁금한 부분은 따로 찾아보는 등 하다보니 주어진 코어타임보다 훨씬 더 오랜 시간을 붙잡고 있게 되었다. 중간중간 집중력도 떨어지고 체력적으로도 힘든 걸 느끼면서, 이론적인 공부보다는 실제 코드를 작성하는 게 더 재밌다는걸 새삼 체감했다. 그렇지만 이론적인 공부가 전부가 아니더라도 기본적인건 알아야 하니까 재미없다고 등한시 하지는 않아야겠다. :\u0026lt;\n이번주는 드디어 웹 크롤링과 분석을 시작하는데, 내가 해봤던 것과 다른점은 무엇이고 어떤걸 배워나가게 될지 벌써부터 기대가 된다. 내일도 열심히 하는 하루를 보내야겠다. :\u0026gt;\n","date":"2023-10-23T00:00:00Z","permalink":"https://srlee056.github.io/p/day-6/","title":"Day 6"},{"content":"TIL - Heap / Dynamic Programming / DFS\u0026amp;BFS (문제풀이 위주) 📋 공부 내용 Heap \u0026lt;더 맵게\u0026gt; 문제 풀이 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import heapq #heap 라이브러리 사용 def solution(scoville, K): answer = 0 # heapify, heappop, heappush 활용 heapq.heapify(scoville) #min heap 구성 while True: s1 = heapq.heappop(scoville) if s1 \u0026gt;= K : #모든 스코빌 지수가 K이상 break elif len(scoville) == 0: # K이상으로 만들 수 없는 경우 answer = -1 break s2 = heapq.heappop(scoville) newS = s1 + s2*2 heapq.heappush(scoville,newS) answer += 1 return answer Dynamic Programming DP(Dynamic Programming) 알고리즘 진행에 따라 탐색해야 할 범위를 동적으로 결정하여 탐색 범위를 한정\nEX1) 피보나치 수열\nComplexity 재귀함수 DP Time O(2^n) O(n) Space O(n) O(n) 참고 : Recursion vs Dynamic Programming - Fibonacci\nEX2) knapsack problem\nweight / value를 가진 여러 물건이 있을 때, weight 제한이 있는 베낭에 value의 합이 가장 높도록 물건을 골라 담는 문제\n\u0026lt;N으로 표현\u0026gt; 문제 풀이 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def solution(N, number): strN = str(N) # 직관적인 코드를 위해 다음과 같이 index : 1~8 사용 설정 (index 0은 사용하지 않음) numberUsed = [{} for _ in range(9)] for i in range(1, 9): numberUsed[i] = {int(strN * (i))} # N을 i번 나열한 숫자 ex) 555, 7777, ... for j in range(1 , i): for n1 in numberUsed[j]: for n2 in numberUsed[i-j]: newNumbers = [n1*n2, n1+n2, n1-n2] if n2 != 0 : newNumbers.append( n1//n2 ) numberUsed[i].update(newNumbers) #set1.update(set2) 사용하여 원소 추가. set 아닌 list를 넘겨줄수도 있다. if number in numberUsed[i]: return i return -1 DFS \u0026amp; BFS 1. Depth First Search 한 vertex에서 인접한 모든 vertex를 방문할 때, 인접한 vertex를 기준으로 깊이 우선 탐색을 끝낸 후 다음 vertex로 진행하는 방식\n스택을 이용하여 어느 정점에서 DFS를 진행하고 있는지를 기억\n2. Breadth First Search 한 vertex에서 인접한 모든 vertex를 방문하고, 방문한 인접 vertex를 기준으로 너비 우선 탐색을 진행하는 방식\n3. Graph -vertex(=node) \u0026amp; edge(=link)\n-directed / undirected graph\n\u0026lt;여행 경로\u0026gt; 문제 풀이 DFS를 응용한 재귀 한 붓 그리기\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def solution(tickets): routes = {} for a, b in tickets: #출발지, 도착지 routes[a] = routes.get(a, []) routes[a].append(b) for r in routes: routes[r].sort(reverse=True) # 역순인 이유? 파이썬의 데이터 삭제 과정을 살펴보면 뒤에서 뽑는게 더 효울적이기 때문 stack = [\u0026#34;ICN\u0026#34;] path = [] while 0 \u0026lt; len(stack): top = stack[-1] if top not in routes or len(routes[top]) == 0: # 이 공항에서 떠나는 티켓이 존재하지 않음 path.append(stack.pop()) else : stack.append(routes[top].pop()) return path[::-1] 추가 문제풀이 문제 링크 모음(많이 김) 프로그래머스 코딩테스트 문제 링크 (코스에 있는 문제여도 프로그래머스 코테 링크로 적음) 완주하지 못한 사람 올바른 괄호 스킬트리 배달 [세 소수의 합] [주사위 게임] 사탕 담기 [빙고] 방문 길이 [쇠막대기] 자물쇠와 열쇠 [게임 아이템] 기능개발 더 맵게 [배상 비용 최소화] [문자열 압축 코드] 카펫 예산 N-Queen [버스 여행] 예산_소팅 최솟값 만들기 가장 큰 수 N으로 표현 2 x n 타일링 등굣길 가장 긴 팰린드롬 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들) PEP 8 파이썬이 추구하는 코드 스타일. 들여쓰기, 공백, 변수명 작성 규칙 등이 포함된다.\nPEP 8 - Style Guide for Python Code(공식 문서) PEP8 스타일 가이드를 설명하는 블로그(한국어) Tim sort Insertion sort + Merge sort\nInsertion sort는 n이 작을 때 (Quick sort보다도) 빠름 전체를 작은 덩어리로 잘라 Insertion sort -\u0026gt; Merge Tim sort에 대해 설명하는 글 DP 익숙해지기 knapsack problem 등 문제풀이를 통해 익숙해지기 ❗ 느낀 점 오늘은 DP(Dynamic Programming)과 DFS\u0026amp;BFS의 개념에 대해 가볍게 배우고, 문제풀이를 위주로 강의가 진행되었다.\n아는 알고리즘들이고 어제 강의의 문제가 나에겐 어렵지 않았기 때문에, 해설 강의를 듣기 전에 문제를 먼저 풀어 보았다. 문제를 풀다가 막히는 부분이 있으면 강의를 틀고, 해결되면 멈추고 다시 풀어보곤 했다.\nHeap 문제를 제외한 두 문제는 해설 없이 풀었고, Heap 문제도 heapq 라이브러리를 사용해야하는 것을 깨닫고는 금방 풀 수 있었다.\n이번주 강의를 듣고 문제를 풀면서 느낀점이 몇개 있다.\n나는 알고리즘 자체는 꽤 잘 알고 활용도 잘 하는 편이지만 라이브러리 사용에 있어서 소극적인 면이 있다. 문제를 풀 때 파이썬 표준 라이브러리조차도 잘 import하지 않고 Dictionary나 Set정도만 사용하는 편이었다. (Heap도 자체적으로 구현하거나 list를 사용하곤 했는데 왜 이런 습관이 들었는지는 잘 모르겠다.) 이번 강의를 들으면서 표준 라이브러리에 있는 여러 데이터형을 활용했고 다음에 문제를 풀 때도 적극적으로 활용하면서 더 효과적인 코드를 작성하는데 가까워지려고 한다.\n나는 CS 용어를 잘 모른다. 아예 모른다는게 아니라, 많이 헷갈리며 정확한 명칭을 찾아보지 않았다는 의미이다. member method, list comprehension 등 용어들은 분명 내가 궁금해서 찾아봤지만 아직도 헷갈리거나 명칭 자체를 몰랐던 것들이다. 강의를 통해 명확해지거나 새롭게 알게 된 용어들이 있어서 좋았고, 이제부터는 모르는 부분에 대해 검색할 때는 아예 용어와 그 정의부터 찾는것부터 시작해야겠다고 다짐했다.\n내일은 강의가 없는 날이다. 하지만 해야 할 일들은 있다. 오늘까지 배운걸 복습하고, 배운 자료구조와 알고리즘을 활용하는 문제들을 lv3정도로 풀어 볼 것이다. 내일도 화이팅!!\n","date":"2023-10-20T00:00:00Z","permalink":"https://srlee056.github.io/p/day-5/","title":"Day 5"},{"content":"TIL - Hash / Greedy \u0026amp; Sort (문제풀이 위주) 📋 공부 내용 Hash Hash?\n개념 정리가 필요하다고 느껴서 글을 따로 발행했다.\nUnderstanding Hash Table\n(번역 및 정리)Hash Table 이해하기\n완주하지 못한 선수 문제풀이\npython dictionary 를 활용하여 hasing 구현 1 2 3 4 5 6 7 8 9 10 11 12 13 def solution(participant, completion): answer = \u0026#39;\u0026#39; pDict = {} # 참가자/ 완주자 정보가 주어질 때, 이름을 key로 활용하여 dictionary 형태에 넣고 빼는 방식으로 # (동명이인이 있을 때에도) 어떤 이름을 가진 사람이 완주를 하지 못했는지 확인할 수 있다. for p in participant: pDict[p] = pDict.get(p, 0) + 1 #.get()을 통해 default 값을 세팅하는 한 방법 for p in completion: pDict[p] -= 1 incompletion = [k for k, v in pDict.items() if v \u0026gt; 0] answer = incompletion[0] return answer Greedy Algorithm 탐욕법(greedy algorithm)\n알고리즘의 각 단계에서 그 순간의 최적의 선택을 함 탐욕법으로 최적해를 찾을 수 있는 문제\n= 현재 선택이 마지막 답의 최적성을 해치지 않는 문제 체육복 문제풀이\n비슷해보이는 조건문이라해도 그 순서에 따라 전혀 다른 결과가 나올 수 있음 작은 번호부터 큰 번호로 순회하기 때문에, 작은 번호가 조건을 만족하는지 먼저 고려함 큰 수 만들기 문제풀이\n매 단계마다 작은 숫자를 지우는 탐욕법을 사용하며, 이 방식은 마지막에 최적성을 충족하게 됨 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def solution(number, k): collected = [] for i, num in enumerate(number): # collected에 미리 들어간 원소가 있을 것 # 제일 마지막으로 들어간 원소는 현재 num 값보다 작을 것 # (제거해야 하는 숫자의 개수) k가 0보다 클 것 while len(collected) \u0026gt; 0 and collected[-1] \u0026lt; num and k \u0026gt;0: collected.pop() k -=1 if k == 0: collected += list(number[i:]) break collected.append(num) # 제거해야 하는 숫자의 개수가 남아있을 때 # (코드가 너무 직관적이고 예뻤다. :\u0026gt;) collected = collected[:-k] if k \u0026gt; 0 else collected answer = \u0026#39;\u0026#39;.join(collected) return answer Sort 가장 큰 수 문제풀이 자릿수가 다른 숫자들을 문자열처럼 나열하여 더 큰 숫자를 만들 때, 숫자들의 우선순위를 정하는 방법은? 1 2 3 4 5 sortedNumbers = sorted(map(str, numbers), key = lambda x : (x * 4)[:4], reverse = True) # map(str, numbers) : numbers 정수 리스트를 문자열 리스트로 변환 # sorted(..., reverse = True) : 주어진 조건으로 정렬하며, 내림차순으로 반환 # lambda x : (x*4)[:4] : 네 자리 수까지 주어지므로 4번 반복 후 네번째자리까지 끊음 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들) Hash\n가볍게 정리했지만 더 자세하게 찾아보고 싶음 (활용되는 곳, 특성을 구현하는 법, hashing function, collision 등) list comprehension\n한 줄에 반복문 할당 배열생성 등이 한번에 일어남 list comprehension 설명 블로그 글 쓸 줄 아는 방식이지만 용어를 처음 알게 됨 (예전에 배우고 까먹은 게 분명) list slicing 에 바로 대입하여 직관적으로 코드 작성 가능\nEX) list[1:3] = [1, 2] ❗ 느낀 점 어제 더 나은 코드를 위해 어떤점을 고려해야하는지 많은 고민을 했는데, 오늘 강의에서 그 부분을 짚어줘서 좋았다.\n오늘은 각 알고리즘이나 자료구조에 대한 설명보다는 문제 풀이와 해설을 위주로 강의가 진행되었는데, 그래서 나 스스로 그 개념에 대해 찾아보고 정리하는 시간이 필요했다. greedy나 sort는 이미 잘 알고 있는 부분이지만 hash는 헷갈리는 부분이 있어서 블로그와 document를 읽어보면서 글로 정리하는 시간을 가졌다.\n깊이가 정해져있지 않다 보니 원하는 만큼 궁금해하고 파헤칠 수 있었지만, 내가 그 내용을 받아들이고 정리할 수 있는가는 별개의 문제임을 깨달았다. hash를 설명하는 블로그 글에 연결된 링크를 타고 여러 글을 읽어가다 보니, 어느새 encoding\u0026amp;decoding, scheduling에 대한 글을 읽고 있었다. 이런 글들을 읽고 어느정도 이해할 수는 있었지만, 글로 정리하거나 그 사이의 관계를 명확하게 아는것은 큰 차이가 있었고, 머리속이 혼란스러웠다. 어떤 주제와 관련된 내용을 잘 찾고 정리하는것도 많은 노력이 필요하다는 걸 새삼 느끼는 순간이었다.\n오늘처럼 깊이가 없는 공부를 해야하는 순간은 계속 있을것이고(있어왔고), 정해진 주제에 대해 찾아본 내용들을 글로 정리하면서 나만의 기준을 정립해야겠다는 결론을 내렸다.\n+) 퇴고하기 위해 글을 읽어보는데 두서없고 추상적이라 맘에 들지 않음..(ㅠㅠ) 문장력을 키우고 싶은데 온라인으로도 필사할 수 있는지 찾아봐야겠다.\n","date":"2023-10-19T00:00:00Z","permalink":"https://srlee056.github.io/p/day-4/","title":"Day 4"},{"content":"TIL - Queue, Tree \u0026amp; Heap 📋 공부 내용 Queues Queue?\nFIFO (First In First Out) operations enqueue dequeue 선형 배열으로 구현: O(n) -\u0026gt; 연결 리스트로 구현하는것이 더 좋음 Circular Queues\n배열의 한쪽 끝과 다른쪽 끝이 닿아 있는 모습 원소의 개수가 정해져있음 front / rear 포인터를 기억하고, dequeue된 원소 저장소는 재활용 선형 배열으로 구현하는것이 더 좋음 Priority Queues\n원소들 사이의 우선순위를 따름 우선순위 구현 원소를 넣을 때 enqueue vs. 원소를 꺼낼 때 dequeue 넣을 때(enqueue) 우선순위에 따라 정렬하는것이 조금 더 나은 Time Complexity를 가짐 데이터를 관리하고 활용하는 데에도 더 편리함 Trees Tree?\n구성 root node interner nodes leaf nodes 특성 parent node / child node 노드의 수준 (level) : root node로부터 거리 노드의 차수 (degree) : 노드의 자식 수 트리의 높이(height) 또는 깊이(depth) : 제일 큰 level + 1 subtree Binary Trees\n모든 node의 degree \u0026lt;= 2 operations size() depth() 순회 traversal Depth First Traversal : 재귀 호출을 통해 구현 inorder preorder postorder Breadth Tirst Traversal : queue 사용! level이 낮은 노드를 우선으로 방문 같은 level인 경우 부모 노드의 순서를 따름 포화 이진 트리 (full binary trees) 모든 node의 degree == 2 완전 이진 트리 (complete binary trees) (depth k) level k-2까지는 full binary tree, level k-1은 왼쪽부터 node 채워짐 Binary Search Trees\n모든 노드에 대해 다음 성질을 만족하는 Binary Tree 왼쪽 subtree\u0026rsquo;s data \u0026lt; 현재 node\u0026rsquo;s data \u0026lt; 오른쪽 subtree\u0026rsquo;s data 장단점 장점 : 원소의 추가, 삭제가 편함 단점 : 큰 공간을 소요함 (연결 리스트로 구현) operations insert() remove() lookup() inorder() min(), max() Heap Heaps? Binary Tree의 한 종류 (binary heap)\nMin / Max heap\nroot node가 항상 최소/최대 값을 가진다 complete binary tree n nodes -\u0026gt; depth log(n)+1 insert / remove operation의 Time Complexity : O(log(n)) subtree 또한 Min / Max heap Binary Seacrh Tree vs. Heap?\nBST Heap 데이터 정렬 크기순서대로 완전 정렬 완전 정렬 X 데이터 검색 O X 완전 이진 트리 X O 연산 시간 (최악의 경우) O(n) O(log(n)) 선형 배열로 구현 X O operations\ninsert() remove() 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들) 노드의 차수(degree) : # of children binary tree : 모든 노드의 degree가 항상 2이하 leaf nodes : degree 0 단축 평가 단축평가에 대해 참고한 블로그 2개 이상의 논리 조건식이 있을 경우에, 앞 조건이 계산한 값에 의해 결과가 확실해지면 두번째 조건은 확인하지 않음 False and (), True or () 인 경우 등이 해당됨 ❗ 느낀 점 어제의 교훈이 있어서 그런지, 오늘은 프로그래밍 과정에 실수가 적었다. 그리고, 자료구조를 구현하는 과정에서 더 나은 방식에 대해 고민하는 상황이 많아졌다.\n오늘 주로 고민한 부분은\n1 2 3 4 5 코드를 더 직관적으로 적고싶음 - 반복되는 같은 코드를 합칠 수 있는가? 같은 코드 다른 효율? - 같은 기능을 하지만 살짝 다른 두 코드 중 더 나은것은? 정도였다.\n전자는 내가 평소 프로그래밍 할 때 자주 하긴 하는데, 항상 고민하는 부분이다. 반복되는 기능을 함수로 빼던가, 적용되는 변수를 리스트로 묶어서 반복하는 등의 방법을 쓰는데, 다른 방법은 뭐가 있을까 고민하고 있다.\n후자는 Complexity를 구하는 방법에 대한 의문이 아니다. 실제로 이 operation이 어떻게 구현되고 있는지, 왜 그렇게 구현되었는지가 궁금한 것이다. 실습 문제에서 우선순위 queue를 구현할 때, skeleton code의 dequeue 함수는 마지막 elements를 가져오는 방식으로 되어있었다.(getAt(data.size())) 나는 처음 element를 가져오는 방식으로 생각하고(getAt(1)) 이에 해당하는 enqueue 함수를 작성했기 때문에 잠깐 막혔다가, 결국은 눈치채고 해결했다.\n그 코드를 보면서 이렇게 구현하는게 더 나은건지 궁금증이 들었고, 같은 기능을 하지만 결함이 적은(?) 코드를 작성하자는 생각이 들었다.\n오늘은 추가 알고리즘 문제들이 있고 아직 풀지 않았는데, 쉬운 문제들이지만 이 두가지를 생각하면서 풀려고 노력해야겠다.\n","date":"2023-10-18T00:00:00Z","permalink":"https://srlee056.github.io/p/day-3/","title":"Day 3"},{"content":"TIL - LinkedList \u0026amp; Stack 📋 공부 내용 연결 리스트 Linked List 추상적 자료구조 Abstract Data Structures\n내부 구현에는 신경쓸 필요 없는 구조 data \u0026amp; a set of operations 이 두 가지를 추상적으로 보여줌 Linke List?\nNode가 선형적으로 연결된 구조 Node \u0026amp; LinkedList 구현\n1 2 3 4 5 6 7 8 9 10 class Node: def __init__(self, item): self.data = item self.next = None # 다음 노드를 가리킴 class LinkedList: def __init__(self): self.nodeCount = 0 # 노드의 총 갯수 self.head = None # 첫번째 노드 self.tail = None # 마지막 노드 Linked List 연산 (operations)\nlinked list의 index는 1부터 시작 / 0은 다른 용도로 사용(Dummy node)\n(실습으로 구현한 코드만 첨부했음) kth element 참조\n리스트 순회\n1 2 3 4 5 6 7 def traverse(self): curr = self.head returnList = [] while curr is not None: returnList.append(curr.data) curr = curr.next return returnList 길이 얻기\n원소 삽입\nTime complexity 맨 앞에 삽입 : O(1) 중간에 삽입 : O(n) 맨 끝에 삽입 : (Tail pointer가 있기 때문에) O(1) 원소 삭제\nTime complexity 맨 앞에 삽입 : O(1) 중간에 삽입 : O(n) 맨 끝에 삽입 : O(n) → 이 상황을 피하기 위해 이중 연결 리스트를 사용 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 삭제한 node 데이터를 반환 def popAt(self, pos): if pos \u0026lt; 1 or pos \u0026gt; self.nodeCount: raise IndexError if pos == 1: prev = None curr = self.head self.head = curr.next else: prev = self.getAt(pos - 1) curr = prev.next prev.next = curr.next if pos == self.nodeCount: self.tail = prev self.nodeCount -= 1 return curr.data 두 리스트 합치기 concat\n배열 Array vs 연결 리스트 Linked List\n배열 연결 리스트 저장 공간 연속된 위치 임의의 위치 특정 원소 참조 매우 간편 선형탐색과 유사 O(1) O(n) time complexity에 불리함이 있는데도 사용하는 이유는?\n연결 리스트 Linked List의 힘\n유연한 삽입 및 삭제 Head, Tail에 dummy node를 추가하여 간편하고 직관적인 설계 가능 추가 구현 operations insertAfter(prev, node)\npopAfter(prev) \u0026amp; popAt(pos)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def popAfter(self, prev): curr = prev.next if curr is None : return None if curr.next is None: self.tail = prev prev.next = curr.next self.nodeCount -= 1 # nodeCount 꼭 체크하기 return curr.data def popAt(self, pos): if pos \u0026lt; 1 or pos \u0026gt; self.nodeCount: raise IndexError prev = self.getAt(pos-1) return self.popAfter(prev) 양방향 / 이중 연결 리스트 Double Linked List 양쪽으로 연결된 link - next node, previous node로 두 방향 모두 진행 가능 - 메모리 사용량이 늘어나지만, 앞에서뿐만 아니라 뒤에서도 데이터를 찾아갈 수 있다는게 장점 getAt() 함수 또한 pos가 중간값 이상일 때는 뒤에서부터 찾도록 구현할 수 있음 operations reverse\n1 2 3 4 5 6 7 def reverse(self): result = [] curr = self.tail while curr.prev.prev: curr = curr.prev result.append(curr.data) return result insertBefore\n1 2 3 4 5 6 7 8 def insertBefore(self, next, newNode): prev = next.prev newNode.next = next newNode.prev = prev prev.next = newNode next.prev = newNode self.nodeCount += 1 return True popAfter, popBefore, popAt\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def popAfter(self, prev): curr = prev.next next = curr.next prev.next = next next.prev = prev self.nodeCount -= 1 return curr.data def popBefore(self, next): curr = next.prev prev = curr.prev prev.next = next next.prev = prev self.nodeCount -= 1 return curr.data def popAt(self, pos): if pos \u0026lt; 1 or pos \u0026gt; self.nodeCount: raise IndexError prev = self.getAt(pos - 1) return self.popAfter(prev) # next = self.getAt(pos+1) # getAt 함수가 pos == nodeCount+1 일 때 지원을 하지 않아서 사용은 어려움 # next = self.getAt(pos).next #로 사용 가능 # return self.popBefore(next) concat(self, L)\n1 2 3 4 5 6 7 def concat(self, L): lastNode = self.tail.prev firstNode = L.head.next lastNode.next = firstNode firstNode.prev = lastNode self.tail = L.tail self.nodeCount += L.nodeCount 스택 Stack data element를 보관할 수 있는 선형 구조 / LIFO operations size() isEmpty() push(x) 꽉 찬 스택에 push(x)로 원소를 더 추가하려고 할 때 stack overflow 발생 pop() 비어있는 스택에서 pop()으로 없는 원소를 꺼내려 할 때 stack underflow 발생 peek() 데이터 참조, 제거하지는 않음 추상적 자료구조로 구현 Array 또는 LinkedList 이용 만들어져있는 Stack library 를 import 할 수도 있음 from pythonds.basic.stack import Stack 스택의 응용 1) 후위 표기법으로 변환\n중위 표기법 (infix notation) : (A+B) * (C+D) → 후위 표기법 (postfix notation) : AB+CD+* 알고리즘 설계 operator 연산자를 스택에 넣는 방식\n연산자 우선순위 설정\n1 prec = {\u0026#39;*\u0026#39;:3, \u0026#39;/\u0026#39;:3, \u0026#39;+\u0026#39;:2, \u0026#39;-\u0026#39;:2, \u0026#39;(\u0026#39;:1} 구현 코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def solution(S): opStack = ArrayStack() charList = [] # 수식을 리스트 형태로 저장한 후 .join을 통해 문자열로 변환 for s in S: if s in prec.keys(): # 연산자 + 여는 괄호 if s == \u0026#34;(\u0026#34;: opStack.push(s) else: while not opStack.isEmpty(): # 스택이 비어있는 동안 계속 if prec[opStack.peek()] \u0026gt;= prec[s]: # 스택 맨 위의 우선순위가 높거나 같은 경우에만 charList.append(opStack.pop()) # pop()하여 문자열에 출력 else: break opStack.push(s) elif s == \u0026#34;)\u0026#34;: # 닫는 괄호 while opStack.peek() != \u0026#34;(\u0026#34;: # 여는 괄호가 나올때까지 모든 연산자를 꺼내 출력 charList.append(opStack.pop()) opStack.pop() # pop \u0026#39;(\u0026#39; else: # 피연산자 charList.append(s) while not opStack.isEmpty(): # 스택에 남아있는 연산자들을 모두 출력 charList.append(opStack.pop()) answer = \u0026#34;\u0026#34;.join(charList) return answer 스택의 응용 2) 후위 표기법 계산\n앞에서부터 뒤로 읽어나가면서 먼저 만나는 연산자를 먼저 계산 알고리즘 설계 operands 피연산자들을 스택에 넣는 방식\n구현 코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def postfixEval(tokenList): valStack = ArrayStack() for t in tokenList: if type(t) is int: valStack.push(t) else: b = valStack.pop() a = valStack.pop() if t == \u0026#39;*\u0026#39;: valStack.push(a*b) elif t == \u0026#39;/\u0026#39;: valStack.push(a/b) elif t == \u0026#39;+\u0026#39;: valStack.push(a+b) elif t == \u0026#39;-\u0026#39;: valStack.push(a-b) return valStack.pop()\t👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들) member field, member method\n용어의 뜻은 알지만 애매해서 다시 정리하기 위해 찾아봄 정리에 참고한 사이트 추상적 자료구조\nabstract data type vs. data structure an ADT (Abstract Data Type) is more of a logical description, while a Data Structure is concrete. 정리에 참고한 사이트 : 추상적 자료형 vs. 자료구조 dummy node를 추가한 구조의 linked list\nstack underflow\n‼️ 느낀 점 오늘은 두 가지 교훈(?) 을 얻었다.\n한번에 두가지 일을 하지 않기 강의를 들으면서 TIL을 적으려고 했는데, 외려 더 정신없고 힘들었다. 강의 듣는 중간에 적다 보니, 그냥 받아쓰기가 되는것도 별로였다. 큰 주제 (오늘 같은 경우 LinkedList / Stack)를 다 듣고 정리하는게 나을 듯!\n사소한 실수 하지 않고 꼼꼼하게 체크하기 오늘 연습문제를 풀면서\nnode.data 대신 node 객체를 반환함 linked list의 nodeCount 증감시키는걸 빼먹음\n명시된 조건을 빼먹는 실수를 저질러서 디버깅 한다고 다 합해서 한시간 가까이 소모했다. 몰라서 못 푸는것 보다 이런 부분에서 꼼꼼하지 못해서 못 푸는게 더 싫다. 심지어 원래는 그렇게 자주 하는 실수도 아니어서 자존심이 더 상했다. ㅠㅠ 그래도 이런 날이 있어야 앞으로 안 그럴 수 있으니까 계속 담아두지는 말아야지!\n내일은 강의와 실습을 꼼꼼하게 진행하고, 내가 이해한 내용을 토대로 TIL을 잘 적어봐야겠다. :\u0026gt;. 그리고 내일은 github 블로그에 올려봐야지! 🔥 어렵지만 할 만한 가치가 있어보인다 😊\n","date":"2023-10-17T00:00:00Z","permalink":"https://srlee056.github.io/p/day-2/","title":"Day 2"},{"content":"1일차 TIL에서 이어지는 블로그 제작기 입니다. :\u0026gt;\n(아직 제작중인)블로그를 구경하시려면 클릭하세요!\n1. 로컬에서 휴고 사이트 만들기 1 2 3 4 5 6 hugo new site blog cd blog git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack echo \u0026#34;theme = \u0026#39;hugo-theme-stack\u0026#39;\u0026#34; \u0026gt;\u0026gt; hugo.toml hugo server 나는 가이드에 적힌 theme과는 다른 hugo-theme-stack을 사용했다. 가이드에는 새 post를 만들고 config 파일인 hugo.toml을 수정하는 부분도 나와있지만, 이후에 둘 다 다른 내용으로 덮어써서 넘어가도 되는 과정이었다.\n2. theme 커스터마이징하기 themes/hugo-theme-stack/exampleSite/config.yaml 파일 내용을 변환하여 제일 상위 폴더의 ./hugo.toml 파일에 붙여넣고,\n(구글에 \u0026lsquo;yaml to toml\u0026rsquo;로 검색하면 많은 converter를 볼 수 있다.)\nthemes/hugo-theme-stack/exampleSite/contetns/ 안의 파일들을 ./contetns 에 붙여넣었다.\n이 과정에는 이 블로그 글을 많이 참고했다. 정말 감사합니다👍🏻\nhugo.toml 파일에 오류가 좀 있는 것 같지만\n내가 아직 hugo configuration 관련해서 잘 모르고 오류가 있는데도 서버가 잘 돌아가고 빌드도 돼서 나중에 고치기로 했다. (🤔 이게 왜 되지?) 3. 배포하기 (사실 배포가 제일 쉬웠다) github 사이트에서 \u0026lt;username\u0026gt;.github.io 이름의 레포지토리를 만들고 로컬에서 변경 내용을 모두 commit한 이후,\n1 git remote add origin https://github.com/\u0026lt;username\u0026gt;/\u0026lt;username\u0026gt;.github.io.git 위 커맨드를 입력해 로컬과 원격 레포지토리를 연결한다. 1 git push -u origin master 그리고 push하면 레포지토리 관련은 끝. (branch 관련 건드린 게 있다면 push하기 전에 master로 옮길것.) +) 요즘은 master가 아닌 main branch로 바뀌었더라. 빌드와 배포는 git actions기능을 활용했는데, hugo 사이트에 github hosting 가이드라인이 잘 적혀있다.\n이 링크의 내용을 요약하자면\n레포지토리 settings/pages에서 source를 GitHub Actions로 변경 로컬에서 .github/workflows/hugo.yaml 파일 생성 후 내용 붙여넣기 (폴더도 직접 생성해줘야함) 변경사항을 commit, push한 이후 레포지토리의 Actions 탭에 들어가면 빌드/배포 기능을 하는 Action이 추가됨 Run Workflow 버튼을 누르면 빌드/배포가 자동으로 진행되며 내 github page에 테마가 적용된 사이트가 잘 올라와 있다. 왜인지 모르겠지만 잘 돌아가는 블로그\n블로그 github repo.\n느낀점 전체적으로 해결하지 못한 오류도 많고, 이해하지 못한 구조도 많지만 오늘은 배포에 성공한 것에 의의를 두려고 한다.🥲\n다음엔? hugo로 포스트 올리기 오류 해결하기 (layout 인식 문제 등) theme custom 으로 링크 등 UI 추가해보기 ","date":"2023-10-16T00:00:00Z","permalink":"https://srlee056.github.io/Blog/blog-1/","title":"Blog 제작기 #1"},{"content":"1. 자료구조 \u0026amp; 알고리즘 강의 및 코드 리뷰 📋 공부 내용 선형 배열 - Linear Arrays 배열(array) : 개념적 구조 / 리스트 : python 데이터형\n리스트 methods\ntime complexity O(1) .append() .pop() time complexity O(n) .insert() .del() .index() .insert() 정렬(sort)\nsorted() : function, 정렬된 새로운 리스트를 반환하며 기존 리스트에는 변화 없음. .sort() : method, 기존 리스트가 정렬됨 숫자가 아닌 문자열 등 데이터형의 정렬 : 사전순이 기본, 문자열의 길이 등 다른 정렬 조건을 사용하고 싶다면 lambda 활용 문자열을 길이순으로 정렬\n1 sorted(L, key = lambda x : len(x)) 사전 데이터형(dictionary)에 key = ‘name’인 value의 문자열 순서대로 정렬\n1 2 3 L = [ {\u0026#39;name\u0026#39; : \u0026#39;John\u0026#39;, \u0026#39;score\u0026#39;: 90}, {\u0026#39;name\u0026#39; : \u0026#39;Paul\u0026#39;, \u0026#39;score\u0026#39;: 80} ] sorted(L, key = lambda x : x[\u0026#39;name\u0026#39;] 탐색(search)\n선형(linear) 탐색, 순차(sequential) 탐색 이진(binary) 탐색 재귀 알고리즘 - recursive algorithms 종결 조건(trivial case) 을 명시해야 함 예시 1부터 x까지 숫자의 합을 구하는 함수 (sum)\n1 2 3 def recursiveSum(x): if x \u0026lt; 1 : return x return recursiveSum(x-1) + x 조합의 수 (nCm)\n하노이의 탑\n피보나치 순열\n장점 : 알고리즘을 간단하고 이해하기 쉽게 풀어냄 단점 : time complexity 부분에서 비효율적인 경우가 많음 이러한 특성 때문에 tree 자료구조를 이용하는 알고리즘에 활용 Complexity Time Complexity Space Complexity 다루는 데이터가 커질수록, 더 효율적인 complexity를 가지는 방식이 필요함 (2^n, n! 등의 complexity X) 👀 CHECK (어렵거나 새롭게 알게 된 것 등 다시 확인할 것들) 코드로 elapsed time을 확인 -\u0026gt; 디버깅이나 time complexity를 직관적으로 확인하는 등에 활용 list method .pop() 과 .remove()의 차이점 big O notation - O of n 으로 읽음 list의 앞과 뒤에 접근하는것은 O(1)의 time complextity를 갖는다. ‼️ 느낀 점 아직까지는 전공 과정 복습하는 느낌이고, 쉽다고 느꼈다. 막히는 부분은 없었다. 코드를 작성하면서 조금 더 나은 코드에 대해 생각해보는것 정도. 공부하는 중이나 이후에 바로 TIL을 적는게 제일 좋다고 생각하는데, 블로그 세팅에 정신이 팔려서 나중에 작성하게 된 건 조금 아쉽다. 오늘은 코어타임보다 일찍 강의를 들어버려서 시간 분배가 애매했다. 내일은 코어타임 시작할 때 듣기 시작하고, 그 전에는 전날 내용을 복습하거나, 알고리즘 문제를 풀고 code review를 작성하는 시간을 가져야겠다.\n2. 블로그 세팅 과정 노션이나 옵시디언으로 TIL을 적고 깃에 업로드 한 적은 많지만 블로그에 올리는건 처음이라, 어디에 올리지 고민하다가 일단 티스토리 계정과 블로그를 만들었다.\n그런데 만들다 보니 github repo와 연동되는 page를 세팅하고 싶다..! 라는 욕심이 들기 시작했고, jekyll 등을 알아보다가 hugo를 활용한 페이지 세팅을 접하게 되어 장장 3시간을 투자했다.\n그런데 이 글을 티스토리에 올리는 이유는? 세팅에 실패했기 때문 ㅠㅠ\nTIL 작성하고 나서 다시 도전해서 세팅 과정에 대해서도 글을 써 볼 예정이다.\n+) 티스토리에서 md로 작성한게 예쁘게 안나와서 벨로그로 옮겼다 😂 훨씬 편한 것 같은데 깃허브랑 연동 전까진 벨로그로 해야겠다 :\u0026gt;\n(지금까지 참고한 링크들) 휴고 사이트 생성 가이드 휴고 사이트 깃허브 연결 가이드 사용 테마1 사용 테마2 ","date":"2023-10-16T00:00:00Z","permalink":"https://srlee056.github.io/p/day-1/","title":"Day 1"}]